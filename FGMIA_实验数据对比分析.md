# FGMIA 论文实验数据对比分析

## 论文基本信息

- **标题**: FGMIA: Feature-Guided Model Inversion Attacks Against Face Recognition Models
- **作者**: Ye Lu, Shen Wang, Guopu Zhu, Zhaoyang Zhang, Jiwu Huang
- **单位**: 哈尔滨工业大学网络空间安全学院
- **期刊**: IEEE Transactions on Information Forensics and Security, Vol. 20, 2025
- **DOI**: 10.1109/TIFS.2025.3592542

---

## 实验设置概览

### 数据集配置

| 数据集类型 | 数据集名称 | 身份数量 | 用途 | 分布特征 |
|----------|----------|---------|-----|---------|
| 私有数据 | CelebA-Mini2 | 1,000 | 目标模型训练 | - |
| 辅助数据（相似分布） | CelebA-Mini1 | 1,000 | 攻击训练 | 与私有数据相似 |
| 辅助数据（偏移分布） | FFHQ-128 | - | 攻击训练 | 高质量人脸，分布偏移 |
| 辅助数据（偏移分布） | VGGFace2-Mini | 1,000 | 攻击训练 | 多姿态多年龄，分布偏移 |

**数据预处理**: 关键点对齐、中心裁剪、数据归一化
**图像尺寸**: 112×112
**辅助图像数量**: 约30,000张

### 目标模型配置

#### 闭集模型（Closed-set）
| 模型名称 | 主干网络 | 分类方式 | LFW准确率 |
|---------|---------|---------|----------|
| IR152 | ResNet-152 | Linear层 | >90% |
| Face.evoLVe | - | Linear层 | >90% |

#### 开集模型（Open-set）
| 模型名称 | 主干网络 | 损失函数 | LFW准确率 |
|---------|---------|---------|----------|
| FaceNet | Inception-ResNet | Triplet Loss | >90% |
| CosFace | Inception-ResNet-v2 | Cosine Loss | >90% |
| ArcFace | Inception-ResNet-v2 | Additive Angular Margin Loss | >90% |

#### 网络深度变体
- **CosFace**: 18层、34层、50层、100层
- **ArcFace**: 18层、34层、50层、100层

### 评估指标

| 指标 | 全称 | 含义 | 优化方向 |
|-----|------|------|---------|
| **Target Acc** | Target Accuracy | 生成样本在目标模型上的分类准确率 | 越高越好 |
| **Eval Acc** | Evaluation Accuracy | 生成样本在交叉评估模型上的准确率 | 越高越好 |
| **KNN** | K-Nearest Neighbor Distance | 特征空间中生成样本与私有数据的余弦相似度 | 越高越好 |
| **FID** | Fréchet Inception Distance | 生成图像与私有图像特征分布的距离 | 越低越好 |
| **LPIPS** | Learned Perceptual Image Patch Similarity | 感知相似度（基于VGG特征） | 越高越好 |

---

## 实验一：多目标模型对比实验（表I）

### 对比方法
1. **GMI** (2020) - 基准方法，首次提出生成模型逆向攻击
2. **PPAMI** (2022) - 基于StyleGAN的即插即用方法
3. **FMI** (2022) - 使用α-GAN作为辅助生成模型
4. **PLG** (2023) - 伪标签引导的条件GAN方法
5. **Diff-MI** (2024) - 基于扩散模型的白盒SOTA方法
6. **IF-GMI** (2024) - 优化StyleGAN中间层特征
7. **UAMI** (2024) - 基于扩散模型的黑盒SOTA方法
8. **FGMIA** (本文) - 特征引导扩散模型方法

### 实验结果总结

#### 目标模型：IR152, Face.evoLVe, FaceNet, CosFace, ArcFace
- **辅助数据集**: CelebA-Mini1（相似分布）
- **生成样本数**: 每类16张，选择最相似的展示

#### 关键发现

| 性能指标 | FGMIA表现 | 对比说明 |
|---------|----------|---------|
| Target Accuracy | ✅ 与PPAMI、Diff-MI相当 | 保持高目标准确率 |
| **Eval Accuracy** | ✅ **显著优于所有方法** | 交叉评估性能最优（核心优势） |
| KNN | ✅ 优秀 | 特征空间距离更近 |
| FID | ⚠️ 未超过PPAMI | PPAMI使用StyleGAN多样性更高 |
| **LPIPS** | ✅ **最优** | 感知相似度最高 |

#### 性能分析

**FGMIA的核心优势**：
- ✅ **交叉评估准确率大幅提升** - 表明生成样本真正代表目标类别，而非仅适配目标模型
- ✅ **感知相似度最高** - 视觉质量最接近私有数据
- ✅ **特征聚类距离最近** - 生成样本在特征空间中最接近私有数据

**FID指标分析**：
- PPAMI使用StyleGAN生成多样性高但相似度低的图像
- FGMIA专注于生成高相似度的代表性样本
- 在相同目标准确率下，FGMIA的评估准确率和感知相似度均优于PPAMI

**可视化验证**（图4、图5、图6）：
- **图4**: 生成样本可视化，FGMIA生成的样本视觉质量最佳
- **图5**: 余弦相似度热图，FGMIA在评估模型下表现最优
- **图6**: t-SNE聚类图，FGMIA生成样本与私有数据聚类最近

---

## 实验二：不同网络深度实验（表II）

### 实验设置
- **目标模型**: CosFace和ArcFace（18/34/50/100层）
- **辅助数据集**: CelebA-Mini1
- **生成样本数**: 每类16张

### 实验结果

| 网络深度 | 模型 | Target Acc | Eval Acc | KNN | FID | LPIPS |
|---------|------|-----------|----------|-----|-----|-------|
| 18层 | CosFace-18 | - | - | - | - | - |
| 34层 | CosFace-34 | - | - | - | - | - |
| 50层 | CosFace-50 | - | - | - | - | - |
| 100层 | CosFace-100 | - | - | - | - | - |
| 18层 | ArcFace-18 | - | - | - | - | - |
| 34层 | ArcFace-34 | - | - | - | - | - |
| 50层 | ArcFace-50 | - | - | - | - | - |
| 100层 | ArcFace-100 | - | - | - | - | - |

*注：PDF中表格数值未清晰提取，但文中描述了以下关键结论*

### 关键发现

1. ✅ **所有网络深度均保持良好攻击性能** - 方法具有广泛适用性
2. ✅ **网络深度与攻击性能无强相关** - 攻击不依赖特定网络深度
3. ✅ **更深网络的评估准确率略有提升** - 深层网络提取的特征语义信息更丰富
4. 📌 **归因分析**: 更深网络能提取更复杂的特征表示，为特征引导提供更好的语义信息

---

## 实验三：微调模型影响实验（表III）

### 实验设置
- **基础模型**: CosFace-18、ArcFace-18
- **微调设置**: 每个模型进行4次完整微调，共8个微调模型
- **私有数据**: CelebA-Mini2
- **辅助数据集**: CelebA-Mini1
- **生成样本数**: 每类16张

### 实验结果

| 模型 | 微调轮次 | Target Acc | Eval Acc | KNN | FID | LPIPS | 备注 |
|-----|---------|-----------|----------|-----|-----|-------|------|
| CosFace-18 | Fine-tune 1 | - | >70% | - | - | - | 基准 |
| CosFace-18 | Fine-tune 2 | - | >70% | - | - | - | 轻微下降 |
| CosFace-18 | Fine-tune 3 | - | >70% | - | - | - | 持续下降 |
| CosFace-18 | Fine-tune 4 | - | >70% | - | - | - | 最大下降 |
| ArcFace-18 | Fine-tune 1 | - | >70% | - | - | - | 基准 |
| ArcFace-18 | Fine-tune 2 | - | >70% | - | - | - | 轻微下降 |
| ArcFace-18 | Fine-tune 3 | - | >70% | - | - | - | 持续下降 |
| ArcFace-18 | Fine-tune 4 | - | >70% | - | - | - | 最大下降 |

### 关键发现

1. ✅ **评估准确率保持在70%以上** - 即使微调后仍保持有效攻击能力
2. ⚠️ **性能随微调程度略有下降** - 微调轮次越多，性能下降越明显
3. 📌 **下降原因**:
   - 目标模型特征提取逐渐偏向私有数据特征
   - 过拟合导致特征分布发生变化
   - 方法通常利用的细微信号被削弱
4. ✅ **鲁棒性验证**: 即使在过拟合情况下，方法仍保持70%以上准确率

---

## 实验四：分布偏移数据集实验（表IV & V）

### 实验设置
- **目标模型**: CosFace（18/34/50/100层）
- **私有数据**: CelebA-Mini2
- **辅助数据集**:
  - FFHQ-128（高质量人脸，分布偏移）
  - VGGFace2-Mini（多姿态多年龄，分布偏移）
- **对比基准**: CelebA-Mini1（相似分布）

### 表IV：FGMIA在分布偏移下的性能

| 目标模型 | 辅助数据集 | Target Acc | Eval Acc | KNN | FID | LPIPS | 趋势 |
|---------|-----------|-----------|----------|-----|-----|-------|------|
| CosFace-18 | CelebA-Mini1 | - | - | - | - | - | 基准 |
| CosFace-18 | FFHQ-128 | - | - | - | - | - | 轻微波动 |
| CosFace-18 | VGGFace2-Mini | - | - | - | - | - | 轻微波动 |
| CosFace-34 | CelebA-Mini1 | - | - | - | - | - | 基准 |
| CosFace-34 | FFHQ-128 | - | - | - | - | - | 轻微波动 |
| CosFace-34 | VGGFace2-Mini | - | - | - | - | - | 轻微波动 |
| CosFace-50 | CelebA-Mini1 | - | - | - | - | - | 基准 |
| CosFace-50 | FFHQ-128 | - | - | - | - | - | 轻微波动 |
| CosFace-50 | VGGFace2-Mini | - | - | - | - | - | 轻微波动 |
| CosFace-100 | CelebA-Mini1 | - | - | - | - | - | 基准 |
| CosFace-100 | FFHQ-128 | - | - | - | - | - | 轻微波动 |
| CosFace-100 | VGGFace2-Mini | - | - | - | - | - | 轻微波动 |

### 表V：不同方法在分布偏移下的对比（ArcFace模型）

| 方法 | 辅助数据集 | Target Acc | Eval Acc | KNN | FID | LPIPS | 影响程度 |
|-----|-----------|-----------|----------|-----|-----|-------|---------|
| GMI | CelebA-Mini1 | - | - | - | - | - | 基准 |
| GMI | FFHQ-128 | - | - | - | - | - | 显著下降 |
| GMI | VGGFace2-Mini | - | - | - | - | - | 显著下降 |
| PPAMI | CelebA-Mini1 | - | - | - | - | - | 基准 |
| PPAMI | FFHQ-128 | - | - | - | - | - | 显著下降 |
| PPAMI | VGGFace2-Mini | - | - | - | - | - | 显著下降 |
| Diff-MI | CelebA-Mini1 | - | - | - | - | - | 基准 |
| Diff-MI | FFHQ-128 | - | - | - | - | - | 中等下降 |
| Diff-MI | VGGFace2-Mini | - | - | - | - | - | 中等下降 |
| **FGMIA** | CelebA-Mini1 | - | - | - | - | - | 基准 |
| **FGMIA** | FFHQ-128 | - | - | - | - | - | **轻微波动甚至提升** |
| **FGMIA** | VGGFace2-Mini | - | - | - | - | - | **轻微波动** |

### 关键发现

1. ✅ **FGMIA对分布偏移具有更强鲁棒性**
   - GAN方法受分布偏移影响显著
   - FGMIA受影响较小，某些配置下性能反而提升

2. ✅ **高质量数据集可能提升性能**
   - 使用FFHQ-128时，某些配置性能优于基准
   - 数据质量对扩散模型更重要

3. 📌 **性能不一定下降**
   - 分布偏移引入系统性偏差
   - 但可能增强模型泛化能力
   - 特征编码引导在某些配置下改善验证性能

4. ✅ **风格差异不影响相似度**
   - 图7可视化显示：不同辅助数据集产生不同风格
   - 但代表性样本与私有图像保持强相似性

### 可视化分析（图7）

**实验设置**: 使用CosFace-50作为目标模型

| 辅助数据集 | 生成风格特征 | 相似度保持 |
|-----------|------------|----------|
| CelebA-Mini1 | 标准CelebA风格 | 高度相似 |
| FFHQ-128 | 高清真实感风格 | 高度相似 |
| VGGFace2-Mini | 多角度多场景风格 | 高度相似 |

---

## 实验五：消融研究（表VI）

### 实验设置
- **目标模型**: IR152（闭集分类模型）
- **测试组件**:
  - **FG** (Feature Guidance): 特征引导
  - **TransF** (Transform Features): 特征转换
  - **ScaleFT** (Scale Features): 特征缩放

### 实验配置

| 配置 | FG | TransF | ScaleFT | 说明 |
|-----|----|----|---------|------|
| **FGMIA (完整)** | ✅ | ✅ | ✅ | 所有组件启用 |
| **no-FG** | ❌ | ✅ | ✅ | 移除特征引导，使用输出logits |
| **no-TransF** | ✅ | ❌ | ✅ | 移除特征转换 |
| **no-ScaleFT** | ✅ | ✅ | ❌ | 直接使用TransF输出，不缩放 |

### 实验结果

| 配置 | Target Acc | Eval Acc | KNN | FID | LPIPS | 性能影响 |
|-----|-----------|----------|-----|-----|-------|---------|
| **FGMIA (完整)** | - | - | - | - | - | 基准 |
| **no-FG** | ⬇️ | ⬇️⬇️ | ⬇️⬇️ | ⬆️ | ⬇️⬇️ | 严重下降 |
| **no-TransF** | ⬇️ | ⬇️ | ⬇️ | ⬆️ | ⬇️ | 中等下降 |
| **no-ScaleFT** | ⬇️ | ⬇️ | ⬇️ | ⬆️ | ⬇️ | 轻微下降 |

*注：⬇️表示性能下降，⬆️表示性能上升（FID越低越好）*

### 各组件贡献分析

#### 1. FG（特征引导）组件
- **作用**: 使扩散模型学习特征编码中的语义信息
- **影响**:
  - 移除后评估准确率和KNN距离严重下降
  - 感知相似度显著降低
  - **结论**: 核心组件，直接决定攻击效果

#### 2. TransF（特征转换）组件
- **作用**: 将MLP分类器转换为特征矩阵，映射到特征编码方向
- **背景**:
  - 开集模型（ArcFace）使用L2归一化特征+余弦相似度
  - 闭集模型特征缺乏L2超球面的良好语义分布
- **影响**:
  - 移除后性能中等下降
  - 特征空间对齐能力减弱
  - **结论**: 对闭集模型至关重要

#### 3. ScaleFT（特征缩放）组件
- **作用**: 将TransF输出映射回原始特征空间
- **影响**:
  - 移除后性能轻微下降
  - 细化代表性特征
  - 增强攻击结果与目标类别对齐
  - **结论**: 优化组件，提升最终性能

### 消融研究结论

1. **三个组件协同工作** - 完整FGMIA性能最优
2. **FG是核心** - 特征引导是方法的基础
3. **TransF关键** - 闭集模型必需的转换步骤
4. **ScaleFT优化** - 进一步提升性能的细化步骤

---

## 计算效率对比

### 训练阶段

| 项目 | 配置/数值 |
|-----|---------|
| 硬件 | 单张NVIDIA 4090 GPU |
| 模型架构 | UNet（6个下采样-上采样模块） |
| 参数量 | 100M |
| 图像尺寸 | 112×112 |
| Batch Size | 16 |
| 训练时长 | 1-2天（100-150 epochs） |
| 优化器 | AdamW（学习率1e-4） |
| 优化步数 | 300K-500K步 |
| 学习率调度 | 余弦退火 |
| 辅助图像数 | 约30,000张 |

### 攻击阶段

| 项目 | FGMIA | 迭代优化方法（GMI/PPAMI） |
|-----|-------|--------------------------|
| 采样步数 | 50步（快速采样） | 数千次迭代 |
| 目标查询次数 | 30,000次 | 数十万次 |
| 生成1000类时间 | **5分钟** | 数小时 |
| 优化要求 | 无需迭代优化 | 需要梯度优化 |

### 效率优势

1. ✅ **攻击阶段极快** - 1000个类别仅需5分钟
2. ✅ **查询次数少** - 30K次 vs 数十万次
3. ✅ **无需迭代优化** - 直接生成，避免非平滑优化
4. ✅ **训练一次，多次使用** - 训练后可快速攻击多个类别

---

## 方法对比总结

### 技术路线对比

| 方法类型 | 代表方法 | 生成模型 | 优化方式 | 优点 | 缺点 |
|---------|---------|---------|---------|------|------|
| **基于GAN迭代优化** | GMI, PPAMI, IF-GMI | StyleGAN | 梯度优化潜变量 | 生成质量高 | 优化不平滑，耗时长 |
| **基于扩散模型迭代优化** | Diff-MI | DDPM | 梯度优化中间状态 | 比GAN更稳定 | 仍需迭代优化 |
| **基于条件生成** | PLG | cGAN | 伪标签条件 | 减少优化 | 依赖伪标签质量 |
| **特征引导扩散（本文）** | FGMIA | 特征引导DDPM | 直接条件生成 | 无需迭代，特征语义强 | 需要白盒访问 |

### 性能总结

| 评估维度 | FGMIA表现 | 排名 |
|---------|----------|------|
| 目标准确率 | 与PPAMI、Diff-MI相当 | 🥇 第一梯队 |
| **交叉评估准确率** | **显著优于所有方法** | 🥇 **第一名** |
| KNN距离 | 最接近私有数据 | 🥇 第一名 |
| FID分数 | 未超过PPAMI | 🥈 第二名 |
| **LPIPS感知相似度** | **最高** | 🥇 **第一名** |
| 计算效率 | 攻击阶段最快 | 🥇 第一名 |
| 分布偏移鲁棒性 | 最强 | 🥇 第一名 |

### 核心创新点

1. ✅ **重新定义MIA问题** - 从迭代优化转为条件数据分布学习
2. ✅ **特征引导扩散模型** - 充分利用目标模型隐含的特征编码
3. ✅ **直接生成策略** - 避免非平滑优化问题
4. ✅ **语义信息利用** - 学习特征编码的语义信息而非仅拟合输出

---

## 局限性与未来工作

### 当前局限性

| 局限性 | 说明 | 影响 |
|-------|------|------|
| **白盒设置** | 需要完整访问模型参数和结构 | 实际应用受限 |
| **属性变化** | 生成样本可能改变发型、发色、肤色 | 细节还原不完美 |
| **黑盒性能差** | 使用独立主干网络的黑盒方案效果不佳 | 无法适应常见黑盒场景 |

### 未来研究方向

1. 🎯 **黑盒场景适配** - 探索无需访问模型参数的攻击方法
2. 🎯 **属性保持增强** - 提升细节属性（发型、发色、肤色）的保真度
3. 🎯 **防御机制研究** - 开发针对特征引导攻击的防御方法
4. 🎯 **其他领域扩展** - 将方法推广到其他生物识别领域

---

## 实验数据质量评估

### 实验设计优势

1. ✅ **全面的对比实验** - 8种方法，5个目标模型
2. ✅ **多维度评估** - 5个评估指标，3种可视化
3. ✅ **鲁棒性验证** - 不同网络深度、微调程度、数据分布
4. ✅ **消融研究完整** - 验证各组件贡献
5. ✅ **效率分析详细** - 训练和攻击阶段均有量化

### 实验可信度

- ✅ 使用公开数据集和预训练模型
- ✅ 遵循前人工作的实验设置
- ✅ 提供代码开源（https://github.com/MMCTTT/FGMIA_codes）
- ✅ 详细的可视化验证
- ✅ 交叉验证和多模型评估

---

## 关键数据汇总

### 最佳性能指标（基于文中描述）

| 指标 | FGMIA | 最佳对比方法 | 提升 |
|-----|-------|------------|------|
| 交叉评估准确率 | **显著最优** | Diff-MI/PPAMI | 显著提升 |
| 感知相似度(LPIPS) | **最高** | - | 最优 |
| 特征空间距离(KNN) | **最近** | - | 最优 |
| 攻击时间(1000类) | **5分钟** | 数小时 | 数十倍 |
| 分布偏移鲁棒性 | **最强** | - | 最优 |

### 适用场景

| 场景 | 适用性 | 说明 |
|-----|-------|------|
| 白盒攻击 | ✅ 优秀 | 核心应用场景 |
| 闭集模型 | ✅ 优秀 | 需要TransF组件 |
| 开集模型 | ✅ 优秀 | 直接使用特征 |
| 深层网络 | ✅ 优秀 | 性能略有提升 |
| 浅层网络 | ✅ 良好 | 性能稳定 |
| 相似分布 | ✅ 优秀 | 最佳场景 |
| 分布偏移 | ✅ 良好 | 鲁棒性强 |
| 微调模型 | ✅ 良好 | >70%准确率 |
| 黑盒攻击 | ❌ 较差 | 主要局限性 |

---

## 结论

**FGMIA方法通过将模型逆向攻击重新定义为条件数据分布学习任务，并创新性地使用特征引导的扩散模型，在多个评估维度上实现了对现有最先进方法的超越，特别是在交叉评估准确率、感知相似度、计算效率和鲁棒性方面表现突出。该方法为模型逆向攻击研究提供了新的思路，同时也为人脸识别系统的隐私保护提出了新的挑战。**

---

**文档生成时间**: 2025年12月21日
**基于论文**: IEEE TIFS 2025, DOI: 10.1109/TIFS.2025.3592542
**代码开源**: https://github.com/MMCTTT/FGMIA_codes
