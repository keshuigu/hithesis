% !Mode:: "TeX:UTF-8"

\hitsetup{
  %******************************
  % 注意：
  %   1. 配置里面不要出现空行
  %   2. 不需要的配置信息可以删除
  %******************************
  %
  %=====
  % 秘级
  %=====
  statesecrets={公开},
  natclassifiedindex={TM301.2},
  intclassifiedindex={62-5},
  %
  %=========
  % 中文信息
  %=========
  ctitleone={局部多孔质气体静压},%本科生封面使用
  ctitletwo={轴承关键技术的研究},%本科生封面使用
  ctitlecover={面向人脸识别模型的逆向重建方法研究},%放在封面中使用，自由断行
  ctitle={面向人脸识别模型的逆向重建方法研究},%放在原创性声明中使用
  % csubtitle={一条副标题}, %一般情况没有，可以注释掉
  cxueke={工学},
  csubject={网络空间安全},
  caffil={计算学部},
  cauthor={俞磊},
  csupervisor={王莘},
  % cassosupervisor={某某某教授}, % 副指导老师
  % ccosupervisor={某某某教授}, % 联合指导老师
  % 如果是第一封面的日期要手动设置，需要取消注释下一行，并将内容改为“规范”中要求的封面第一页最下方的日期
  % firstpagecdate={2022年6月},
  % 日期自动使用当前时间，若需指定按如下方式修改：
  % cdate={超新星纪元},
  cstudentid={9527},
  cstudenttype={学术学位论文}, %非全日制教育申请学位者
  cnumber={no9527}, %编号
  cpositionname={哈铁西站}, %博士后站名称
  cfinishdate={20XX年X月---20XX年X月}, %到站日期
  csubmitdate={20XX年X月}, %出站日期
  cstartdate={3050年9月10日}, %到站日期
  cenddate={3090年10月10日}, %出站日期
  %（同等学力人员）、（工程硕士）、（工商管理硕士）、
  %（高级管理人员工商管理硕士）、（公共管理硕士）、（中职教师）、（高校教师）等
  %
  %
  %=========
  % 英文信息
  %=========
  etitle={Inverse Reconstruction Methods for Face Recognition Models},
  % esubtitle={This is the sub title},
  exueke={Engineering},
  esubject={Cyberspace Security},
  eaffil={\emultiline[t]{Faculty of Computing}},
  eauthor={Lei Yu},
  esupervisor={Prof. Shen Wang},
  % eassosupervisor={XXX},
  % 日期自动生成，若需指定按如下方式修改：
  % edate={December, 2017},
  estudenttype={Master of Engineering},
  %
  % 关键词用“英文逗号”分割
  ckeywords={人脸识别, 模板逆向攻击, 模型反演, 扩散生成模型, 隐私泄露},
  ekeywords={face recognition, template inversion attack, model inversion attack, diffusion models, privacy leakage},
}
  % 关键词是为了文献标引工作、用以表示全文主要内容信息的单词或术语。关键词不超过 5
  % 个，每个关键词中间用分号分隔。（模板作者注：关键词分隔符不用考虑，模板会自动处
  % 理。英文关键词同理。）
\begin{cabstract}
随着深度学习技术的快速发展，人脸识别系统已在身份认证、访问控制等关键领域广泛部署。然而，系统在实现高识别性能的同时，不可避免地在特征表示与模型输出中暴露了与原始图像高度相关的语义信息，为隐私攻击提供了可能。本文针对人脸识别系统面临的隐私泄露风险，系统研究了模板反演攻击与模型反演攻击两类典型威胁，提出了基于扩散模型的高效逆向重建方法。

本文建立了攻击的形式化框架，明确了攻击者的知识边界与能力假设。针对模板反演攻击，提出了基于明晰扩散模型的方法，通过角度约束特征匹配对齐ArcFace的超球面特征空间，引入任务不确定性加权框架自动平衡像素去噪与特征感知的协同优化，并采用多样性正则化防止特征空间崩塌。针对模型反演攻击，本文首次将换脸模型的身份解耦能力引入该任务，通过标签条件嵌入层将类别标签映射为512维身份向量，采用低秩适配技术仅需微调约1\%的参数即可实现对目标分类器决策边界的精确匹配，并采用渐进式三阶段训练策略实现从图像到标签的平滑模态迁移。

实验结果表明，模板反演方法在LFW数据集上于误识率$10^{-3}$阈值下攻击成功率达到98.50\%，相比现有方法GaFaR提升6.33个百分点。消融实验证实角度约束、任务不确定性加权和多样性正则化使攻击成功率进一步提升至99.67\%。模型反演方法在VGGFace2数据集上训练的多种分类器架构上均取得了稳定的性能，FID值降低至23.82到28.16，相比PLG-MI降低约28\%。三阶段训练策略使攻击准确率从单阶段的62.47\%提升至93.47\%，LoRA配置$r=16$在仅训练0.18\%参数的情况下达到接近全参数微调的性能。研究成果系统揭示了人脸识别系统在特征表示与模型输出层面的隐私脆弱性，为理解和评估人脸识别系统的隐私风险提供了理论基础与技术支撑。
\end{cabstract}

\begin{eabstract}
With the rapid development of deep learning, face recognition systems have been widely deployed in critical domains. However, these systems inevitably expose semantic information in feature representations and model outputs, providing opportunities for privacy attacks. This dissertation investigates template inversion attack and model inversion attack, proposing efficient inverse reconstruction methods based on diffusion models.

This dissertation establishes a formalized framework clarifying the knowledge boundaries and capabilities of attackers. For template inversion attack, a method based on Elucidating Diffusion Models (EDM) is proposed, which aligns with ArcFace's hyperspherical feature space through angle-constrained feature matching, introduces task uncertainty weighting to balance pixel denoising and feature perception, and employs diversity regularization. For model inversion attack, this dissertation pioneers the application of face-swapping models' identity disentanglement capability by designing a label-conditioned embedding layer, using Low-Rank Adaptation (LoRA) to match target classifier decision boundaries with only 1\% parameters, and adopting a progressive three-stage training strategy.

Experimental results show that the template inversion method achieves 98.50\% attack success rate at FMR=$10^{-3}$ on LFW dataset, improving by 6.33 percentage points over GaFaR, with ablation experiments confirming further improvement to 99.67\%. The model inversion method achieves FID values of 23.82-28.16, approximately 28\% lower than PLG-MI. The three-stage training strategy improves attack accuracy from 62.47\% to 93.47\%, and LoRA configuration $r=16$ achieves near full-parameter performance with only 0.18\% parameters. The research reveals privacy vulnerabilities of face recognition systems and provides theoretical foundation for understanding privacy risks.
\end{eabstract}
