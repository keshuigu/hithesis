% !Mode:: "TeX:UTF-8"

\chapter{绪论}[Introduction]
\section{课题背景及研究的目的和意义}

近年来，随着深度学习技术的迅速发展，人脸识别模型的性能显著提升，已广泛应用于身份认证、公共安全、金融支付和社交媒体等领域。在实际应用中，人脸识别系统承担着多样的任务，主要可概括为验证、识别/检索与鉴权/访问控制三类典型功能。验证任务是判定两张人脸是否属于同一主体，通常以一对一比对为主；识别/检索任务则对给定的查询图像在大量登记模板中进行一对多比对以输出最可能的身份或候选列表；鉴权任务常用于门禁、支付等场景，以快速判断是否授予权限。这些任务在工程实现上依赖于将像素级输入 $x$ 映射为低维的特征向量或模板 $e = f(x)$ ，即对人脸图像的有效中间表示，并据此通过相似性度量或分类决策来完成最终判定。从系统实现角度出发，目前主流的人脸识别架构可根据输出与接口的不同大致分为两类：一类是以特征提取结合模板匹配为核心的检索型体系，该类系统在登记阶段为每个身份保存一个或多个特征模板 $t_i$ ，在识别阶段通过计算相似性度量 $sim(e,t_i)$ 实现快速检索与阈值判定，因而天然适合大规模、开放集的场景（如人群查找与大规模身份库检索）；另一类是将分类头直接接在特征提取器之上的端到端分类体系，模型输出为预定义类别集合上的概率分布或标签，适用于封闭集和固定身份数量的应用（例如企业人员考勤、设备解锁等），其训练目标常以交叉熵损失优化分类性能。两者在工程约束、扩展性与安全隐私方面各有取舍：模板匹配型易于扩展与进行近似最近邻索引，但其长期存储的模板若被泄露将带来直接的身份重建风险；分类型在样本量充足时能取得更高的分类准确率，但在开放集或不断增量的身份场景下维护成本更高，且模型输出的置信信息可能被滥用以进行模型反演。

现有研究表明：当攻击者能够获取到模型参数、查询接口输出的置信信息或识别系统中长期保存的特征模板时，可通过优化或生成模型等技术，将这些中间表示逆向映射为近似的像素级图像，从而恢复用户面部信息并造成隐私泄露与安全风险（例如身份伪造、越权访问等）。

为便于后文讨论，下面给出两类常见逆向重建攻击的规范定义：

模板逆向重建（Template Inversion Attack, TIA）：指在攻击者已获得人脸识别系统中存储的特征模板或嵌入向量（例如 $t=f(x_0)$）的情形下，试图将该低维表示映射回具有辨识性的像素级人脸图像。实现途径通常包括：（1）基于优化的方法：以最大化生成图像在目标识别模型嵌入空间上与模板相似度为目标，通过迭代优化直接搜索像素或潜在变量；（2）基于学习的方法：训练条件生成模型（例如条件 GAN 或隐空间扩散模型），学习从嵌入或条件向量到图像的逆映射以进行批量生成。相关工作表明，特征逆映射能够在一定程度上恢复面部结构与身份相关属性，对长期存储的模板构成现实威胁\cite{Mahendran_2015_CVPR,Dosovitskiy_2016_CVPR}。

模型反演攻击（Model Inversion Attack, MIA）：泛指攻击者借助对目标模型的访问（白盒或黑盒查询），利用输出置信度、概率分布或模型参数等信息，通过优化、统计推断或生成模型重建训练数据的近似样本或推断敏感属性。经典工作指出，在模型返回丰富置信信息的情况下，攻击者可以还原出与训练样本相似的输入或敏感属性；后续研究将生成模型与分数/分类器引导相结合，显著提高了重建图像的感知质量与识别性\cite{fredrikson2015model,hoDenoisingDiffusionProbabilistic2020,rombachHighResolutionImageSynthesis2022}。

从方法论角度看，现有逆向重建研究大致可分为两类路线：基于优化/梯度的显式反演与基于生成模型的学习式反演。前者可在信息充分（如白盒或可获梯度）时实现精细匹配；后者则借助条件化生成能力在信息受限（如仅有模板或有限查询）时生成更具感知质量的候选样本。尤其是近年来隐空间扩散（LDM）与分数匹配方法在高分辨率图像生成上的成功，为在保持视觉保真度的同时实现识别级别一致性的逆向重建提供了有力工具，并成为研究热点\cite{songScoreBasedGenerativeModeling2021,hoDenoisingDiffusionProbabilistic2020,rombachHighResolutionImageSynthesis2022}。


基于以上背景，本文旨在系统研究因特征模板或模型输出暴露引发的逆向重建与隐私风险问题，并提出可复现、工程可行的缓解策略。具体目标包括：
\begin{itemize}
  \item 系统化刻画模板逆向与模型反演的威胁模型与评估指标，明确白盒、半白盒、黑盒以及仅模板等常见攻击假设下的可行策略与局限；
  \item 提出基于隐空间扩散与分数/分类器引导的高质量模板逆向重建框架，旨在在保持视觉保真度的前提下最大化生成样本与目标嵌入的一致性；
  \item 设计参数高效的微调与采样优化方法（例如两阶段一致性微调、LoRA 低秩注入与采样修正），以显著降低训练与部署成本并提高方法的稳健性；
  \item 构建统一且可复现的评估体系，覆盖嵌入相似度、识别/验证成功率（TAR@FAR）、感知质量（FID、LPIPS）及计算开销，并在多个公开数据集与典型识别模型上开展广泛对比实验；
  \item 评估常见防御手段（如模板保护、差分隐私、特征裁剪等）的有效性与代价，并给出工程化部署建议与风险缓解方案。
\end{itemize}

综上所述，本课题兼具理论与实践价值：一方面，通过系统的威胁建模与量化评估，将加深对模板与中间表示泄露机制的理解，为隐私风险评估提供科学依据；另一方面，所提出的高质量重建框架与参数高效适配策略将为攻防双方提供可复现的技术方法与工程建议，有助于推动在不显著损失识别性能的前提下实现更可靠的隐私保护。研究过程中将严格遵循伦理与合规要求，优先使用公开数据集并在论文与代码库中公开复现说明与风险缓解指导。

\section{国内外研究现状及分析}

近年来，随着深度学习在视觉识别领域的广泛应用，研究者逐步揭示了中间表示与模型输出所蕴含的隐私风险。早期工作针对局部描述子和手工特征证明了从低层信息恢复原始图像的可行性，进而促使学者们将视角拓展到以深度特征为代表的现代识别系统：研究表明通过梯度反传、优化求解或学习式逆映射，可以在一定程度上从深度嵌入中恢复出具有辨识性的面部图像，从而暴露个人隐私\cite{5995616,Mahendran_2015_CVPR,Dosovitskiy_2016_CVPR}。与此同时，生成模型的发展为高质量重建提供了有力工具，基于生成对抗网络的条件生成方法能够在像素域生成逼真样本，而扩散模型及其隐空间变体凭借更稳定的训练机制和更优的样本质量，近年来被逐步引入到逆向重建与模型反演研究中，显示出在保持视觉保真度与特征一致性方面的显著潜力\cite{hoDenoisingDiffusionProbabilistic2020,songScoreBasedGenerativeModeling2021,rombachHighResolutionImageSynthesis2022}。

关于攻击假设与适用场景，现有工作普遍以白盒、黑盒及介于两者之间的条件划分：白盒情形下攻击者可利用模型参数和梯度信息进行精确优化；黑盒情形下则依赖查询接口或输出置信信息开展重建试探；而在仅获得嵌入向量或相似度分数的中度可见情形，生成模型常作为补偿手段用于构造候选图像。开创性研究进一步指出，即便仅暴露置信度或部分输出信息，也足以导致严重的信息泄露，这对实际部署提出了重要警示\cite{fredrikson2015model}。为在计算资源受限的场景下提高重建效率与可用性，参数高效的微调方法（如 LoRA）被提出用于将大型生成模型快速适配至特定反演任务，从而在降低训练与存储开销的同时保持较好的生成性能\cite{hu2021loralowrankadaptationlarge}。

在评估与防御方面，逆向重建研究通常采用特征相似度（嵌入空间的余弦或欧氏距离）、识别/验证成功率以及图像质量度量（FID、LPIPS 等）作为主要量化指标，并以公开人脸数据集作为实验基准以保证可比性\cite{9393327}。为缓解信息泄露风险，学界提出了包括模板保护与加密、差分隐私噪声注入、特征扰动与裁剪、以及局部差分隐私机制等多类防御手段，但这些防御通常会在一定程度上影响识别性能，而且在面对基于高保真生成模型的现代攻击时，其有效性和鲁棒性仍需进一步验证\cite{Pittaluga_2023_ICCV,Qin2014TowardsEP,SUN2020102642}。

综上可见，尽管已有研究在理论与实践上证明了模板与中间表示的泄露风险，并提供了多种重建与防御方法，但仍存在若干未被充分解决的问题：评估协议与攻击假设缺乏统一性导致结果难以比较；在资源受限条件下如何系统地利用参数高效微调以提高重建器性能尚缺乏研究；将判别性或分类器分数直接引入扩散模型驱动的重建过程以增强特征一致性的技术路线仍有待深入；以及防御-攻击的对抗性评估在高保真生成背景下尚不完善。基于上述认识，本研究拟以隐扩散为基础，结合判别/分数引导与 LoRA 类微调策略，构建兼顾重建质量与计算效率的模板逆向重建框架，并在统一的评估体系下对其有效性与防御策略进行系统比较与分析。


目前有三个主流的图像生成模型研究方向，分别是基于似然的模型，生成对抗网络以及基于能量的模型\cite{luoUnderstandingDiffusionModels2022}。
基于似然的模型，主要目标是学习为观察到的数据样本分配高似然的模型，代表的模型有自回归模型、流模型和变分自动编码器。
生成对抗网络模型中一般包括判别器和生成器共同运行，其中生成器根据隐空间采样数据生成一个图像，判别器则用于区分生成的图像与原始的图像。训练过程中，生成器和判别器的相互对抗，生成器所学习到的分布逐渐靠近原始图像分布。
基于能量的模型又称扩散模型，扩散模型一般由前向扩散过程和反向生成过程组成。其中前向扩散过程将图像逐步添加噪声直至变成随机噪声，反向生成过程则将随机噪声逐步去除噪声直至生成图像数据。
\par
在基于似然的模型方面，Kingma\cite{kingmaAutoEncodingVariationalBayes2022}等人提出了变分自编码器(Variational Auto-Encoder, VAE)模型，通过变分贝叶斯方法，将对原始图像数据的负对数似然的建模优化转为变分下界的计算。VAE模型包含编码器和解码器，其中编码器将原始图像映射到隐变量，解码器从采样的隐变量重建原始图像。
Sohn\cite{sohnLearningStructuredOutput2015}等人在VAE的基础上提出了条件变分自编码器(Conditional Variational Auto-Encoder, CVAE) 模型，其在VAE的基础上，引入条件概率，使得在生成时能够按照标签条件生成。VAE与CVAE的区别在于数据产生方式，VAE是从隐变量采样后使用网络生成图像数据，而CVAE使用标签采样隐变量，再使用网络生成图像数据。
Van\cite{vandenoordNeuralDiscreteRepresentation2017}等人提出了向量量化变分自编码器(VectorQuantisation Variational Auto-Encoder, VQ-VAE)，其在VAE基础上，采用了离散的隐变量，并单独训练一个自回归模型来学习隐变量的先验分布。相比于原始的VAE，VQ-VAE采用了离散编码，并且用了两阶段来生成，让隐变量的先验分布从高斯分布变成可学习的分布，提升了模型的学习能力。
\par
生成对抗模型(Generative Adversarial Networks, GAN)是由Goodfellow\cite{goodfellowGenerativeAdversarialNetworks2014}等人提出。这类模型主要是通过一个生成器G和一个判别器D的双方博弈完成训练。对于判别器而言，其优化期望能区分输入图像是生成图像的概率；对于生成器而言，其优化期望是能生成判别器难以分辨真伪的图像。
Arjovsky\cite{arjovskyWassersteinGAN2017}等人提出WGAN(Wasserstein GAN,WGAN)模型，该文献认为原始GAN模型的损失函数中使用的对称的JS散度不能很好体现两个分布之间的差距，使得在初始阶段分布差距过大时难以训练，而KL散度对生成器训练阶段的多样性与真实性的惩罚贡献不均衡，使得模型发生模式崩溃而难以生成多样性的样本。这项工作中使用了Wasserstein距离代替了JS散度，解决训练稳定性问题。
Esser\cite{esserTamingTransformersHighResolution2021}等人在VQ-VAE的基础上，将其隐变量生成器从pixelCNN换成了Transformer，并且在训练过程中加入使用PatchGAN的判别器以及对抗损失。通过使用Transformer做离散编码的生成器，隐变量的预测过程可以被视作自回归预测。经实验，VQGAN可以很好的完成高分辨图像的生成任务。
\par
在扩散模型方面，Ho\cite{hoDenoisingDiffusionProbabilistic2020}等人提出了第一个正式的去噪扩散模型(Denoising Diffusion Probabilistic Models, DDPM)，其包含一个前向的扩散过程和一个反向的生成过程。前向扩散过程中，将原始图像数据按马尔可夫过程据逐步添加随机噪声，最终变成纯随机噪声；在反向生成过程中，将噪声数据每次去噪并采样，逐步恢复原始数据。DDPM对整个扩散生成过程建模，经过优化将问题转变为预测每一步的随机噪声，并采用神经网络对噪声预测拟合。
Song\cite{songGenerativeModelingEstimating2019}等人提出了条件噪声得分网络(Noise-Conditional Score Networks, NCSN)，其主要思路为分数匹配方法来估算数据分布的分数函数，并通过朗之万动力学采样实现采样生成。由于数据位于高维空间中的低维流行上，难以估计分数函数，则该文献提出了使用不同程度的噪声对其扰动，并联合估计分数函数。该工作可以视为DDPM扩散模型的另一种解释。
Song\cite{songScoreBasedGenerativeModeling2021}等人针对扩散模型，提出了Score SDE框架统一并且解释了扩散模型。该文献从分数匹配与能量模型角度，提出了基于随机微分方程(StochasticDifferentialEquations, SDE) 的去噪分数匹配模型。不同于DDPM的离散形式，使用随机微分方程建模的ScoreSDE是连续形式，正向过程通过SDE求解来注入噪声，将图像数据分布转换到已知的先验分布，并使用神经网络模型学习分数，反向过程通过预测并修正的采样方案，最终将噪声去除并从先验分布转换到数据分布。该文献不仅提出模型，并且将以往的DDPM模型和基于得分匹配朗之万动力学模型都统一使用SDE模型表达，实现了对扩散模型的解释与统一。
Rombach\cite{rombachHighResolutionImageSynthesis2022}等人提出了隐扩散模型 LDM(Latent Diffusion Models, LDM)，因以往的扩散模型直接在图像空间扩散与训练，对计算资源、运算时间消耗大，LDM在隐空间作扩散训练，通过预训练的自编码模型来实现对图像像素空间与隐空间的转换。其中还内嵌条件生成机制，可以在模型中引入多种形态的条件机制，如文本、标签、语音、图像等条件信息。经过实验，其在图像生成、超分辨率、图像修复等诸多下游任务都有很好的表现。
\par
除了以上三类模型，在条件生成模型方面，还有不少工作取得了效果显著的成果。Radford \cite{pmlr-v139-radford21a}等提出文图对比预训练模型CLIP(Contrastive Language-Image Pre-training, CLIP)，为基于对比学习的多模态模型。该模型使用文本编码器和图像编码器，将文本与图像编码到相似的隐空间中。该文献打通了文本与图像的隔阂，将两者统一起来，后续许多工作的研究都采用了 CLIP 的引导实现的文生图与图生图功能。
Ramesh \cite{pmlr-v139-ramesh21a}等人提出了DALL-E模型，这是一个由OpenAI开发的文本描述生成图像模型。该模型首先使用VAE思路将图像编码为离散的隐变量，用Transformer模型将自然语言映射到隐变量，最后将隐变量融合成并使用解码器生成图像，通过CLIP辅助计算文本与图像的相关度。其中的VAE、Transformer和CLIP都可以独立完成训练学习。
\par
大语言模型（Large Language Models，LLM）出现后，条件引导图像生成的研究工作中涌现出了一个新的思路，即利用现成预训练好的大语言模型去生成图像，因此产生了多模态大模型\cite{zhang2024mmllmsrecentadvancesmultimodal}。
Alayrac\cite{NEURIPS2022_960a172b}等人基于70B参数的Chinchilla大语言模型，训练出的Flamingo模型在5个任务达到了领先的水平。目前的效果较好的生成模型规模普遍较大，训练过程长，所需资源多。为了解决根据下游任务重新训练大模型代价昂贵的问题，Hu\cite{hu2021loralowrankadaptationlarge}等人提出了低秩适应（Low-rank Adaptation，LoRA）技术，通过冻结了预训练的模型权重，并将可训练的秩分解矩阵注入到 Transformer 架构的每一层中，大大减少了利用大模型进行下游任务的可训练参数的数量。LoRA作为一种有效的适应策略，既不会引入推理延迟，也不会减少输入序列长度，同时保持高模型质量。重要的是，通过共享绝大多数模型参数，它可以在部署为服务时实现快速任务切换。该项工作指出其所提出的原理通常适用于任何具有密集层的神经网络.

针对模板逆向重建，方法设计应在特征一致性、视觉保真度与计算开销之间进行权衡：一方面需要在训练或推理过程中引入嵌入级别的匹配损失、分类器分数引导或判别器约束，以直接优化生成样本在目标识别模型嵌入空间的相似性；另一方面需关注采样效率与微调成本，特别是在实际部署或攻击情境中，采用参数高效的微调方法（如 LoRA）能够在显著降低可训练参数量的同时实现对大型生成器的快速适配，从而提升方法的工程可行性与可复现性\cite{hu2021loralowrankadaptationlarge}。评估上应将嵌入相似度（余弦或欧氏距离）、识别/验证成功率与感知质量指标（FID、LPIPS）并列报告，同时关注微调参数规模与运行时成本，以便全面衡量方法的优劣\cite{9393327}。

此外，多模态对比学习与大模型驱动的条件生成技术（如 CLIP、DALL·E）为在语义或文本约束下实现目标引导的重建提供了新思路，使得将语义条件与特征匹配相结合成为可行方向；在实践中，结合这些条件化机制与扩散模型的分数引导策略，有望在保持视觉质量的同时进一步强化目标嵌入一致性，从而提升逆向重建的识别成功率与稳健性\cite{pmlr-v139-radford21a,pmlr-v139-ramesh21a,zhang2024mmllmsrecentadvancesmultimodal}。


与此同时，面对大规模预训练模型和多模态系统的普及，如何在保证模型性能的前提下以节省参数和计算代价的方式进行任务适配，也成为工程实践中的重要问题。为此出现了诸如低秩适配（Low‑Rank Adaptation, LoRA）等参数高效微调方法，它们通过在模型部分权重中注入可训练的低秩矩阵，实现对下游任务的高效适配而无需更新全部预训练参数\cite{hu2021loralowrankadaptationlarge}。在本课题中，结合这类高效微调策略，可在有限计算资源下对生成或反演模块进行定制化训练，从而提升攻击效率或防御对抗能力。

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{本文的研究内容及章节安排}

\subsection{问题描述}

为方便后文形式化与讨论，本文在此给出简要的问题描述与研究假设：
\begin{itemize}
  \item 问题对象：设目标识别器为函数 $f(\cdot)$，输入图像 $x$ 的嵌入为 $e=f(x)\in\mathbb{R}^d$，攻击者可获得目标个体的特征模板 $t$（例如 $t=f(x_0)$），希望生成图像 $\hat{x}$ 使得 $f(\hat{x})$ 与 $t$ 在嵌入空间上相似（余弦相似度或欧氏距离小于阈值）。
  \item 目标形式化：我们将模板逆向重建定义为求解
  $$\hat{x} = \arg\min_x \; \mathcal{L}_{embed}(f(x),t) + \lambda_{perc}\mathcal{L}_{perc}(x) + R(x),$$
  其中 $\mathcal{L}_{embed}$ 表示嵌入级别相似度度量（如 $1-\cos(f(x),t)$），$\mathcal{L}_{perc}$ 为感知质量相关损失（例如 LPIPS 或像素重建损失），$R(\cdot)$ 为正则化项或先验（例如扩散先验），$\lambda_{perc}$ 为权衡系数。
  \item 攻击假设分类：本文将实验覆盖如下常见攻击假设——白盒（攻击者可访问识别器权重与梯度）、半白盒（可查询置信度或嵌入）、黑盒（仅可通过 API 获得 top-k/置信度）以及仅获得模板 $t$ 的极限情形。每种情形在可用信息与可行攻击策略上有所不同，需分别评估。
\end{itemize}

\subsection{主要研究内容}

本研究围绕人脸识别系统中的特征模板逆向重建问题展开，重点在于在保证视觉保真度的同时最大化生成样本与目标模板在识别模型嵌入空间的相似性，并兼顾工程可行性与计算开销。主要研究内容包括：
\begin{itemize}
  \item 提出一种基于隐空间扩散模型（Latent Diffusion / EDM）的模板逆向重建框架：以预训练的隐空间自编码器与扩散采样器为基础，结合嵌入级一致性损失与分数/分类器引导（score/classifier guidance）机制，在采样或微调阶段显式优化生成样本在目标识别模型嵌入空间的相似度，从而在保持视觉质量的前提下提升识别级别的一致性（参见第3章与第5章）\cite{hoDenoisingDiffusionProbabilistic2020,rombachHighResolutionImageSynthesis2022,songScoreBasedGenerativeModeling2021}。

  \item 设计并验证两阶段一致性微调策略与参数高效适配方案：第一阶段在像素/隐空间上进行基线重建训练以确保图像质量；第二阶段以嵌入相似度或分类器分数为主目标，采用 LoRA 等低秩注入方法对生成器进行参数高效微调，以显著减少可训练参数与存储开销，同时提高针对特定目标模板的匹配能力与稳健性\cite{hu2021loralowrankadaptationlarge}。

  \item 构建判别/分数引导的采样与损失设计：研究如何将目标识别模型的嵌入相似度、验证分数或判别器信号融入扩散模型的采样过程（例如作为能量项或采样修正项），并比较不同引导策略（分类器引导、分数引导、条件化提示）的效果与计算代价，以实现更高的识别成功率与更低的误报率\cite{fredrikson2015model}。

  \item 建立统一的评估协议与基准实验：在公开人脸数据集（如 CelebA、VGGFace2、LFW 等）与若干典型目标识别模型上，定义并报告多维度指标（嵌入相似度/余弦相似度、识别/验证成功率 TAR@FAR、感知质量指标 FID/LPIPS、微调参数量与推理/训练时间开销），从而实现不同方法的可比性评价（详见第5章）。

  \item 分析防御与对抗鲁棒性：基于所构建的攻击基线，系统评估若干防御策略（模板加密/保护、差分隐私噪声注入、特征扰动/裁剪等）在不同攻击假设下的有效性与代价，并提出在工程部署中可行的缓解建议（详见第6章）。

  \item 开源复现与工程化实践：提供训练配置、微调脚本与评估流水线，使得实验可复现；同时给出对资源受限环境（如单卡/低内存）下的实用部署建议与参数化方案，便于后续研究与安全评估工作复用。
\end{itemize}

% === 被替换的原始段落（作为注释保留，便于回溯） ===
% 提出了一种基于隐扩散模型（EDM）的图像特征反向重建方法，能够在特征空间引入分类器分数引导，提高重建与目标模板的一致性（详见第3章与第5章）。
% 设计了一种两阶段一致性微调策略，在保持图像质量的同时增强与目标特征的匹配度，从而提高攻击成功率并降低结构性失真。

\subsection{章节安排}

本文的章节安排如下。为便于读者把握全文脉络，每章均给出简要说明。

第1章（绪论）：阐述研究背景、问题定义与研究意义，概述国内外研究现状并明确本文的主要研究内容与贡献，以及论文的组织结构。

第2章（相关理论与技术基础）：系统介绍本研究依赖的理论与方法，包括人脸识别模型与嵌入表示、生成模型家族（自回归/流/VAE、GAN、扩散模型及隐空间扩散）、参数高效微调方法（如 LoRA）与常用评估指标，为后续方法设计与实验评估提供理论基础。

第3章（基于隐扩散的模板逆向重建方法）：详细描述针对人脸特征模板的逆向重建框架，包括隐空间扩散模型的构建、嵌入一致性损失与分数/分类器引导策略、以及两阶段微调与 LoRA 适配的实现细节与理论考虑（模型结构、损失项与训练流程）。

第4章（面向分类模型的模型反演攻击）：扩展讨论在以分类器为目标的反演场景下的攻击设计，比较直接优化、生成器条件化与判别器/分数引导等策略的适用性，并提出针对分类模型的专用引导与正则化方法以提高反演的目标性与可识别性。

第5章（实验设计与结果分析）：给出实验设置、数据集与基线方法，按量化指标（嵌入相似度、识别/验证成功率、FID/LPIPS、微调参数量与计算开销）系统展示并分析所提方法在多种攻击假设与识别模型上的性能，对比不同引导策略与微调规模的效果差异。

\subsection{本文主要贡献}
% NOTE: 在最终提交前请把下面的 X/Y/时间等占位符替换为实验测得的真实数值。
\begin{itemize}
  \item 提出一种基于隐空间扩散（LDM/EDM）并结合嵌入一致性损失与分数引导的模板逆向重建框架，使生成样本在识别嵌入空间上的匹配度显著提升（实验中在 CelebA 上相比基线提升约 X\% \textit{（占位，需替换）}）。
  \item 设计并实现了一种两阶段的一致性微调策略，结合 LoRA 低秩注入，可在仅更新 <Y\% 的参数情况下达到接近全量微调的性能（Y 为参数更新比例，占位请替换）。
  \item 给出一套可复现的评估协议（脚本与配置）与工程化建议，包含 N=5 次重复实验统计、标准化的 TAR@FAR 报告流程以及对资源受限环境的实用部署阈值与时间成本估计。
\end{itemize}

% === 被替换的原始章节安排（已注释，便于回溯） ===
% 本文的章节安排如下：
%
% 第1章：绪论。
%
% 第2章：相关理论及技术基础，识别模型，生成模型，Lora微调，换脸模型
%
% 第3章：面向人脸特征提取模型的模板逆向攻击方法
%
% 第4章：面向人脸分类模型的模型反演攻击方法
%
% 第5章：实验设计与结果分析


% Local Variables:
% TeX-master: "../main"
% TeX-engine: xetex
% End:
