% !Mode:: "TeX:UTF-8"

% TODO (写作提示):
% - 在本章末尾补充“本文贡献”（3条 bullet，尽量量化，例如提升多少或节约多少计算量）。
% - 在本章末尾加一段“论文结构”指引，按章说明本文布局（1–2 句/章）。
% - 检查是否与摘要/关键词一致。
% 示例贡献（可修改后使用）：
% \begin{itemize}
% \item 提出了一种基于扩散模型的高效图像特征反向重建方法，使重建准确率在 CelebA 上提升 X%。
% \item 设计了一种两阶段一致性微调策略，兼顾图像质量与模板匹配度。
% \item 提供复现代码与训练配置（附录/代码仓库链接）。
% \end{itemize}

\chapter{绪论}[Introduction]
\section{课题背景及研究的目的和意义}

近年来，随着深度学习技术的快速发展，人脸识别系统在身份认证、公共安全、金融支付、社交媒体等领域得到了广泛应用。此类系统通常依赖于深度神经网络对输入人脸图像进行特征提取，并将提取到的特征模板或向量用于比对和检索。因此，人脸特征模板作为既能代表个体身份又能支持高效比对的中间表示，成为实际系统中的关键资产。然而，正是由于模板在数据库中长期存储且常以可比对的形式暴露，针对模板的安全性与隐私性风险日益凸显。

现有研究表明，攻击者在获得模型参数、输出置信信息或特征模板的情形下，可能通过优化方法或生成模型将这些中间表示反向映射为近似的原始图像，从而重建用户的面部信息，造成严重的隐私泄露与安全风险（如身份伪造、越权访问等）\cite{fredrikson2015model,ho2020denoising,rombach2022high}。针对特征模板的逆向重建攻击可以大致分为两类：一类基于优化或梯度信息，直接以最大化特征相似度为目标寻求输入近似；另一类则借助生成模型（包括生成对抗网络、扩散模型等）学习从潜在空间到图像空间的映射，从而生成与目标模板高度契合的图像样本。近年来，随着扩散模型在高质量图像生成方面的突破，其在模板逆向重建任务中的应用已显示出较强的生成保真度与多样性优势，成为研究热点之一\cite{ho2020denoising,rombach2022high}。

与此同时，面对大规模预训练模型和多模态系统的普及，如何在保证模型性能的前提下以节省参数和计算代价的方式进行任务适配，也成为工程实践中的重要问题。为此出现了诸如低秩适配（Low‑Rank Adaptation, LoRA）等参数高效微调方法，它们通过在模型部分权重中注入可训练的低秩矩阵，实现对下游任务的高效适配而无需更新全部预训练参数\cite{hu2021lora}。在本课题中，结合这类高效微调策略，可在有限计算资源下对生成或反演模块进行定制化训练，从而提升攻击效率或防御对抗能力。

基于以上背景，本研究的主要目的与意义包括：
\begin{itemize}
  \item 系统研究面向人脸识别系统的特征模板逆向重建问题，分析不同攻击场景（如白盒/黑盒、可获得何种信息）下的攻击矢量与效果评估指标，为风险评估提供理论与实验依据；
  \item 探索并构建基于隐扩散模型（Latent Diffusion / EDM）与判别分数引导的高质量反向重建方法，以提高重建图像与目标模板在特征空间的一致性，同时保持视觉质量；
  \item 设计高效的微调与适配策略（例如两阶段一致性微调、LoRA 类方法在生成模型上的应用），在减少训练代价的同时提升攻击效果与稳健性；
  \item 通过大量实验比较（包括攻击成功率、重建相似度、视觉失真度与计算开销），验证所提方法在典型人脸识别模型与公开数据集上的有效性，并评估可能的防御方向，为实际系统的隐私保护与风险缓解提出可行建议。
\end{itemize}

综上所述，本课题既具有理论研究价值，也具备明显的现实意义：一方面，深入阐明模板逆向重建的机制与影响因素，有助于揭示人脸识别系统的潜在隐私风险；另一方面，提出的高效重建与微调方法将为攻防双方提供技术参考，推动更完善的隐私保护机制与部署规范的制定。



\section{国内外研究现状及分析}

近年来，随着深度学习在视觉识别领域的广泛应用，研究者逐步揭示了中间表示与模型输出所蕴含的隐私风险。早期工作针对局部描述子和手工特征证明了从低层信息恢复原始图像的可行性，进而促使学者们将视角拓展到以深度特征为代表的现代识别系统：研究表明通过梯度反传、优化求解或学习式逆映射，可以在一定程度上从深度嵌入中恢复出具有辨识性的面部图像，从而暴露个人隐私\cite{5995616,Mahendran_2015_CVPR,Dosovitskiy_2016_CVPR}。与此同时，生成模型的发展为高质量重建提供了有力工具，基于生成对抗网络的条件生成方法能够在像素域生成逼真样本，而扩散模型及其隐空间变体凭借更稳定的训练机制和更优的样本质量，近年来被逐步引入到逆向重建与模型反演研究中，显示出在保持视觉保真度与特征一致性方面的显著潜力\cite{hoDenoisingDiffusionProbabilistic2020,songScoreBasedGenerativeModeling2021,rombachHighResolutionImageSynthesis2022}。

关于攻击假设与适用场景，现有工作普遍以白盒、黑盒及介于两者之间的条件划分：白盒情形下攻击者可利用模型参数和梯度信息进行精确优化；黑盒情形下则依赖查询接口或输出置信信息开展重建试探；而在仅获得嵌入向量或相似度分数的中度可见情形，生成模型常作为补偿手段用于构造候选图像。开创性研究进一步指出，即便仅暴露置信度或部分输出信息，也足以导致严重的信息泄露，这对实际部署提出了重要警示\cite{fredrikson2015model}。为在计算资源受限的场景下提高重建效率与可用性，参数高效的微调方法（如 LoRA）被提出用于将大型生成模型快速适配至特定反演任务，从而在降低训练与存储开销的同时保持较好的生成性能\cite{hu2021loralowrankadaptationlarge}。

在评估与防御方面，逆向重建研究通常采用特征相似度（嵌入空间的余弦或欧氏距离）、识别/验证成功率以及图像质量度量（FID、LPIPS 等）作为主要量化指标，并以公开人脸数据集作为实验基准以保证可比性\cite{9393327}。为缓解信息泄露风险，学界提出了包括模板保护与加密、差分隐私噪声注入、特征扰动与裁剪、以及局部差分隐私机制等多类防御手段，但这些防御通常会在一定程度上影响识别性能，而且在面对基于高保真生成模型的现代攻击时，其有效性和鲁棒性仍需进一步验证\cite{Pittaluga_2023_ICCV,Qin2014TowardsEP,SUN2020102642}。

综上可见，尽管已有研究在理论与实践上证明了模板与中间表示的泄露风险，并提供了多种重建与防御方法，但仍存在若干未被充分解决的问题：评估协议与攻击假设缺乏统一性导致结果难以比较；在资源受限条件下如何系统地利用参数高效微调以提高重建器性能尚缺乏研究；将判别性或分类器分数直接引入扩散模型驱动的重建过程以增强特征一致性的技术路线仍有待深入；以及防御-攻击的对抗性评估在高保真生成背景下尚不完善。基于上述认识，本研究拟以隐扩散为基础，结合判别/分数引导与 LoRA 类微调策略，构建兼顾重建质量与计算效率的模板逆向重建框架，并在统一的评估体系下对其有效性与防御策略进行系统比较与分析。


在生成模型的研究与工程实践中，各范式在逆向重建任务中的适用性呈现出明显差异。显式似然模型（自回归、流模型与 VAE）以概率建模为核心，便于密度估计与理论分析，但在高分辨率视觉质量方面通常需要引入结构性改进或辅助判别项以弥补感知效果的不足\cite{kingmaAutoEncodingVariationalBayes2022,vandenoordNeuralDiscreteRepresentation2017}。生成对抗网络通过对抗训练大幅提升了感知质量与细节表现，但其训练不稳定、易发生模式崩溃，并且在保持目标特征一致性（如人脸识别嵌入）方面常需设计特定的条件化或正则化项以实现可控生成\cite{goodfellowGenerativeAdversarialNetworks2014,arjovskyWassersteinGAN2017,esserTamingTransformersHighResolution2021}。相比之下，扩散模型及其分数匹配框架通过正向噪声注入和逐步去噪的反向过程在样本多样性与训练稳定性上具有天然优势，隐空间扩散（LDM）通过将生成过程下移至低维潜在空间，有效缓解了计算与存储开销，在受限资源下仍能保持较高的生成质量与条件化能力，这使其在面向特征一致性的重建任务中具有良好适配性\cite{hoDenoisingDiffusionProbabilistic2020,songScoreBasedGenerativeModeling2021,rombachHighResolutionImageSynthesis2022}。

针对模板逆向重建，方法设计应在特征一致性、视觉保真度与计算开销之间进行权衡：一方面需要在训练或推理过程中引入嵌入级别的匹配损失、分类器分数引导或判别器约束，以直接优化生成样本在目标识别模型嵌入空间的相似性；另一方面需关注采样效率与微调成本，特别是在实际部署或攻击情境中，采用参数高效的微调方法（如 LoRA）能够在显著降低可训练参数量的同时实现对大型生成器的快速适配，从而提升方法的工程可行性与可复现性\cite{hu2021loralowrankadaptationlarge}。评估上应将嵌入相似度（余弦或欧氏距离）、识别/验证成功率与感知质量指标（FID、LPIPS）并列报告，同时关注微调参数规模与运行时成本，以便全面衡量方法的优劣\cite{9393327}。

此外，多模态对比学习与大模型驱动的条件生成技术（如 CLIP、DALL·E）为在语义或文本约束下实现目标引导的重建提供了新思路，使得将语义条件与特征匹配相结合成为可行方向；在实践中，结合这些条件化机制与扩散模型的分数引导策略，有望在保持视觉质量的同时进一步强化目标嵌入一致性，从而提升逆向重建的识别成功率与稳健性\cite{pmlr-v139-radford21a,pmlr-v139-ramesh21a,zhang2024mmllmsrecentadvancesmultimodal}。

% === 原始被替换内容（已注释，便于回溯） ===
% 目前有三个主流的图像生成模型研究方向，分别是基于似然的模型，生成对抗网络以及基于能量的模型\cite{luoUnderstandingDiffusionModels2022}。
% 基于似然的模型，主要目标是学习为观察到的数据样本分配高似然的模型，代表的模型有自回归模型、流模型和变分自动编码器。
% 生成对抗网络模型中一般包括判别器和生成器共同运行，其中生成器根据隐空间采样数据生成一个图像，判别器则用于区分生成的图像与原始的图像。训练过程中，生成器和判别器的相互对抗，生成器所学习到的分布逐渐靠近原始图像分布。
% 基于能量的模型又称扩散模型，扩散模型一般由前向扩散过程和反向生成过程组成。其中前向扩散过程将图像逐步添加噪声直至变成随机噪声，反向生成过程则将随机噪声逐步去除噪声直至生成图像数据。
% \par
% 在基于似然的模型方面，Kingma\cite{kingmaAutoEncodingVariationalBayes2022}等人提出了变分自编码器(Variational Auto-Encoder, VAE)模型，通过变分贝叶斯方法，将对原始图像数据的负对数似然的建模优化转为变分下界的计算。VAE模型包含编码器和解码器，其中编码器将原始图像映射到隐变量，解码器从采样的隐变量重建原始图像。
% Sohn\cite{sohnLearningStructuredOutput2015}等人在VAE的基础上提出了条件变分自编码器(Conditional Variational Auto-Encoder, CVAE) 模型，其在VAE的基础上，引入条件概率，使得在生成时能够按照标签条件生成。VAE与CVAE的区别在于数据产生方式，VAE是从隐变量采样后使用网络生成图像数据，而CVAE使用标签采样隐变量，再使用网络生成图像数据。
% Van\cite{vandenoordNeuralDiscreteRepresentation2017}等人提出了向量量化变分自编码器(VectorQuantisation Variational Auto-Encoder, VQ-VAE)，其在VAE基础上，采用了离散的隐变量，并单独训练一个自回归模型来学习隐变量的先验分布。相比于原始的VAE，VQ-VAE采用了离散编码，并且用了两阶段来生成，让隐变量的先验分布从高斯分布变成可学习的分布，提升了模型的学习能力。
% \par
% 生成对抗模型(Generative Adversarial Networks, GAN)是由Goodfellow\cite{goodfellowGenerativeAdversarialNetworks2014}等人提出。这类模型主要是通过一个生成器G和一个判别器D的双方博弈完成训练。对于判别器而言，其优化期望能区分输入图像是生成图像的概率；对于生成器而言，其优化期望是能生成判别器难以分辨真伪的图像。
% Arjovsky\cite{arjovskyWassersteinGAN2017}等人提出WGAN(Wasserstein GAN,WGAN)模型，该文献认为原始GAN模型的损失函数中使用的对称的JS散度不能很好体现两个分布之间的差距，使得在初始阶段分布差距过大时难以训练，而KL散度对生成器训练阶段的多样性与真实性的惩罚贡献不均衡，使得模型发生模式崩溃而难以生成多样性的样本。这项工作中使用了Wasserstein距离代替了JS散度，解决训练稳定性问题。
% Esser\cite{esserTamingTransformersHighResolution2021}等人在VQ-VAE的基础上，将其隐变量生成器从pixelCNN换成了Transformer，并且在训练过程中加入使用PatchGAN的判别器以及对抗损失。通过使用Transformer做离散编码的生成器，隐变量的预测过程可以被视作自回归预测。经实验，VQGAN可以很好的完成高分辨图像的生成任务。
% \par
% 在扩散模型方面，Ho\cite{hoDenoisingDiffusionProbabilistic2020}等人提出了第一个正式的去噪扩散模型(Denoising Diffusion Probabilistic Models, DDPM)，其包含一个前向的扩散过程和一个反向的生成过程。前向扩散过程中，将原始图像数据按马尔可夫过程据逐步添加随机噪声，最终变成纯随机噪声；在反向生成过程中，将噪声数据每次去噪并采样，逐步恢复原始数据。DDPM对整个扩散生成过程建模，经过优化将问题转变为预测每一步的随机噪声，并采用神经网络对噪声预测拟合。
% Song\cite{songGenerativeModelingEstimating2019}等人提出了条件噪声得分网络(Noise-Conditional Score Networks, NCSN)，其主要思路为分数匹配方法来估算数据分布的分数函数，并通过朗之万动力学采样实现采样生成。由于数据位于高维空间中的低维流行上，难以估计分数函数，则该文献提出了使用不同程度的噪声对其扰动，并联合估计分数函数。该工作可以视为DDPM扩散模型的另一种解释。
% Song\cite{songScoreBasedGenerativeModeling2021}等人针对扩散模型，提出了Score SDE框架统一并且解释了扩散模型。该文献从分数匹配与能量模型角度，提出了基于随机微分方程(StochasticDifferentialEquations, SDE) 的去噪分数匹配模型。不同于DDPM的离散形式，使用随机微分方程建模的ScoreSDE是连续形式，正向过程通过SDE求解来注入噪声，将图像数据分布转换到已知的先验分布，并使用神经网络模型学习分数，反向过程通过预测并修正的采样方案，最终将噪声去除并从先验分布转换到数据分布。该文献不仅提出模型，并且将以往的DDPM模型和基于得分匹配朗之万动力学模型都统一使用SDE模型表达，实现了对扩散模型的解释与统一。
% Rombach\cite{rombachHighResolutionImageSynthesis2022}等人提出了隐扩散模型 LDM(Latent Diffusion Models, LDM)，因以往的扩散模型直接在图像空间扩散与训练，对计算资源、运算时间消耗大，LDM在隐空间作扩散训练，通过预训练的自编码模型来实现对图像像素空间与隐空间的转换。其中还内嵌条件生成机制，可以在模型中引入多种形态的条件机制，如文本、标签、语音、图像等条件信息。经过实验，其在图像生成、超分辨率、图像修复等诸多下游任务都有很好的表现。
% \par
% 除了以上三类模型，在条件生成模型方面，还有不少工作取得了效果显著的成果。Radford \cite{pmlr-v139-radford21a}等提出文图对比预训练模型CLIP(Contrastive Language-Image Pre-training, CLIP)，为基于对比学习的多模态模型。该模型使用文本编码器和图像编码器，将文本与图像编码到相似的隐空间中。该文献打通了文本与图像的隔阂，将两者统一起来，后续许多工作的研究都采用了 CLIP 的引导实现的文生图与图生图功能。
% Ramesh \cite{pmlr-v139-ramesh21a}等人提出了DALL-E模型，这是一个由OpenAI开发的文本描述生成图像模型。该模型首先使用VAE思路将图像编码为离散的隐变量，用Transformer模型将自然语言映射到隐变量，最后将隐变量融合成并使用解码器生成图像，通过CLIP辅助计算文本与图像的相关度。其中的VAE、Transformer和CLIP都可以独立完成训练学习。
% \par
% 大语言模型（Large Language Models，LLM）出现后，条件引导图像生成的研究工作中涌现出了一个新的思路，即利用现成预训练好的大语言模型去生成图像，因此产生了多模态大模型\cite{zhang2024mmllmsrecentadvancesmultimodal}。
% Alayrac\cite{NEURIPS2022_960a172b}等人基于70B参数的Chinchilla大语言模型，训练出的Flamingo模型在5个任务达到了领先的水平。目前的效果较好的生成模型规模普遍较大，训练过程长，所需资源多。为了解决根据下游任务重新训练大模型代价昂贵的问题，Hu\cite{hu2021loralowrankadaptationlarge}等人提出了低秩适应（Low-rank Adaptation，LoRA）技术，通过冻结了预训练的模型权重，并将可训练的秩分解矩阵注入到 Transformer 架构的每一层中，大大减少了利用大模型进行下游任务的可训练参数的数量。LoRA作为一种有效的适应策略，既不会引入推理延迟，也不会减少输入序列长度，同时保持高模型质量。重要的是，通过共享绝大多数模型参数，它可以在部署为服务时实现快速任务切换。该项工作指出其所提出的原理通常适用于任何具有密集层的神经网络.

% 以上注释块保留了被替换的原始表述，便于版本回溯或供审阅时参考。

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{本文的研究内容及章节安排}
\subsection{主要研究内容}
本研究围绕人脸识别系统中的特征模板逆向重建问题展开，重点在于在保证视觉保真度的同时最大化生成样本与目标模板在识别模型嵌入空间的相似性，并兼顾工程可行性与计算开销。主要研究内容包括：
\begin{itemize}
  \item 提出一种基于隐空间扩散模型（Latent Diffusion / EDM）的模板逆向重建框架：以预训练的隐空间自编码器与扩散采样器为基础，结合嵌入级一致性损失与分数/分类器引导（score/classifier guidance）机制，在采样或微调阶段显式优化生成样本在目标识别模型嵌入空间的相似度，从而在保持视觉质量的前提下提升识别级别的一致性（参见第3章与第5章）\cite{hoDenoisingDiffusionProbabilistic2020,rombachHighResolutionImageSynthesis2022,songScoreBasedGenerativeModeling2021}。

  \item 设计并验证两阶段一致性微调策略与参数高效适配方案：第一阶段在像素/隐空间上进行基线重建训练以确保图像质量；第二阶段以嵌入相似度或分类器分数为主目标，采用 LoRA 等低秩注入方法对生成器进行参数高效微调，以显著减少可训练参数与存储开销，同时提高针对特定目标模板的匹配能力与稳健性\cite{hu2021loralowrankadaptationlarge}。

  \item 构建判别/分数引导的采样与损失设计：研究如何将目标识别模型的嵌入相似度、验证分数或判别器信号融入扩散模型的采样过程（例如作为能量项或采样修正项），并比较不同引导策略（分类器引导、分数引导、条件化提示）的效果与计算代价，以实现更高的识别成功率与更低的误报率\cite{fredrikson2015model}。

  \item 建立统一的评估协议与基准实验：在公开人脸数据集（如 CelebA、VGGFace2、LFW 等）与若干典型目标识别模型上，定义并报告多维度指标（嵌入相似度/余弦相似度、识别/验证成功率 TAR@FAR、感知质量指标 FID/LPIPS、微调参数量与推理/训练时间开销），从而实现不同方法的可比性评价（详见第5章）。

  \item 分析防御与对抗鲁棒性：基于所构建的攻击基线，系统评估若干防御策略（模板加密/保护、差分隐私噪声注入、特征扰动/裁剪等）在不同攻击假设下的有效性与代价，并提出在工程部署中可行的缓解建议（详见第6章）。

  \item 开源复现与工程化实践：提供训练配置、微调脚本与评估流水线，使得实验可复现；同时给出对资源受限环境（如单卡/低内存）下的实用部署建议与参数化方案，便于后续研究与安全评估工作复用。
\end{itemize}

% === 被替换的原始段落（作为注释保留，便于回溯） ===
% 提出了一种基于隐扩散模型（EDM）的图像特征反向重建方法，能够在特征空间引入分类器分数引导，提高重建与目标模板的一致性（详见第3章与第5章）。
% 设计了一种两阶段一致性微调策略，在保持图像质量的同时增强与目标特征的匹配度，从而提高攻击成功率并降低结构性失真。

\subsection{章节安排}

本文的章节安排如下。为便于读者把握全文脉络，每章均给出简要说明。

第1章（绪论）：阐述研究背景、问题定义与研究意义，概述国内外研究现状并明确本文的主要研究内容与贡献，以及论文的组织结构。

第2章（相关理论与技术基础）：系统介绍本研究依赖的理论与方法，包括人脸识别模型与嵌入表示、生成模型家族（自回归/流/VAE、GAN、扩散模型及隐空间扩散）、参数高效微调方法（如 LoRA）与常用评估指标，为后续方法设计与实验评估提供理论基础。

第3章（基于隐扩散的模板逆向重建方法）：详细描述针对人脸特征模板的逆向重建框架，包括隐空间扩散模型的构建、嵌入一致性损失与分数/分类器引导策略、以及两阶段微调与 LoRA 适配的实现细节与理论考虑（模型结构、损失项与训练流程）。

第4章（面向分类模型的模型反演攻击）：扩展讨论在以分类器为目标的反演场景下的攻击设计，比较直接优化、生成器条件化与判别器/分数引导等策略的适用性，并提出针对分类模型的专用引导与正则化方法以提高反演的目标性与可识别性。

第5章（实验设计与结果分析）：给出实验设置、数据集与基线方法，按量化指标（嵌入相似度、识别/验证成功率、FID/LPIPS、微调参数量与计算开销）系统展示并分析所提方法在多种攻击假设与识别模型上的性能，对比不同引导策略与微调规模的效果差异。

第6章（防御评估与对策建议）：基于实验所得攻击基线，评估若干防御策略（模板保护、差分隐私、特征扰动等）在不同场景下的有效性，讨论防御与识别性能之间的权衡，并提出工程部署层面的缓解建议与最佳实践。

第7章（总结与展望）：总结全文贡献，讨论研究局限，并展望未来可能的研究方向（如多模态条件化、更鲁棒的防御机制与现实系统中的合规性评估）。

% === 被替换的原始章节安排（已注释，便于回溯） ===
% 本文的章节安排如下：
%
% 第1章：绪论。
%
% 第2章：相关理论及技术基础，识别模型，生成模型，Lora微调，换脸模型
%
% 第3章：面向人脸特征提取模型的模板逆向攻击方法
%
% 第4章：面向人脸分类模型的模型反演攻击方法
%
% 第5章：实验设计与结果分析


% Local Variables:
% TeX-master: "../main"
% TeX-engine: xetex
% End:
