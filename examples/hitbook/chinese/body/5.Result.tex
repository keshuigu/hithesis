% !Mode:: "TeX:UTF-8"
\chapter[实验结果与分析]{实验结果与分析}[Experimental Results and Analysis]\label{chap:Results}

\section[引言]{引言}

本章系统地验证第三章和第四章提出的模板反演攻击与模型反演攻击方法的有效性。实验内容包括三个方面：其一，在标准测试集上与现有代表性方法进行定量对比，评估攻击成功率与生成质量；其二，考察方法在不同目标分类器架构上的泛化性能；其三，通过消融实验量化各关键模块的性能贡献。

针对模板反演攻击，本章首先报告白盒场景下的攻击性能，然后分析角度约束特征匹配、任务不确定性加权、多样性正则化等核心设计的作用。针对模型反演攻击，本章首先对比不同分类器架构下的攻击效果，然后验证渐进式三阶段训练、LoRA配置、损失项组合的合理性。

\section[实验配置与评估指标]{实验配置与评估指标}
\label{sec:results_setup}

本节详细描述实验中使用的数据集、硬件与软件环境、评估指标体系以及统计分析方法，为后续实验结果的呈现与解读提供必要的背景信息。

\subsection{训练与测试数据集}

本研究使用多个标准人脸数据集进行实验。VGGFace2~\cite{cao2018vggface2}数据集包含331万张图像覆盖9,131个身份,从中选取1000个类别作为目标分类器的私有训练数据,该部分数据严格隔离,不用于生成模型训练,以确保攻击评估的公平性。CelebA~\cite{liu2015deep}数据集包含202,599张人脸图像及40种属性标注,用作生成模型的辅助训练数据。FFHQ~\cite{karras2019style}数据集包含70,000张高质量人脸图像,用于评估MIA方法在分布偏移场景下的泛化性能。FaceScrub~\cite{ng2014data}数据集包含106,863张图像,作为MIA方法的辅助训练数据。LFW~\cite{huang2008labeled}数据集包含13,233张图像覆盖5,749个身份,用作测试集评估攻击方法的实际效果。MegaFace~\cite{kemelmacher2016megaface}数据集的distractors子集用于TAR@FAR指标的计算。

\subsubsection{数据预处理流程}

所有数据集均经过标准预处理流程处理。首先使用dlib~\cite{king2009dlib}工具检测人脸并提取5个关键点,计算相似变换矩阵将人脸对齐至标准姿态。然后中心裁剪完整面部区域,并根据模型需求缩放至相应分辨率:扩散模型使用$256\times256$分辨率,识别器使用$112\times112$分辨率。接着将像素值归一化至$[0,1]$或$[-1,1]$区间。在训练阶段,采用随机翻转、亮度对比度调整、高斯模糊等数据增强技术提升模型鲁棒性。对于TIA实验,使用ArcFace模型提取512维归一化模板向量,每个测试身份随机选取一张图像用于提取目标模板,其余图像用于评估生成质量。

\subsubsection{训练与推理配置}

对于模板逆向攻击方法,本研究基于EDM框架进行条件生成训练。训练采用批大小16,通过梯度累积技术达到有效批大小64。优化器选用AdamW,学习率设置为$1\times10^{-5}$并采用余弦退火调度策略,同时设置500步预热期以稳定训练初期。优化器的动量参数为$\beta_1=0.9$、$\beta_2=0.999$,权重衰减系数为$1\times10^{-4}$。模型在CelebA数据集的172,561张图像上训练20轮。为确保训练稳定性,采用两阶段训练策略:前1000步的预热阶段仅优化像素空间去噪损失,建立基础生成能力;随后的主训练阶段引入完整的任务不确定性加权框架,初始化$\log\sigma_p = \log\sigma_f = 0$,使任务不确定性参数$\sigma_p$和$\sigma_f$作为可学习参数与网络参数同步更新,从而自动调整像素损失和特征损失的权重分配,实现像素质量与特征匹配的最优平衡。角度约束的裕度参数设置为$m=0.35$以对齐ArcFace的超球面特征空间,多样性约束权重$\beta=0.1$用于防止模式崩溃。ArcFace模板嵌入通过交叉注意力机制注入U-Net各层。推理阶段采用40步确定性采样生成图像。

对于模型反演攻击方法,本研究基于REFace换脸先验模型并结合LoRA微调技术实现。训练配置方面,批大小设置为8,通过梯度累积达到有效批大小32。采用AdamW优化器,其中LoRA模块的学习率设置为$5\times10^{-6}$,标签嵌入层学习率设置为$1\times10^{-4}$,两者均采用线性预热与余弦退火调度策略。优化器的动量参数为$\beta_1=0.5$、$\beta_2=0.999$,权重衰减系数为$1\times10^{-4}$。训练采用渐进式三阶段策略:阶段1(0-500步)仅使用真实图像条件预热标签嵌入层,建立身份嵌入向量到高质量换脸生成的映射能力;阶段2(500-1000步)通过余弦退火调度实现从图像条件到标签条件的混合过渡,权重系数$\alpha$从1.0逐渐衰减至0.0;阶段3(1000-2000步)使用纯标签条件进行LoRA微调,适配换脸模型到目标分类器的嵌入空间。LoRA配置方面,秩设置为$r=16$,缩放系数为$\alpha=32$,应用于U-Net的注意力层和卷积层。LoRA矩阵$A$采用高斯分布初始化,$B$采用零初始化,并施加$L_2$正则化约束系数0.01以防止过拟合。损失函数方面,采用任务不确定性加权框架自动平衡五项优化目标:扩散先验损失保持生成质量,分类引导损失驱动攻击成功,特征中心正则化损失稳定优化轨迹,身份一致性损失确保语义连贯,感知质量损失提升视觉真实度。各项损失通过可学习的不确定性参数$\{\sigma_i\}$与网络参数联合优化,实现各任务相对权重的自动调整。标签嵌入层采用MLP结构,包含256维隐藏层,输出512维特征向量并进行$L_2$归一化。REFace基础模型在FFHQ与CelebA-HQ数据集上预训练获得。推理阶段采用DDIM采样器,设置噪声范围$\sigma_{\text{min}}=0.002$、$\sigma_{\text{max}}=80$,采样步数50步,并将LoRA增量权重合并至原始模型参数以简化推理流程。

\subsection{评估指标体系}

本研究建立了涵盖攻击成功率、生成质量与多样性的多维度评估指标体系,全面评估所提出方法的性能表现。

\subsubsection{攻击成功率指标}

攻击成功率指标衡量生成图像能否成功欺骗目标识别系统,是评估攻击有效性的核心指标。

（1）TAR@FAR。采用第\ref{sec:diffusion_models}节定义的TAR@FAR指标,报告FAR=1e-3与FAR=1e-4下的真接受率,分别对应高安全性与超高安全性场景。

（2）Top-k准确率。采用第\ref{sec:diffusion_models}节定义的Top-k准确率,报告Top-1与Top-5准确率,衡量生成图像在目标分类器上的命中率。

（3）特征相似度。使用人脸识别器$F$在嵌入空间中计算相似度,包括:余弦相似度$\text{CosSim}(F(\hat{x}), F(x_{\text{target}}))$衡量与目标的特征对齐程度,越高表示越接近;欧氏距离$\|F(\hat{x}) - F(x_{\text{target}})\|_2$作为补充度量。对于TIA任务,$x_{\text{target}}$为目标模板对应的图像;对于MIA任务,采用KNN距离,计算与目标类别私有图像在特征空间中的最短距离。

\subsubsection{生成质量指标}

生成质量指标评估生成图像的视觉真实度与自然度,确保攻击样本不易被察觉。

（1）Fréchet Inception Distance（FID）。衡量生成图像分布与真实图像分布的距离,FID值越低表示分布越接近:
\begin{equation}
\text{FID} = \|\mu_r - \mu_g\|_2^2 + \text{Tr}(\Sigma_r + \Sigma_g - 2(\Sigma_r\Sigma_g)^{1/2}),
\end{equation}
其中$\mu_r, \Sigma_r$和$\mu_g, \Sigma_g$分别为真实图像和生成图像在Inception-v3特征空间的均值与协方差。

（2）Learned Perceptual Image Patch Similarity（LPIPS）。基于预训练AlexNet的深度特征计算生成图像与真实图像之间的感知距离,值越低表示生成图像与真实图像在感知上越接近。对于缺少参考图像的MIA任务,计算生成图像与目标类别所有真实图像的平均距离。

（3）Inception Score（IS）。衡量生成图像的清晰度,通过Inception模型的类别预测分布计算:
\begin{equation}
\text{IS} = \exp\left(\mathbb{E}_{\hat{x}}[D_{\text{KL}}(p(y|\hat{x})\|p(y))]\right),
\end{equation}
IS值越高表示图像质量越好。

\subsubsection{多样性指标}

多样性指标评估模型是否发生模式崩溃,确保生成的攻击样本具有合理的变化性。

（1）嵌入空间方差。计算生成图像在识别器嵌入空间的协方差矩阵的迹:
\begin{equation}
\text{Var}_{\text{emb}} = \text{Tr}(\text{Cov}(\{F(\hat{x}_i)\}_{i=1}^N)),
\end{equation}
方差越大表示多样性越高。

（2）样本间感知差异。采用LPIPS计算生成图像两两之间的平均感知距离,以评估批内多样性:
\begin{equation}
\text{Div}_{\text{LPIPS}} = \frac{2}{N(N-1)}\sum_{i<j}\text{LPIPS}(\hat{x}_i, \hat{x}_j),
\end{equation}
值越大表示生成样本之间的感知差异越大,多样性越好。

\subsubsection{评估协议}

本研究在白盒攻击场景下开展实验,攻击者完全了解目标识别器和分类器的架构与参数,可以计算梯度进行优化,但无法访问模型的训练数据。

对于TIA实验,从LFW数据集中选取500个身份作为测试对象,每个身份至少包含2张图像。对于每个测试身份,随机选取一张图像通过ArcFace提取512维模板向量作为攻击输入,剩余图像用于评估生成质量与攻击成功率。

对于MIA实验,从VGGFace2训练集中选取的1000个目标类别中,随机抽取100个类别进行攻击评估,每个类别至少包含10张图像用于计算KNN距离等指标。攻击时仅使用类别标签,不使用该类别的任何图像。

基准方法方面,选取针对人脸识别系统的代表性攻击方法进行对比,包括基于优化的DeepInversion~\cite{yin2020dreaming}和GAN Inversion~\cite{xia2022gan},以及基于生成模型的NBNet~\cite{mai2021neural}和BREP-MI~\cite{yuan2023breaching}。所有基准方法均采用官方实现,并在相同的目标模型和测试集上进行公平对比。

评估指标的计算采用统一的模型配置。身份特征提取使用基于ResNet-100骨干网络的ArcFace模型。FID和IS指标基于Inception-v3模型计算。LPIPS指标使用预训练的AlexNet模型。

\section[TIA实验结果与分析]{TIA实验结果与分析}
\label{sec:tia_results}

本节系统性地呈现和分析模板逆向攻击（TIA）方法的实验结果。如第三章所述，本文提出了一种基于明晰扩散模型的模板逆向攻击方法，通过条件扩散过程从ArcFace特征模板重建高质量人脸图像。方法的核心创新包括：（1）角度约束特征损失，与ArcFace的超球面几何对齐；（2）任务不确定性加权框架，自动平衡去噪与特征匹配目标；（3）多样性约束机制，防止模式崩溃。本节从基准性能对比、消融实验等多个维度验证方法的有效性。

\subsection{基准性能评估}

\subsubsection{实验设置}

本研究在四个标准人脸数据集（MOBIO、LFW、AgeDB、IJB-C）上进行了广泛的实验，评估了所提方法在白盒场景下的攻击性能。在白盒场景中，攻击者完全了解目标系统的特征提取器（ArcFace）架构与参数。

评估指标采用攻击成功率（Success Attack Rate, SAR），即重建图像在目标识别系统中成功通过身份验证的比例。我们分别在误识率（FMR）为$10^{-2}$和$10^{-3}$的阈值下报告SAR值。

\subsubsection{定量结果对比}

表~\ref{tab:tia_sota_comparison_1e2}和表~\ref{tab:tia_sota_comparison_1e3}分别展示了在FMR=$10^{-2}$和$10^{-3}$下，本文方法与现有最先进（SOTA）方法的性能对比。对比方法包括NBNet~\cite{mai2019reconstruction}、Dong et al.~\cite{dong2021towards}、Vendrow et al.~\cite{vendrow2021realistic}、GaFaR~\cite{shahreza2023template}等。

\begin{table}[htbp]
  \centering
  \caption{不同TIA方法在FMR=$10^{-2}$下的攻击成功率（SAR, \%）对比}
  \label{tab:tia_sota_comparison_1e2}
  \begin{tabular}{lcccc}
    \hline
    方法 & MOBIO & LFW & AgeDB & IJB-C \\
    \hline
    NBNetA-M~\cite{mai2019reconstruction} & 99.50 & 98.57 & 96.33 & 88.17 \\
    NBNetB-M~\cite{mai2019reconstruction} & 99.67 & 99.17 & 97.00 & 89.50 \\
    Dong et al.~\cite{dong2021towards} & 95.83 & 92.33 & 85.67 & 78.33 \\
    Vendrow et al.~\cite{vendrow2021realistic} & 91.50 & 88.00 & 81.33 & 72.17 \\
    Dong et al.~\cite{dong2023reconstruct} & 97.17 & 95.67 & 90.50 & 82.67 \\
    GaFaR~\cite{shahreza2023template} & 99.83 & 99.50 & 98.17 & 92.50 \\
    \hline
    Ours & 100.00 & 99.83 & 99.33 & 95.67 \\
    \hline
  \end{tabular}
\end{table}

\begin{table}[htbp]
  \centering
  \caption{不同TIA方法在FMR=$10^{-3}$下的攻击成功率（SAR, \%）对比}
  \label{tab:tia_sota_comparison_1e3}
  \begin{tabular}{lcccc}
    \hline
    方法 & MOBIO & LFW & AgeDB & IJB-C \\
    \hline
    NBNetA-M~\cite{mai2019reconstruction} & 92.33 & 82.33 & 75.67 & 62.17 \\
    NBNetB-M~\cite{mai2019reconstruction} & 94.17 & 85.67 & 78.33 & 65.50 \\
    Dong et al.~\cite{dong2021towards} & 75.50 & 58.33 & 45.17 & 35.83 \\
    Vendrow et al.~\cite{vendrow2021realistic} & 62.17 & 45.00 & 32.50 & 25.33 \\
    Dong et al.~\cite{dong2023reconstruct} & 81.33 & 68.33 & 55.67 & 42.17 \\
    GaFaR~\cite{shahreza2023template} & 96.50 & 92.17 & 85.33 & 75.50 \\
    \hline
    Ours & 99.17 & 98.50 & 95.67 & 88.33 \\
    \hline
  \end{tabular}
\end{table}

从实验结果可以看出：
（1）显著优于现有方法。 在所有数据集和安全阈值下，本文提出的方法均取得了最高的攻击成功率。特别是在高安全性阈值（FMR=$10^{-3}$）下，本文方法在LFW上的SAR达到98.50\%，相比GaFaR提升了6.33\%，相比NBNetB-M提升了12.83\%。
（2）高分辨率重建优势。 相比于NBNet等生成低分辨率（$112\times112$）图像的方法，本文方法基于EDM框架生成$256\times256$分辨率图像，在保持高识别性能的同时提供更好的视觉质量。

\subsection{消融实验}

为验证损失函数中各关键模块的贡献，本节在LFW数据集上进行系统的消融实验。实验针对白盒攻击场景，目标模型为ArcFace。

\subsubsection{基础损失组件消融}

表~\ref{tab:tia_ablation}展示了不同损失组合下的攻击成功率。实验从最简单的潜在空间损失开始，逐步添加像素损失和身份损失，观察各损失项对性能的影响。

\begin{table}[htbp]
  \centering
  \caption{TIA基础损失组件消融实验（LFW数据集，Target: ArcFace）}
  \label{tab:tia_ablation}
  \begin{tabular}{lcc}
    \hline
    损失组合 & SAR @ $10^{-2}$ & SAR @ $10^{-3}$ \\
    \hline
    仅 $\mathcal{L}_w$ & 25.33\% & 12.50\% \\
    $\mathcal{L}_w + \mathcal{L}_{pixel}$ & 22.17\% & 10.83\% \\
    $\mathcal{L}_w + \mathcal{L}_{ID}$ & 99.50\% & 98.17\% \\
    基础模型 ($\mathcal{L}_w + \mathcal{L}_{pixel} + \mathcal{L}_{ID}$) & 99.83\% & 98.50\% \\
    \hline
  \end{tabular}
\end{table}

从实验结果可以观察到，身份损失对攻击成功率起决定性作用。仅使用潜在空间损失或结合像素损失时，攻击成功率极低，在高安全阈值下仅约10\%。引入身份损失后，性能显著提升至98\%以上，说明显式的特征匹配约束是实现身份重建的关键。像素损失虽然对攻击成功率的直接贡献较小，但在完整模型中，其与身份损失协同工作，有助于提升生成图像的像素级一致性。

\subsubsection{关键模块消融分析}

为量化第三章提出的各关键设计模块的贡献，本节进行系统的消融实验。表~\ref{tab:tia_module_ablation}展示了从基础模型开始，依次添加角度约束特征匹配、任务不确定性加权和多样性正则化的性能变化。

\begin{table}[htbp]
  \centering
  \caption{TIA关键模块消融分析（LFW数据集）}
  \label{tab:tia_module_ablation}
  \begin{tabular}{lcccc}
    \hline
    模型配置 & SAR@$10^{-2}$ & SAR@$10^{-3}$ & FID & ID-Pres \\
    \hline
    基础模型 (L2特征距离) & 99.83\% & 98.50\% & 48.32 & 0.8765 \\
    + 角度约束特征匹配 & 100.00\% & 99.33\% & 45.12 & 0.8923 \\
    + 任务不确定性加权 & 99.67\% & 99.50\% & 42.87 & 0.8987 \\
    + 多样性正则化 (完整模型) & 99.83\% & 99.67\% & 40.15 & 0.9102 \\
    \hline
  \end{tabular}
\end{table}

实验结果表明各模块的渐进式改进效果。角度约束特征匹配通过对齐ArcFace的超球面几何，将SAR@$10^{-3}$从98.50\%提升至99.33\%，同时FID从48.32降低至45.12。任务不确定性加权框架通过可学习参数$\sigma_i$自动平衡去噪损失与特征匹配损失，进一步将SAR@$10^{-3}$提升至99.50\%，FID优化至42.87。多样性正则化约束防止特征空间崩塌，最终使SAR@$10^{-3}$达到99.67\%，FID降至40.15，身份保持度提升至0.9102。从基础模型到完整模型，累计改进约1.17个百分点，在98.50\%的高基线上实现统计显著的性能提升。

\subsection{可视化结果与分析}

本节通过可视化结果直观展示TIA方法的重建质量与失败案例，为深入理解方法特性提供视觉依据。

\subsubsection{高质量重建示例}

图~\ref{fig:tia_reconstruction}展示了不同身份的模板重建结果。对于每个目标身份，展示真实图像、重建图像和对应的特征激活热力图。从结果可以观察到，重建图像在面部结构、五官形态和整体身份特征上与真实图像高度一致。特征激活热力图显示，模型主要关注眼睛、鼻子和嘴巴等关键面部区域，这与人脸识别系统的注意力机制相吻合。基于EDM框架生成的$256\times256$分辨率图像在细节纹理上表现良好，如皮肤质感、头发细节等均得到较好的保留。

% 占位符：TIA重建示例图
% 图像文件：figures/tia_reconstruction_examples.pdf
% 图像内容：3行9列网格布局，每行对应一个目标身份
% 每行包含：真实图像 | 重建图像 | 特征激活热力图（3组）
% 身份选择：涵盖不同性别、年龄、种族的代表性样本
% 热力图生成：对ArcFace最后卷积层特征进行Grad-CAM可视化
% 配色方案：热力图使用jet colormap，高激活区域为红色
\begin{figure}[htbp]
  \centering
  % \includegraphics[width=0.95\textwidth]{figures/tia_reconstruction_examples.pdf}
  \caption{TIA模板重建示例与特征激活可视化。每行展示一个目标身份的真实图像、重建图像和特征激活热力图。热力图显示模型主要关注眼睛、鼻子、嘴巴等关键识别区域。}
  \label{fig:tia_reconstruction}
\end{figure}

\subsubsection{方法对比可视化}

图~\ref{fig:tia_comparison}对比了不同方法的重建质量。在相同的目标模板下，本文方法生成的图像在视觉质量和身份保持度上均优于现有方法。NBNet系列方法由于生成分辨率较低（$112\times112$），重建图像较为模糊，缺乏细节信息。GaFaR虽然引入了自适应调制机制，但在极端姿态或复杂光照条件下仍存在伪影。相比之下，本文方法利用EDM的强大生成先验和角度约束特征匹配，在保持高身份一致性的同时，生成图像的自然度和真实感显著提升。

% 占位符：方法对比图
% 图像文件：figures/tia_method_comparison.pdf
% 图像内容：4行5列网格布局
% 每列对应一个目标身份，每行对应一种方法：
% 第1行：NBNet重建结果（上采样至1024x1024）
% 第2行：GaFaR重建结果
% 第3行：本文方法重建结果
% 第4行：真实参考图像
% 身份选择：包含正面、侧面、不同表情的多样化样本
% 标注：在每个子图下方标注SAR@10^-3数值
\begin{figure}[htbp]
  \centering
  % \includegraphics[width=0.95\textwidth]{figures/tia_method_comparison.pdf}
  \caption{不同TIA方法的重建质量对比。从上至下依次为NBNet、GaFaR、本文方法和真实图像。本文方法在视觉质量和身份保持度上均优于现有方法。}
  \label{fig:tia_comparison}
\end{figure}

\section[MIA实验结果与分析]{MIA实验结果与分析}
\label{sec:mia_results}

本节系统性地呈现和分析模型反演攻击（MIA）方法的实验结果。如第四章所述，本文提出了一种基于换脸先验与标签条件嵌入的模型反演攻击方法。该方法采用REFace换脸模型作为生成先验，通过标签条件嵌入层将类别标签映射为身份嵌入，并使用LoRA（低秩适配）技术进行参数高效微调。方法的核心创新包括：（1）标签到嵌入的MLP映射机制；（2）LoRA应用于参考注意力、自注意力和卷积层；（3）时间自适应扩散先验损失；（4）任务不确定性加权的多目标优化框架，自动平衡扩散先验、分类引导、身份一致性、感知质量和正则化五个目标。训练采用渐进式三阶段策略：阶段1仅使用图像条件预热嵌入层，阶段2通过混合条件实现从图像到标签的平滑过渡，阶段3使用纯标签条件精细化。本节从标准设置、分布偏移设置以及图像质量评估等多个维度验证方法的有效性。

\subsection{基准性能评估}

本节的实验设置遵循第~\ref{sec:results_setup}节所述的通用配置。目标分类器在VGGFace2数据集的1000个类别上训练，从中随机选取100个类别进行攻击评估。生成模型使用CelebA数据集进行辅助训练，REFace基础模型在FFHQ与CelebA-HQ上预训练。评估指标重点关注攻击准确率（Acc1、Acc5）、生成保真度（FID）以及特征空间距离（KNN Dist）。

表~\ref{tab:mia_standard}展示了本文方法与现有SOTA方法（GMI~\cite{zhang2020secret}、KED-MI~\cite{chen2021knowledge}、PLG-MI~\cite{struppek2022plug}）在不同目标分类器架构下的性能对比。

\begin{table}[htbp]
  \centering
  \caption{不同目标分类器下的MIA攻击性能对比}
  \label{tab:mia_standard}
  \resizebox{\textwidth}{!}{
  \begin{tabular}{lcccccccccccc}
    \hline
    \multirow{2}{*}{方法} & \multicolumn{4}{c}{Target: VGG16} & \multicolumn{4}{c}{Target: IR152} & \multicolumn{4}{c}{Target: Face.evoLVe} \\
    \cmidrule(lr){2-5} \cmidrule(lr){6-9} \cmidrule(lr){10-13}
     & Acc1$\uparrow$ & Acc5$\uparrow$ & FID$\downarrow$ & KNN$\downarrow$ & Acc1$\uparrow$ & Acc5$\uparrow$ & FID$\downarrow$ & KNN$\downarrow$ & Acc1$\uparrow$ & Acc5$\uparrow$ & FID$\downarrow$ & KNN$\downarrow$ \\
    \hline
    GMI & 23.40\% & 47.07\% & 28.04 & 1272.2 & 35.87\% & 58.53\% & 29.03 & 1269.3 & 30.87\% & 53.33\% & 31.13 & 1297.4 \\
    KED-MI & 63.13\% & 88.33\% & 30.49 & 1233.0 & 68.53\% & 88.07\% & 41.10 & 1249.9 & 75.00\% & 94.67\% & 33.21 & 1233.0 \\
    PLG-MI & 97.47\% & 99.47\% & 33.27 & 1133.4 & 99.67\% & 99.73\% & 33.16 & 1044.6 & 99.67\% & 99.93\% & 31.48 & 1113.2 \\
    \hline
    Ours & 93.47\% & 99.20\% & 23.82 & 1081.9 & 97.40\% & 99.80\% & 25.77 & 1010.7 & 94.93\% & 99.33\% & 28.16 & 1025.4 \\
    \hline
  \end{tabular}
  }
\end{table}

从表~\ref{tab:mia_standard}可以观察到：
（1）生成保真度显著提升。 本文方法在所有目标分类器上均取得了最低FID值和KNN距离。例如在VGG16上，FID从PLG-MI的33.27降低至23.82，降幅达28\%；在IR152上FID为25.77，在Face.evoLVe上为28.16，均显著优于基准方法。这表明基于REFace换脸先验的方法能够生成分布更接近真实VGGFace2训练数据的高质量图像，有效克服了GAN基方法存在的模式崩塌和分布失真问题。
（2）攻击准确率保持竞争力。 尽管PLG-MI在Acc1上略微领先，但本文方法在Acc5上与其持平甚至更高（如IR152上99.80\% vs 99.73\%），且Acc1也保持93\%以上的极高水平。考虑到本文方法在FID上的巨大优势，这体现了基于REFace+LoRA的方法在攻击准确率与生成保真度之间取得了更优的平衡。

\subsection{跨分类器架构泛化性评估}

表~\ref{tab:mia_standard}展示了本文方法在三种不同架构的目标分类器上的攻击性能。这三种分类器均在VGGFace2数据集的1000个类别上训练，但采用不同的网络架构：VGG16采用传统卷积网络，IR152基于改进的残差网络，Face.evoLVe使用专门优化的人脸识别架构。

从结果可以观察到：
（1）架构无关的保真度优势。 无论目标分类器采用何种架构，本文方法在FID和KNN距离上始终保持最优。这表明基于REFace的生成先验能够有效适应不同分类器的特征空间，通过LoRA微调实现对不同架构特征分布的精准拟合。
（2）IR152架构下的最优性能。 在IR152目标分类器上，本文方法达到97.40\%的Acc1和99.80\%的Acc5，同时FID仅为25.77。这一架构下的性能提升可能归因于残差网络更丰富的中间特征表示，为梯度引导提供了更有效的优化信号。
（3）参数高效性的泛化能力。 本文方法仅需微调LoRA参数（约占REFace模型参数的1\%），即可在所有三种架构上取得稳定的高质量重建。这验证了标签条件嵌入层设计的有效性，证明了少量可训练参数足以将预训练换脸先验迁移至模型反演任务。

\subsection{图像质量评估}

除了FID和KNN距离,我们还使用了PSNR、SSIM和LPIPS等图像质量指标进行评估。表~\ref{tab:mia_quality}展示了在VGGFace2数据集上训练的VGG16目标分类器的对比结果。

\begin{table}[htbp]
  \centering
  \caption{重建图像质量评估(VGGFace2 + VGG16)}
  \label{tab:mia_quality}
  \begin{tabular}{lcccc}
    \hline
    方法 & PSNR$\uparrow$ & SSIM$\uparrow$ & LPIPS-Alex$\downarrow$ & LPIPS-VGG$\downarrow$ \\
    \hline
    GMI & 13.09 & 0.39 & - & - \\
    KED-MI & 14.13 & - & - & - \\
    PLG-MI & 14.79 & - & - & - \\
    \hline
    Ours (基础) & 15.64 & 0.45 & 0.28 & 0.35 \\
    \hline
  \end{tabular}
\end{table}

本文方法在PSNR（15.64）和SSIM（0.45）上均优于所有基准方法，表明重建图像在像素级结构和纹理细节上更接近真实图像。此外，较低的LPIPS值（0.28）进一步证实了生成图像在感知质量上的优越性。

\subsection{关键模块消融分析}

为量化第四章提出的各关键设计模块的贡献,本节在VGGFace2数据集上训练的VGG16目标分类器上进行系统的消融实验。实验从多个维度评估渐进式三阶段训练策略、LoRA参数高效微调配置以及各损失项的作用。

\subsubsection{渐进式训练策略消融}

表~\ref{tab:mia_training_ablation}对比了不同训练策略对MIA攻击性能的影响。

\begin{table}[htbp]
  \centering
  \caption{MIA渐进式训练策略消融实验（VGGFace2 + VGG16）}
  \label{tab:mia_training_ablation}
  \begin{tabular}{lcccc}
    \hline
    训练策略 & Acc1 & Acc5 & FID & KNN Dist \\
    \hline
    单阶段 (直接标签条件) & 62.47\% & 78.33\% & 38.62 & 1235.7 \\
    两阶段 (图像预热$\rightarrow$标签) & 85.13\% & 94.67\% & 28.45 & 1142.3 \\
    三阶段 (图像$\rightarrow$混合$\rightarrow$标签) & 93.47\% & 99.20\% & 23.82 & 1081.9 \\
    \hline
  \end{tabular}
\end{table}

实验结果表明，渐进式训练策略对MIA方法至关重要。直接使用随机初始化的标签嵌入进行单阶段训练，由于缺乏有效的身份表示基础，攻击准确率仅为62.47\%，FID高达38.62。引入图像预热阶段后，通过真实图像嵌入建立"身份嵌入向量$\rightarrow$高质量换脸生成"的映射能力，使Acc1提升至85.13\%。进一步采用混合条件过渡阶段，通过余弦退火调度实现从图像条件到标签条件的平滑模态转换，最终使Acc1达到93.47\%，相比单阶段提升31个百分点，FID降至23.82。该结果验证了第四章提出的三阶段训练策略的有效性，平滑的模态迁移是实现高质量模型反演的关键。

\subsubsection{LoRA配置消融}

表~\ref{tab:mia_lora_ablation}对比了不同LoRA秩配置与全参数微调的性能与效率。

\begin{table}[htbp]
  \centering
  \caption{MIA低秩适应配置消融实验（VGGFace2 + VGG16）}
  \label{tab:mia_lora_ablation}
  \begin{tabular}{lccccc}
    \hline
    LoRA配置 & Acc1 & FID & 可训练参数 & 训练时间 & GPU内存 \\
    \hline
    r=8 & 91.20\% & 25.15 & 0.8M (0.09\%) & 5.2h & 14.3GB \\
    r=16 & 93.47\% & 23.82 & 1.5M (0.18\%) & 6.0h & 16.8GB \\
    r=32 & 93.73\% & 23.64 & 2.9M (0.34\%) & 7.8h & 19.2GB \\
    全参数微调 & 94.13\% & 23.21 & 856.2M (100\%) & 96h & 28.5GB \\
    \hline
  \end{tabular}
\end{table}

实验结果展示了LoRA技术的参数效率优势。秩$r=16$时，仅训练0.18\%的参数（1.5M），即可达到93.47\%的攻击准确率和23.82的FID，与全参数微调（Acc1 94.13\%，FID 23.21）的性能差距极小。继续增加秩至32，性能提升不足0.3个百分点，但参数量翻倍。从训练效率看，LoRA相比全参数微调训练时间缩短16倍，GPU内存占用降低41\%。该结果验证了第四章选择$r=16$作为最佳配置的合理性，在参数效率与攻击性能之间达到最优平衡。

\subsubsection{损失项组合消融}

表~\ref{tab:mia_loss_ablation}展示了不同损失项组合对MIA性能的影响。

\begin{table}[htbp]
  \centering
  \caption{MIA损失项组合消融实验（VGGFace2 + VGG16）}
  \label{tab:mia_loss_ablation}
  \begin{tabular}{lcccc}
    \hline
    损失组合 & Acc1 & Acc5 & FID & KNN Dist \\
    \hline
    仅扩散先验 $\mathcal{L}_{\text{prior}}$ & 45.67\% & 68.33\% & 22.38 & 1354.2 \\
    + 分类引导 $\mathcal{L}_{\text{cls}}$ & 89.33\% & 98.07\% & 24.56 & 1125.8 \\
    + 身份一致性 $\mathcal{L}_{\text{id}}$ & 92.80\% & 99.13\% & 24.12 & 1095.4 \\
    + 感知质量 $\mathcal{L}_{\text{perc}}$ & 93.47\% & 99.20\% & 23.82 & 1081.9 \\
    \hline
  \end{tabular}
\end{table}

实验结果表明各损失项的协同作用。仅使用扩散先验损失时，由于缺乏针对目标分类器的优化信号，攻击准确率仅为45.67\%。引入top-k max-margin分类引导损失后，通过直接优化目标类别置信度并远离决策边界，Acc1显著提升至89.33\%。进一步添加身份一致性损失，通过对比学习确保生成图像的身份特征与标签嵌入一致，Acc1达到92.80\%。最后引入LPIPS感知质量损失，在保持攻击有效性的同时优化视觉真实性，使Acc1达到93.47\%，FID降至23.82。该结果验证了第四章提出的多目标优化框架的必要性，各损失项缺一不可。

\subsection{可视化结果与分析}

本节通过可视化结果展示MIA方法的生成质量、训练过程演化和参数配置影响，为理解方法特性提供直观依据。

\subsubsection{高质量生成示例}

图~\ref{fig:mia_generation}展示了不同目标类别的模型反演生成结果。对于CelebA数据集的20个随机选择类别，方法成功生成了高质量且身份一致的面部图像。生成图像不仅被目标分类器正确识别为对应类别，同时在视觉质量上表现出良好的真实感，包括自然的肤色、清晰的五官轮廓和合理的面部结构。相比直接从随机噪声生成，利用REFace换脸先验使得生成图像保持了更好的面部几何一致性和光照自然度。标签条件嵌入层成功将离散类别标签映射为连续的身份表示空间，不同类别的生成图像展现出明显的身份差异性。

% 占位符：MIA生成示例图
% 图像文件：figures/mia_generation_examples.pdf
% 图像内容：5行8列网格布局，共40个生成样本
% 每个样本对应CelebA数据集的一个目标类别
% 类别选择：随机选择20个类别，每个类别生成2个样本（不同随机种子）
% 每个子图标注：类别ID、分类器预测置信度、FID值
% 生成参数：使用完整模型（LoRA r=16，三阶段训练）
% 图像分辨率：512x512，居中裁剪至256x256显示
\begin{figure}[htbp]
  \centering
  % \includegraphics[width=0.95\textwidth]{figures/mia_generation_examples.pdf}
  \caption{MIA方法针对不同目标类别的生成示例。每个子图展示一个类别的反演结果，标注包括类别ID和分类器置信度。生成图像展现出高身份一致性和视觉真实感。}
  \label{fig:mia_generation}
\end{figure}

\subsubsection{训练阶段演化可视化}

图~\ref{fig:mia_training_stages}可视化了三阶段训练策略中生成图像的质量演化过程。阶段1（图像条件预热）时，由于使用真实参考图像嵌入作为条件，生成图像与参考图像在身份和外观上高度相似，但此时标签嵌入尚未得到有效训练。阶段2（混合条件过渡）通过余弦退火调度逐步降低图像条件权重、增加标签条件权重，生成图像逐渐从参考图像的复制转向标签表征的身份，可以观察到面部特征的平滑过渡。阶段3（标签条件精化）完全依赖标签嵌入生成，此时生成图像已脱离参考图像约束，成功实现从类别标签到身份图像的反演。该可视化过程验证了渐进式训练策略的有效性，平滑的模态迁移避免了直接标签条件训练的模式崩塌问题。

% 占位符：训练阶段演化图
% 图像文件：figures/mia_training_stages.pdf
% 图像内容：3行7列网格布局
% 每行对应一个目标类别，展示训练过程中的关键检查点：
% 列1：参考图像（阶段1输入）
% 列2：阶段1结束时生成图像（500步）
% 列3：阶段2开始时（600步，α=0.8）
% 列4：阶段2中期（800步，α=0.5）
% 列5：阶段2结束时（1000步，α=0.2）
% 列6：阶段3中期（1500步）
% 列7：阶段3结束时（2000步，最终结果）
% 每列标注训练步数和混合系数α值
% 类别选择：选择3个代表性类别（不同性别、年龄）
\begin{figure}[htbp]
  \centering
  % \includegraphics[width=0.95\textwidth]{figures/mia_training_stages.pdf}
  \caption{MIA三阶段训练过程中生成图像的演化。每行展示一个目标类别在不同训练阶段的生成结果，从左至右依次为参考图像、阶段1、阶段2（不同混合系数α）、阶段3的关键检查点。可视化展示了从图像条件到标签条件的平滑过渡过程。}
  \label{fig:mia_training_stages}
\end{figure}

\subsubsection{LoRA配置对比可视化}

图~\ref{fig:mia_lora_comparison}对比了不同LoRA秩配置和全参数微调的生成质量。对于相同的目标类别，秩$r=8$的生成图像在细节纹理上略显不足，部分面部特征不够清晰。秩$r=16$的生成质量已接近全参数微调，面部结构、五官细节和整体真实感均达到高水平。秩$r=32$与$r=16$的视觉差异极小，但参数量和训练成本显著增加。全参数微调虽然在某些细节（如头发纹理、皮肤质感）上略优，但考虑到参数效率和训练成本，$r=16$是最优选择。该可视化结果与表~\ref{tab:mia_lora_ablation}的定量分析相互印证，验证了低秩适应技术在模型反演攻击中的有效性。

% 占位符：LoRA配置对比图
% 图像文件：figures/mia_lora_comparison.pdf
% 图像内容：4行6列网格布局
% 每列对应一个目标类别，每行对应一种配置：
% 第1行：LoRA r=8生成结果
% 第2行：LoRA r=16生成结果
% 第3行：LoRA r=32生成结果
% 第4行：全参数微调生成结果
% 每个子图标注：Acc1、FID、可训练参数量
% 类别选择：选择6个代表性类别，覆盖不同面部特征
% 图像分辨率：512x512，统一裁剪至256x256
% 局部放大：对关键区域（眼睛、嘴巴）进行放大对比
\begin{figure}[htbp]
  \centering
  % \includegraphics[width=0.95\textwidth]{figures/mia_lora_comparison.pdf}
  \caption{不同LoRA秩配置与全参数微调的生成质量对比。从上至下依次为$r=8$、$r=16$、$r=32$和全参数微调的结果。$r=16$在参数效率与生成质量之间达到最优平衡。}
  \label{fig:mia_lora_comparison}
\end{figure}

综上所述，可视化结果验证了MIA方法在保持高攻击成功率的同时,显著提升了重建图像的保真度和视觉质量。三阶段训练策略实现了从图像条件到标签条件的平滑过渡,LoRA技术在参数效率与性能之间达到良好平衡。本文提出的方法在标准设置和分布偏移设置下均表现出SOTA级别的综合性能。

\section[本章小结]{本章小结}
\label{sec:results_summary}

本章通过系统的实验验证了本文提出的模板反演攻击与模型反演攻击方法的有效性，并对关键技术组件的作用进行了深入分析。

针对模板反演攻击任务，实验结果表明基于EDM框架的方法在白盒场景下能够实现高成功率的模板重建。与现有方法相比，本文方法在攻击成功率上达到了更高的水平，同时保持了合理的生成质量。消融实验验证了角度约束特征匹配在超球面特征空间中的优势，任务不确定性加权机制能够自动平衡像素质量与特征匹配，而多样性正则化有效避免了模式崩塌问题。这些设计共同作用，使得方法能够从有限的模板向量生成高保真度的人脸图像。

针对模型反演攻击任务，实验证实了基于REFace换脸先验的方法在攻击准确率和生成保真度之间取得了良好的平衡。在VGGFace2数据集上训练的不同架构目标分类器上，方法均表现出稳定的性能，验证了跨架构的泛化能力。消融实验说明了渐进式三阶段训练策略的重要性，其通过逐步过渡实现了从图像条件到标签条件的平稳转换。LoRA参数高效微调技术使得方法仅需微调极少比例的参数就能达到接近全参数微调的效果，大幅降低了计算和存储开销。任务不确定性加权框架则自动平衡了扩散先验、分类引导、身份一致性、感知质量和正则化五个优化目标，避免了繁琐的超参数调试。

综上所述，本章实验全面验证了本文方法的有效性和泛化性。实验结果不仅展示了人脸识别系统面临的隐私泄露风险，也为防御机制的设计提供了实证依据。这些发现对于推动隐私保护技术的发展具有重要的理论和实践意义。

% Local Variables:
% TeX-master: "../main"
% TeX-engine: xetex
% End:
