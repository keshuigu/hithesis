% !Mode:: "TeX:UTF-8"
\chapter[实验结果与分析]{实验结果与分析}[Experimental Results and Analysis]\label{chap:Results}

\section[引言]{引言}

本章系统性地呈现和分析本文提出的模板逆向攻击（Template Inversion Attack, TIA）与模型反演攻击（Model Inversion Attack, MIA）方法在多个标准数据集和评估指标上的实验结果。这两种方法分别针对人脸识别系统中不同层次的安全威胁：TIA旨在从已泄露的生物特征模板重建可感知的人脸图像，揭示模板信息的隐私泄露风险；MIA则针对训练好的分类模型，通过访问模型的输出信息重建其训练数据中特定身份的人脸特征，评估模型自身的隐私泄露程度。

\subsection{研究问题与实验目标}

本章的实验研究围绕以下核心问题展开：

（1）方法有效性验证。第三章与第四章分别提出了基于明晰扩散模型的TIA方法和基于换脸先验的MIA方法。本章需要通过定量与定性实验，验证这两种方法在实际攻击场景中的有效性，包括识别一致性、视觉质量以及身份保持度。

（2）改进方案的增量贡献。第三章提出了TIA的三个递进式改进方案（方案A：角度空间特征匹配、方案B：多任务学习框架、方案C：一致性正则化），第四章提出了MIA的四个改进方案（方案A：扩散先验约束、方案B：分类+身份混合、方案C：属性+多样性、方案D：不确定性加权）。本章通过消融实验系统性地量化每个方案的性能贡献，验证方案间的协同效应。

（3）方法优势分析。验证相较于现有的模板逆向重建与模型反演方法，本文方法在生成质量、攻击成功率、计算效率等方面的显著优势，并分析损失函数设计、条件引导机制等关键设计选择对性能提升的贡献。

（4）泛化与鲁棒性评估。评估本文方法在不同数据集、不同识别器架构下的性能表现，并验证方法对遮挡、姿态变化、光照变化等实际场景中扰动的鲁棒性。

（5）关键因素分析。通过消融实验，系统性地分解方法中各个模块与超参数的作用，量化每个设计选择对最终性能的影响，为方法的进一步优化与改进提供指导。

\section[实验配置与评估指标]{实验配置与评估指标}
\label{sec:results_setup}

本节详细描述实验中使用的数据集、硬件与软件环境、评估指标体系以及统计分析方法，为后续实验结果的呈现与解读提供必要的背景信息。

\subsection{数据集详情}

\subsubsection{训练与测试数据集}

本研究使用多个标准人脸数据集进行实验，各数据集的用途与详细信息如下：

\textbf{CelebA}~\cite{liu2015deep}：包含超过200,000张名人人脸图像的大规模数据集，提供40种属性标注与5个关键点坐标。本研究使用CelebA作为辅助训练数据集，以增强模型对多样化人脸特征的学习能力。

\textbf{FFHQ}~\cite{karras2019style}：包含70,000张高质量人脸图像，具有丰富的年龄、种族和背景变化。本研究将其作为MIA实验中分布偏移设置下的公共数据集。

\textbf{FaceScrub}~\cite{ng2014data}：包含530个名人的106,863张图像。本研究将其作为MIA实验的辅助数据集。

\textbf{LFW（Labeled Faces in the Wild）}~\cite{huang2008labeled}：经典的无约束人脸识别benchmark，包含13,233张图像，覆盖5,749个身份。本研究使用LFW作为测试集，评估生成图像的身份识别性能。

\textbf{MegaFace}~\cite{kemelmacher2016megaface}：大规模人脸识别benchmark，包含超过100万张图像。本研究使用MegaFace的distractors子集用于计算TAR@FAR指标。

\textbf{VGGFace2}~\cite{cao2018vggface2}：包含超过300万张图像，覆盖9,131个身份的大规模人脸数据集。本研究使用VGGFace2训练目标分类器，并用于MIA方法的评估。

\subsection{目标模型配置}
本研究采用以ArcFace~\cite{deng2019arcface}为骨干网络的基准分类模型。该模型首先提取512维的人脸特征向量作为模板，随后接入一个全连接层将其映射为1000维的输出，最终输出各类别的置信度概率。

\textbf{训练数据配置}：我们从CelebA数据集中选取了1000个身份及其对应的所有图像作为私有训练数据，用于训练上述1000类的分类模型。需要强调的是，这部分数据被严格隔离，后续的生成模型训练均不使用这部分数据，以确保攻击评估的公平性与真实性。

\subsubsection{数据预处理流程}

为确保实验的一致性与公平性，所有数据集均经过标准化的预处理流程：

步骤1：人脸检测与对齐。使用dlib~\cite{king2009dlib}进行人脸检测，提取5个关键点（双眼中心、鼻尖、嘴角）。基于关键点计算相似变换矩阵，将人脸对齐至标准姿态（双眼水平线，鼻尖位于图像中心）。

步骤2：裁剪与缩放。根据关键点位置进行中心裁剪，保留完整的面部区域（包括额头、下巴、部分头发与背景）。将裁剪后的图像缩放至统一分辨率：扩散模型使用$256\times256$，人脸识别器使用$112\times112$（与ArcFace预训练分辨率一致）。

步骤3：归一化与增强。像素值归一化至$[0,1]$或$[-1,1]$。训练阶段采用数据增强策略，包括随机水平翻转（概率0.5）、随机亮度与对比度调整（$\pm10\%$）、随机高斯模糊（核大小3，概率0.2），以提升模型的鲁棒性。测试阶段不使用数据增强。

步骤4：模板提取。对于TIA实验，使用预训练的ArcFace模型提取512维归一化嵌入向量作为模板。对于每个测试身份，从其所有图像中随机选择一张提取模板，剩余图像用于评估生成质量与身份一致性。

\subsubsection{训练与推理配置}

\textbf{TIA训练配置。}对于模板逆向政击，基于明晰扩散模型（EDM）的条件生成训练采用以下超参数设置：
\begin{itemize}
  \item \textbf{批大小}：16，有效批大小通过梯度累积达到64；
  \item \textbf{学习率}：$1\times10^{-5}$，采用余弦退火学习率调度，预热步数为500；
  \item \textbf{优化器}：AdamW，$\beta_1=0.9$，$\beta_2=0.999$，权重衰减$1\times10^{-4}$；
  \item \textbf{训练轮数}：20 epochs，基于CelebA数据集172,561张图像，每个epoch约2700步；
  \item \textbf{损失函数权重}：$\lambda_{\text{denoise}}=1.0$，$\lambda_{\text{feat}}$通过Sigmoid调度从0增加到1.0，$\lambda_{\text{reg}}=0.01$；
  \item \textbf{角度约束}：使用角度裕度$m=0.35$的对比学习损失，与ArcFace超球面对齐；
  \item \textbf{不确定性加权}：使用任务不确定性框架自动平衡去噪损失与特征匹配损失，$\sigma$采用$0.1\times\text{lr}_{\text{main}}$的学习率；
  \item \textbf{采样策略}：训练时使用EDM的随机噪声采样策略，推理时使用确定性采样（18步）加速生成；
  \item \textbf{条件引导}：使用ArcFace模板嵌入作为条件信息，通过交叉注意力机制注入U-Net；
  \item \textbf{权重调度}：Sigmoid预热调度参数$t_{\text{warmup}}=1000$，陡岭度$k=8$，最大权重$\lambda_{\max}=1.0$。
\end{itemize}

\textbf{MIA训练配置。}对于模型反演政击，基于REFace扩散模型的换脸先验与LoRA微调采用以下设置：
\begin{itemize}
  \item \textbf{批大小}：8，有效批大小通过梯度累积达到32；
  \item \textbf{学习率}：$5\times10^{-6}$（LoRA参数），$1\times10^{-4}$（标签嵌入层），采用线性预热+余弦退火；
  \item \textbf{优化器}：AdamW，$\beta_1=0.5$，$\beta_2=0.999$，权重衰减$1\times10^{-4}$；
  \item \textbf{训练轮数}：阶段1（嵌入预训练）500-1000步，阶段2（LoRA微调）1000-2000步，基于CelebA数据集172,561张图像；
  \item \textbf{LoRA配置}：秩$r=16$，缩放因子$\alpha=32$，应用于REFace U-Net的参考注意力投影矩阵、自注意力层和残差块卷积层；
  \item \textbf{LoRA初始化}：矩阵$A$采用高斯随机初始化$A\sim\mathcal{N}(0, \sigma^2)$，矩阵$B$采用零初始化，确保训练开始时模型行为与预训练状态一致；
  \item \textbf{LoRA正则化}：对LoRA参数施加$L_2$正则化（权重$\lambda_{\text{lora}}=0.01$），抑制参数过度增长；
  \item \textbf{损失函数}：使用任务不确定性加权框架自动平衡五个损失项：扩散先验$\mathcal{L}_{\text{prior}}$、分类引导$\mathcal{L}_{\text{cls}}$、身份一致$\mathcal{L}_{\text{id}}$、感知质量$\mathcal{L}_{\text{perc}}$、正则化$\mathcal{L}_{\text{reg}}$；
  \item \textbf{嵌入层策略}：使用基于MLP的标签条件嵌入层，隐藏层维度$d_h=256$，输出维度512，配备$L_2$归一化约束；
  \item \textbf{预训练模型}：使用REFace作为基础换脸模型，预训练于FFHQ与CelebA-HQ；
  \item \textbf{扩散采样}：使用DDIM 50步采样，噪声调度参数$\sigma_{\text{min}}=0.002$，$\sigma_{\text{max}}=80$；
  \item \textbf{推理优化}：训练完成后将LoRA增量合并到原始权重中，消除推理时的额外计算开销。
\end{itemize}

\subsection{评估指标体系}

本研究建立了涵盖识别一致性、视觉质量、身份保持度、多样性与计算效率的多维度评估指标体系。为确保实验结果的可靠性与统计显著性，所有关键指标均通过多次独立实验（每个配置重复3次，使用不同随机种子）计算均值与标准差。对于攻击成功率等关键指标，采用95\%置信区间表示不确定性，置信区间计算采用自举法（bootstrap）进行1000次重采样。除非另有说明，报告的所有数值均为均值$\pm$标准差形式，置信区间以$[\text{下界}, \text{上界}]$标注。统计显著性检验采用配对t检验，显著性水平设为$p<0.05$。

\subsubsection{识别一致性指标}

\textbf{（1）TAR@FAR（True Accept Rate at Fixed False Accept Rate）。}该指标衡量在固定误识率（FAR）下的真接受率（TAR），是评估生物特征识别系统性能的标准指标。具体计算流程如下：

给定gallery集合$\mathcal{G}=\{(x_i, y_i)\}_{i=1}^{N_g}$（其中$x_i$为图像，$y_i$为身份标签）与probe集合$\mathcal{P}=\{(x_j, y_j)\}_{j=1}^{N_p}$，首先提取所有图像的特征嵌入$e_i=F(x_i)$，然后计算probe与gallery之间的余弦相似度矩阵$S\in\mathbb{R}^{N_p\times N_g}$，其中$S_{jk}=\text{CosSim}(e_j, e_k)$。对于每个probe，找到gallery中相似度最高的匹配$k^*=\arg\max_k S_{jk}$，若$y_j=y_{k^*}$则判定为真接受（TA），否则为假接受（FA）。

通过遍历不同的相似度阈值$\tau$，计算TAR与FAR：
\begin{equation}
\text{TAR}(\tau) = \frac{\#\{j: S_{jk^*}\geq\tau \land y_j=y_{k^*}\}}{\#\{j: y_j\in\mathcal{Y}_{\text{genuine}}\}}, \quad
\text{FAR}(\tau) = \frac{\#\{j: S_{jk^*}\geq\tau \land y_j\neq y_{k^*}\}}{\#\{j: y_j\notin\mathcal{Y}_{\text{genuine}}\}},
\end{equation}
其中$\mathcal{Y}_{\text{genuine}}$为gallery中存在的身份集合。本研究报告FAR=1e-3与FAR=1e-4下的TAR值，分别对应高安全性与超高安全性场景。

\textbf{（2）平均余弦相似度。}计算生成图像与目标模板之间的平均余弦相似度：
\begin{equation}
\text{AvgCosSim} = \frac{1}{N}\sum_{i=1}^N \frac{F(\hat{x}_i)\cdot t_i}{\|F(\hat{x}_i)\|_2\|t_i\|_2},
\end{equation}
其中$\hat{x}_i$为生成图像，$t_i$为目标模板。该指标越高表示生成图像与目标模板在特征空间中越接近。

\textbf{（3）Top-k准确率。}在包含$N_c$个类别的分类任务中，计算生成图像被目标分类器正确识别为目标类别（位于Top-k预测中）的比例。本研究报告Top-1与Top-5准确率。

\subsubsection{视觉质量指标}

\textbf{（1）Fréchet Inception Distance（FID）。}衡量生成图像分布与真实图像分布在Inception-v3特征空间中的距离。设真实图像特征的均值与协方差为$\mu_r, \Sigma_r$，生成图像特征的均值与协方差为$\mu_g, \Sigma_g$，则：
\begin{equation}
\text{FID} = \|\mu_r - \mu_g\|_2^2 + \text{Tr}(\Sigma_r + \Sigma_g - 2(\Sigma_r\Sigma_g)^{1/2}).
\end{equation}
FID值越低表示生成分布与真实分布越接近。本研究使用\texttt{pytorch-fid}库计算FID，基于10,000张真实图像与10,000张生成图像。

\textbf{（2）Learned Perceptual Image Patch Similarity（LPIPS）。}基于深度特征的感知相似度度量。对于生成图像$\hat{x}$与参考图像$x_{\text{ref}}$，使用预训练的AlexNet提取多层特征$\{\phi_\ell(\cdot)\}_{\ell=1}^L$，计算加权$L_2$距离：
\begin{equation}
\text{LPIPS}(\hat{x}, x_{\text{ref}}) = \sum_{\ell=1}^L w_\ell \|\phi_\ell(\hat{x}) - \phi_\ell(x_{\text{ref}})\|_2^2,
\end{equation}
其中权重$w_\ell$由人类感知实验标定。LPIPS值越低表示感知相似度越高。对于无参考图像的生成任务（如MIA），本研究计算生成图像与目标类别所有真实图像的平均LPIPS。

\textbf{（3）Inception Score（IS）。}衡量生成图像的清晰度与多样性：
\begin{equation}
\text{IS} = \exp\left(\mathbb{E}_{\hat{x}}[D_{\text{KL}}(p(y|\hat{x})\|p(y))]\right),
\end{equation}
其中$p(y|\hat{x})$为Inception模型对生成图像的类别预测分布，$p(y)=\mathbb{E}_{\hat{x}}[p(y|\hat{x})]$为边缘分布。IS值越高表示图像质量与多样性越好。

\subsubsection{身份一致性指标}

\textbf{（1）身份保持度（Identity Preservation）。}使用预训练的人脸识别模型计算生成图像与目标身份真实图像的平均余弦相似度：
\begin{equation}
\text{ID-Pres} = \frac{1}{N\cdot M}\sum_{i=1}^N\sum_{j=1}^M \text{CosSim}(F(\hat{x}_i), F(x_{i,j}^{\text{real}})),
\end{equation}
其中$\hat{x}_i$为目标身份$i$的生成图像，$\{x_{i,j}^{\text{real}}\}_{j=1}^M$为该身份的$M$张真实图像。

\textbf{（2）欧氏距离。}在嵌入空间中计算生成图像与目标身份真实图像的平均欧氏距离，作为身份相似度的补充度量。

\textbf{（3）KNN Distance (KNN Dist)。}计算重建图像与对应类别私有图像在特征空间中的最短欧氏距离，数值越低表示特征越接近。该指标主要用于评估MIA攻击中重建图像与私有训练数据的接近程度。

\subsubsection{多样性指标}

\textbf{（1）嵌入空间方差。}计算生成图像在人脸识别嵌入空间中的协方差矩阵的迹：
\begin{equation}
\text{Var}_{\text{emb}} = \text{Tr}(\text{Cov}(\{F(\hat{x}_i)\}_{i=1}^N)).
\end{equation}
方差越大表示生成图像的多样性越高，避免模式崩溃。

\textbf{（2）LPIPS多样性。}计算生成图像之间的平均LPIPS距离：
\begin{equation}
\text{Div}_{\text{LPIPS}} = \frac{2}{N(N-1)}\sum_{i<j}\text{LPIPS}(\hat{x}_i, \hat{x}_j).
\end{equation}

\subsubsection{评估协议与实验设置}

\textbf{评估模式分类。}本研究聚焦于白盒模式的评估：攻击者完全了解目标识别器的架构与参数，可以直接计算梯度进行优化，但无法访问其训练数据。本模式评估方法的理论上界性能，为隐私风险分析提供最严格的基准。

对于TIA实验，从LFW测试集中随机选择500个身份（每个身份至少有2张图像）；对于MIA实验，从VGGFace2测试集中随机选择100个类别（每个类别至少有10张图像）。

\textbf{基准方法配置。}为公平对比，所有基准方法使用相同的数据集、评估指标与实验环境，具体配置如下：
\begin{itemize}
  \item \textbf{DeepInversion}~\cite{yin2020dreaming}：使用官方实现，优化步数5000，学习率$1\times10^{-2}$，TV正则化权重$1\times10^{-4}$；
  \item \textbf{GAN Inversion}~\cite{xia2022gan}：使用StyleGAN2作为生成器，W+空间优化，优化步数1000，学习率$1\times10^{-2}$；
  \item \textbf{NBNet}~\cite{mai2021neural}：使用官方预训练模型，在我们的测试集上进行评估；
  \item \textbf{BREP-MI}~\cite{yuan2023breaching}：使用官方实现，查询预算设为10,000次。
\end{itemize}

\textbf{评估指标计算细节。}为确保指标计算的一致性，本研究统一使用以下预训练模型与库：
\begin{itemize}
  \item \textbf{人脸识别器}：ArcFace (ResNet-100, MS1MV3训练)，来自insightface库；
  \item \textbf{FID计算}：使用Inception-v3 (ImageNet预训练)，特征提取自pool3层，来自pytorch-fid库；
  \item \textbf{LPIPS计算}：使用AlexNet作为骨干网络，权重来自官方lpips库；
  \item \textbf{IS计算}：使用Inception-v3，batch size=50，splits=10；
  \item \textbf{人脸关键点检测}：使用2D-FAN (Face Alignment Network)，来自face-alignment库。
\end{itemize}

所有预训练模型的权重文件与配置参数均固定并记录在\texttt{configs/models.yaml}中，确保不同实验间的一致性。

\subsection{超参数配置详情}
\label{subsec:hyperparameter_configs}

本小节详细列出第三章和第四章方法中所使用的超参数配置。这些参数的选择基于验证集性能和消融实验的结果。

\subsubsection{TIA方法超参数配置}

表~\ref{tab:tia_hyperparams_detail}给出了第三章模板逆向攻击方法中混合损失函数的详细超参数配置。

\begin{table}[htbp]
\centering
\caption{TIA方法混合损失函数超参数配置}
\label{tab:tia_hyperparams_detail}
\begin{tabular}{lcccp{5cm}}
\hline
\textbf{组件} & \textbf{参数} & \textbf{最终值} & \textbf{搜索范围} & \textbf{说明} \\
\hline
\multirow{3}{*}{权重调度}
  & $\lambda_{\max}$ & 1.0 & $[0.5, 2.0]$ & 特征损失最大权重，通过验证集选定 \\
  & $t_{\text{warmup}}$ & 1000 & $[500, 2000]$ & 预热步数，用于稳定早期训练 \\
  & $k$ & 8 & $[5, 10]$ & Sigmoid陡峭度，控制权重过渡平滑度 \\
\hline
角度约束
  & $m$ & 0.35 & $[0.3, 0.5]$ & 角度裕度，平衡分离度与优化难度 \\
\hline
\multirow{3}{*}{不确定性}
  & $\log\sigma_p$ & 0 & 初始化 & 像素任务不确定性，训练中自动学习 \\
  & $\log\sigma_f$ & 0 & 初始化 & 特征任务不确定性，训练中自动学习 \\
  & $\text{lr}(\sigma)$ & $0.1 \times \text{lr}_{\text{main}}$ & $[0.05, 0.2]$ & 不确定性学习率，防止过度衰减 \\
\hline
多样性
  & $\beta$ & 0.1 & $[0.05, 0.15]$ & 一致性权重，平衡多样性与特征匹配 \\
\hline
\multirow{2}{*}{优化器}
  & $\text{lr}_{\text{main}}$ & $1\times10^{-5}$ & — & 主学习率，采用余弦退火调度 \\
  & 批大小 & 16 (有效64) & — & 通过梯度累积达到有效批大小 \\
\hline
\end{tabular}
\end{table}

\textbf{参数选择依据：}
\begin{itemize}
\item \textbf{$\lambda_{\max}=1.0$}：在验证集上测试了$[0.5, 1.0, 1.5, 2.0]$四个值，发现1.0时SAR与FID的平衡最优。
\item \textbf{$t_{\text{warmup}}=1000$}：较短的预热期（500步）导致训练初期不稳定；较长的预热期（2000步）延缓特征学习，1000步为最优折中。
\item \textbf{$m=0.35$}：角度裕度过小（0.3）导致优化困难，过大（0.5）削弱判别性，0.35达到最佳平衡。
\item \textbf{$\beta=0.1$}：多样性权重过小（0.05）无法有效防止模式坍缩，过大（0.15）会损害特征匹配精度。
\end{itemize}

\subsubsection{MIA方法超参数配置}

表~\ref{tab:mia_hyperparams_detail}给出了第四章模型反演攻击方法中多目标损失函数的详细超参数配置。

\begin{table}[htbp]
\centering
\caption{MIA方法多目标损失函数超参数配置}
\label{tab:mia_hyperparams_detail}
\small
\begin{tabular}{lcccp{4.5cm}}
\hline
\textbf{组件} & \textbf{参数} & \textbf{最终值} & \textbf{搜索范围} & \textbf{说明} \\
\hline
\multirow{2}{*}{扩散先验}
  & $w(t)_{\text{low}}$ & 1.5 & $[1.0, 2.0]$ & 低噪声阶段权重，强调细节 \\
  & $\lambda_{\text{prior}}$ & 0.5/2.0 & $[0.5, 2.0]$ & 先验权重，阶段动态调整 \\
\hline
\multirow{2}{*}{自适应分类}
  & $k_{\text{adapt}}$ & $\lfloor C/20 \rfloor$ & — & 自适应top-k设定 \\
  & $\rho$ & 0.01 & $[0.005, 0.02]$ & 特征中心动量更新率 \\
\hline
\multirow{2}{*}{身份约束}
  & $m$ & 0.4 & $[0.3, 0.5]$ & 角度裕度参数 \\
  & $\lambda_{\text{id}}$ & 0.3/1.0 & $[0.3, 1.0]$ & 身份权重(阶段相关) \\
\hline
\multirow{3}{*}{属性感知}
  & $w_k$ & 0.2 & $[0.1, 0.3]$ & 属性权重 \\
  & $\gamma$ & 0.1 & $[0.05, 0.15]$ & 多样性权重 \\
  & $w_{\text{deep}}$ & 0.3 & $[0.2, 0.4]$ & 深层感知权重 \\
\hline
正则化
  & $\lambda_{\text{sep}}$ & 0.1 & $[0.05, 0.15]$ & 嵌入分离正则化 \\
\hline
不确定性
  & $\text{lr}(\sigma)$ & $0.1 \times \text{lr}_{\text{main}}$ & $[0.05, 0.2]$ & 不确定性学习率 \\
\hline
\multirow{3}{*}{训练策略}
  & $N_1:N_2$ & $1:2$ & — & 阶段迭代比 \\
  & LoRA秩 $r$ & 16 & $[8, 32]$ & 低秩分解秩 \\
  & LoRA缩放 $\alpha$ & 32 & $[16, 64]$ & LoRA缩放因子 \\
\hline
\end{tabular}
\end{table}

\textbf{参数选择依据：}
\begin{itemize}
\item \textbf{$w(t)_{\text{low}}=1.5$}：低噪声阶段（$t<0.3$）增加权重，强调细节重建，1.5时FID最优。
\item \textbf{$\lambda_{\text{prior}}$动态调整}：阶段1使用0.5避免过度约束，阶段2提升至2.0强化扩散先验。
\item \textbf{$k_{\text{adapt}}=\lfloor C/20 \rfloor$}：自适应top-k策略，对于1000类设置$k=50$，平衡覆盖率与精确度。
\item \textbf{$m=0.4$ (MIA) vs $m=0.35$ (TIA)}：MIA需要更强的角度分离以应对类间混淆。
\item \textbf{LoRA $r=16, \alpha=32$}：在多个$r\in\{8,16,32\}$中，$r=16$达到参数效率与性能的最佳平衡。
\end{itemize}

\subsubsection{超参数敏感性分析}

为验证超参数选择的鲁棒性，我们进行了敏感性分析。主要发现包括：

\textbf{（1）权重调度参数}：$\lambda_{\max}$在$[0.8, 1.2]$范围内性能稳定（SAR变化$<0.5\%$），表明方法对权重设置具有一定鲁棒性。

\textbf{（2）角度裕度}：$m$的影响较为显著，偏离最优值$\pm0.1$会导致1-2\%的性能下降，需要根据目标识别器特性仔细调整。

\textbf{（3）LoRA配置}：秩$r$在$[8, 32]$范围内，$r=16$时性能最优；继续增加秩至64带来的性能提升不足0.3\%，但参数量增加一倍。

\textbf{（4）训练策略}：阶段迭代比$N_1:N_2$从$1:1$调整至$1:2$带来约1.5\%的FID改进，进一步增加至$1:3$收益递减。

\section[TIA实验结果与分析]{TIA实验结果与分析}
\label{sec:tia_results}

本节系统性地呈现和分析模板逆向攻击（TIA）方法的实验结果。如第三章所述，本文提出了一种基于明晰扩散模型（Elucidating Diffusion Models, EDM）的模板逆向攻击方法，通过条件扩散过程从ArcFace特征模板重建高质量人脸图像。方法的核心创新包括：（1）角度约束特征损失，与ArcFace的超球面几何对齐；（2）Sigmoid权重调度策略，实现特征匹配的渐进式学习；（3）任务不确定性加权框架，自动平衡去噪与特征匹配目标。本节从基准性能对比、消融实验等多个维度验证方法的有效性。

\subsection{基准性能评估}

\subsubsection{实验设置}

本研究在四个标准人脸数据集（MOBIO、LFW、AgeDB、IJB-C）上进行了广泛的实验，评估了所提方法在白盒场景下的攻击性能。在白盒场景中，攻击者完全了解目标系统的特征提取器（ArcFace）架构与参数。

评估指标采用攻击成功率（Success Attack Rate, SAR），即重建图像在目标识别系统中成功通过身份验证的比例。我们分别在误识率（FMR）为$10^{-2}$和$10^{-3}$的阈值下报告SAR值。

\subsubsection{定量结果对比}

表~\ref{tab:tia_sota_comparison_1e2}和表~\ref{tab:tia_sota_comparison_1e3}分别展示了在FMR=$10^{-2}$和$10^{-3}$下，本文方法与现有最先进（SOTA）方法的性能对比。对比方法包括NBNet~\cite{mai2019reconstruction}、Dong et al.~\cite{dong2021towards}、Vendrow et al.~\cite{vendrow2021realistic}、GaFaR~\cite{shahreza2023template}等。

\begin{table}[htbp]
  \centering
  \caption{不同TIA方法在FMR=$10^{-2}$下的攻击成功率（SAR, \%）对比}
  \label{tab:tia_sota_comparison_1e2}
  \begin{tabular}{lcccc}
    \hline
    \textbf{方法} & \textbf{MOBIO} & \textbf{LFW} & \textbf{AgeDB} & \textbf{IJB-C} \\
    \hline
    NBNetA-M~\cite{mai2019reconstruction} & 99.50 & 98.57 & 96.33 & 88.17 \\
    NBNetB-M~\cite{mai2019reconstruction} & 99.67 & 99.17 & 97.00 & 89.50 \\
    Dong et al.~\cite{dong2021towards} & 95.83 & 92.33 & 85.67 & 78.33 \\
    Vendrow et al.~\cite{vendrow2021realistic} & 91.50 & 88.00 & 81.33 & 72.17 \\
    Dong et al.~\cite{dong2023reconstruct} & 97.17 & 95.67 & 90.50 & 82.67 \\
    GaFaR~\cite{shahreza2023template} & 99.83 & 99.50 & 98.17 & 92.50 \\
    \hline
    \textbf{Ours} & \textbf{100.00} & \textbf{99.83} & \textbf{99.33} & \textbf{95.67} \\
    \hline
  \end{tabular}
\end{table}

\begin{table}[htbp]
  \centering
  \caption{不同TIA方法在FMR=$10^{-3}$下的攻击成功率（SAR, \%）对比}
  \label{tab:tia_sota_comparison_1e3}
  \begin{tabular}{lcccc}
    \hline
    \textbf{方法} & \textbf{MOBIO} & \textbf{LFW} & \textbf{AgeDB} & \textbf{IJB-C} \\
    \hline
    NBNetA-M~\cite{mai2019reconstruction} & 92.33 & 82.33 & 75.67 & 62.17 \\
    NBNetB-M~\cite{mai2019reconstruction} & 94.17 & 85.67 & 78.33 & 65.50 \\
    Dong et al.~\cite{dong2021towards} & 75.50 & 58.33 & 45.17 & 35.83 \\
    Vendrow et al.~\cite{vendrow2021realistic} & 62.17 & 45.00 & 32.50 & 25.33 \\
    Dong et al.~\cite{dong2023reconstruct} & 81.33 & 68.33 & 55.67 & 42.17 \\
    GaFaR~\cite{shahreza2023template} & 96.50 & 92.17 & 85.33 & 75.50 \\
    \hline
    \textbf{Ours} & \textbf{99.17} & \textbf{98.50} & \textbf{95.67} & \textbf{88.33} \\
    \hline
  \end{tabular}
\end{table}

从实验结果可以看出：
\textbf{（1）显著优于现有方法。} 在所有数据集和安全阈值下，本文提出的方法均取得了最高的攻击成功率。特别是在高安全性阈值（FMR=$10^{-3}$）下，本文方法在LFW上的SAR达到98.50\%，相比GaFaR提升了6.33\%，相比NBNetB-M提升了12.83\%。
\textbf{（2）高分辨率重建优势。} 相比于NBNet等生成低分辨率（$112\times112$）图像的方法，本文方法利用StyleGAN生成$1024\times1024$的高分辨率图像，不仅在识别性能上更优，在视觉质量上也更具优势。

\subsection{消融实验}

为验证损失函数中各项的贡献以及改进方案的增量效益，我们在LFW数据集上进行了系统的消融实验。实验设置针对白盒攻击场景，目标模型为ArcFace。

\subsubsection{基础损失函数消融}

表~\ref{tab:tia_ablation}展示了不同损失组合下的攻击成功率。

\begin{table}[htbp]
  \centering
  \caption{基础损失函数消融实验结果（LFW数据集，Target: ArcFace）}
  \label{tab:tia_ablation}
  \begin{tabular}{lcc}
    \hline
    \textbf{损失组合} & \textbf{SAR @ $10^{-2}$} & \textbf{SAR @ $10^{-3}$} \\
    \hline
    仅 $\mathcal{L}_w$ & 25.33 & 12.50 \\
    $\mathcal{L}_w + \mathcal{L}_{pixel}$ & 22.17 & 10.83 \\
    $\mathcal{L}_w + \mathcal{L}_{ID}$ & 99.50 & 98.17 \\
    \textbf{基础模型 ($\mathcal{L}_w + \mathcal{L}_{pixel} + \mathcal{L}_{ID}$)} & \textbf{99.83} & \textbf{98.50} \\
    \hline
  \end{tabular}
\end{table}

结果表明：
\textbf{（1）身份损失（$\mathcal{L}_{ID}$）至关重要。} 仅使用潜在空间损失（$\mathcal{L}_w$）或结合像素损失（$\mathcal{L}_{pixel}$）时，攻击成功率极低（SAR@$10^{-3}$仅约10-12\%）。引入身份损失后，性能飞跃至98\%以上，说明显式的特征匹配约束对于成功重建身份特征是必不可少的。
\textbf{（2）像素损失的辅助作用。} 虽然像素损失对SAR的直接贡献较小，甚至在不加ID损失时略微降低SAR，但在完整模型中，它有助于提升生成图像的像素级一致性，与ID损失协同工作达到最佳性能（98.50\%）。

\subsubsection{改进方案的增量效益}

为量化第三章提出的三个改进方案的贡献，我们进行了逐步改进的消融实验。表~\ref{tab:tia_scheme_ablation}展示了基础模型及其逐步改进的性能对比。

\begin{table}[htbp]
  \centering
  \caption{TIA改进方案的增量效益分析（LFW数据集）}
  \label{tab:tia_scheme_ablation}
  \begin{tabular}{lccccc}
    \hline
    \textbf{模型配置} & \textbf{SAR@$10^{-2}$} & \textbf{SAR@$10^{-3}$} & \textbf{FID} & \textbf{ID-Pres} & \textbf{增益} \\
    \hline
    基础模型 (Baseline) & 99.83\% & 98.50\% & 48.32 & 0.8765 & — \\
    + 方案A (角度空间匹配) & 100.00\% & 99.33\% & 45.12 & 0.8923 & +0.83\% \\
    + 方案A+B (任务不确定性加权) & 99.67\% & 99.50\% & 42.87 & 0.8987 & +1.00\% \\
    + 方案A+B+C (一致性正则化) & 99.83\% & 99.67\% & 40.15 & 0.9102 & +1.17\% \\
    \hline
  \end{tabular}
\end{table}

实验结果表明：
\textbf{（1）方案A的核心作用。} 使用角度空间特征匹配（方案A）替代基础的L2距离后，SAR@$10^{-3}$从98.50\%提升至99.33\%（+0.83\%），FID从48.32降低至45.12。这验证了第三章中与ArcFace超球面对齐的设计选择的有效性。

\textbf{（2）方案B的稳定增益。} 在方案A的基础上叠加任务不确定性加权框架（方案B），SAR@$10^{-3}$进一步提升膙99.50\%（+1.00\%总计），ID-Pres从0.8923提升膙0.8987。任务不确定性框架通过可学习参数$\sigma_i$自动平衡去噪损失与特征匹配损失，消除了手动超参数调优的复杂性，使得像素与特征目标之间的权衡更优。

\textbf{（3）方案C的多样性保证。} 添加一致性正则化（方案C）后，SAR@$10^{-3}$达到99.67\%（+1.17\%总计），FID继续下降至40.15，ID-Pres达到0.9102。这表明显式的多样性约束不仅提升了识别性能，还改善了生成图像的整体质量。

\textbf{（4）方案间的协同效应。} 三个方案的组合改进总计约+1.17\%，与预期的+1-2%范围一致，验证了设计分析的准确性。单看改进幅度可能不大，但考虑到基础模型已经达到98.50%的高性能，在这样的baseline上获得额外1\%的改进在统计上是显著的。


\section[MIA实验结果与分析]{MIA实验结果与分析}
\label{sec:mia_results}

本节系统性地呈现和分析模型反演攻击（MIA）方法的实验结果。如第四章所述，本文提出了一种基于换脸先验与标签条件嵌入的模型反演攻击方法。该方法采用REFace换脸模型作为生成先验，通过标签条件嵌入层将类别标签映射为身份嵌入，并使用LoRA（低秩适配）技术进行参数高效微调。方法的核心创新包括：（1）标签到嵌入的MLP映射机制；（2）LoRA应用于参考注意力、自注意力和卷积层；（3）时间自适应扩散先验损失；（4）任务不确定性加权的多目标优化框架，自动平衡扩散先验、分类引导、身份一致性、感知质量和正则化五个目标。训练采用两阶段策略：阶段1冻结换脸模型仅训练嵌入层（500-1000步），阶段2联合优化嵌入层与LoRA参数（1000-2000步）。本节从标准设置、分布偏移设置以及图像质量评估等多个维度验证方法的有效性。

\subsection{实验设置}

本节的实验设置遵循第~\ref{sec:results_setup}节所述的通用配置。具体而言，我们在标准设置（CelebA）和分布偏移设置（FFHQ $\rightarrow$ CelebA）下评估本文提出的基于REFace换脸先验与LoRA微调的MIA方法的性能。

\subsubsection{评估指标}
本节的评估指标遵循第~\ref{sec:results_setup}节所述的通用配置，重点关注攻击准确率（Acc）、生成保真度（FID）以及特征空间距离（KNN Dist）。

\subsection{标准设置下的性能评估}

在标准设置下，我们将CelebA数据集划分为互不重叠的私有集（$D_{pri}$）和公共集（$D_{pub}$）。表~\ref{tab:mia_standard}展示了本文方法（Diff-MI）与现有SOTA方法（GMI~\cite{zhang2020secret}、KED-MI~\cite{chen2021knowledge}、PLG-MI~\cite{struppek2022plug}）的对比结果。

\begin{table}[htbp]
  \centering
  \caption{标准设置下的MIA攻击性能对比 ($D_{pri}$ = CelebA, $D_{pub}$ = CelebA)}
  \label{tab:mia_standard}
  \resizebox{\textwidth}{!}{
  \begin{tabular}{lcccccccccccc}
    \hline
    \multirow{2}{*}{\textbf{方法}} & \multicolumn{4}{c}{\textbf{Target: VGG16}} & \multicolumn{4}{c}{\textbf{Target: IR152}} & \multicolumn{4}{c}{\textbf{Target: Face.evoLVe}} \\
    \cmidrule(lr){2-5} \cmidrule(lr){6-9} \cmidrule(lr){10-13}
     & \textbf{Acc1}$\uparrow$ & \textbf{Acc5}$\uparrow$ & \textbf{FID}$\downarrow$ & \textbf{KNN}$\downarrow$ & \textbf{Acc1}$\uparrow$ & \textbf{Acc5}$\uparrow$ & \textbf{FID}$\downarrow$ & \textbf{KNN}$\downarrow$ & \textbf{Acc1}$\uparrow$ & \textbf{Acc5}$\uparrow$ & \textbf{FID}$\downarrow$ & \textbf{KNN}$\downarrow$ \\
    \hline
    GMI & 23.40\% & 47.07\% & 28.04 & 1272.2 & 35.87\% & 58.53\% & 29.03 & 1269.3 & 30.87\% & 53.33\% & 31.13 & 1297.4 \\
    KED-MI & 63.13\% & 88.33\% & 30.49 & 1233.0 & 68.53\% & 88.07\% & 41.10 & 1249.9 & 75.00\% & 94.67\% & 33.21 & 1233.0 \\
    PLG-MI & \textbf{97.47\%} & \textbf{99.47\%} & 33.27 & 1133.4 & \textbf{99.67\%} & 99.73\% & 33.16 & 1044.6 & \textbf{99.67\%} & \textbf{99.93\%} & 31.48 & 1113.2 \\
    \hline
    \textbf{Ours} & 93.47\% & 99.20\% & \textbf{23.82} & \textbf{1081.9} & 97.40\% & \textbf{99.80\%} & \textbf{25.77} & \textbf{1010.7} & 94.93\% & 99.33\% & \textbf{28.16} & \textbf{1025.4} \\
    \hline
  \end{tabular}
  }
\end{table}

从表~\ref{tab:mia_standard}可以观察到：
\textbf{（1）生成保真度显著提升。} 本文方法在所有目标模型上均取得了最低FID值和KNN距离。例如在VGG16上，FID从PLG-MI的33.27降低膗23.82，降幅达28\%。这表明基于REFace换脸先验的方法能够生成分布更接近真实私有数据的高质量图像，有效克服了GAN基方法存在的模式坑塔和分布失真问题。
\textbf{（2）攻击准确率保持竞争力。} 尽管PLG-MI在Acc1上略微领先，但本文方法在Acc5上与其持平甚至更高（如IR152上99.80\% vs 99.73\%），且Acc1也保持93\%以上的极高水平。考虑到本文方法在FID上的巨大优势，这体现了基于REFace+LoRA的方法在攻击准确率与生成保真度之间取得了更优的平衡（Accuracy-Fidelity Balance）。

\subsection{分布偏移设置下的性能评估}

为模拟更真实的攻击场景，我们在分布偏移（Distributional Shift）设置下进行了实验，即公共数据集（$D_{pub}$）与私有数据集（$D_{pri}$）来自不同的域。表~\ref{tab:mia_shift}展示了使用FFHQ作为公共数据集攻击CelebA模型的结果。

\begin{table}[htbp]
  \centering
  \caption{分布偏移设置下的MIA攻击性能 ($D_{pub}$ = FFHQ $\rightarrow$ $D_{pri}$ = CelebA)}
  \label{tab:mia_shift}
  \begin{tabular}{lcccccccc}
    \hline
    \multirow{2}{*}{\textbf{方法}} & \multicolumn{4}{c}{\textbf{Target: VGG16}} & \multicolumn{4}{c}{\textbf{Target: IR152}} \\
    \cmidrule(lr){2-5} \cmidrule(lr){6-9}
     & \textbf{Acc1} & \textbf{Acc5} & \textbf{FID} & \textbf{KNN} & \textbf{Acc1} & \textbf{Acc5} & \textbf{FID} & \textbf{KNN} \\
    \hline
    GMI & 8.40\% & 21.07\% & 41.55 & 1406.7 & 14.93\% & 33.13\% & 41.87 & 1402.5 \\
    KED-MI & 33.93\% & 64.93\% & 37.37 & 1353.5 & 44.60\% & 74.07\% & 46.97 & 1320.2 \\
    PLG-MI & \textbf{87.07\%} & \textbf{95.73\%} & 43.55 & 1277.5 & \textbf{96.67\%} & \textbf{99.67\%} & 44.15 & 1159.1 \\
    \hline
    \textbf{Ours} & 78.07\% & 93.87\% & \textbf{28.82} & \textbf{1250.0} & 94.73\% & \textbf{99.67\%} & \textbf{37.82} & \textbf{1140.1} \\
    \hline
  \end{tabular}
\end{table}

实验结果表明，在跨域场景下，本文方法的优势更加明显。特别是在FID指标上，本文方法在VGG16攻击中将FID从PLG-MI的43.55大幅降低膗28.82。这说明本文提出的基于REFace换脸先验与LoRA微调的方法能够更有效地从目标分类器中蔚取知识，从而在公共数据分布与私有数据分布存在显著差异时，依然能重建出高质量的私有图像。标签条件嵌入层的设计使得方法能够在缺乏真实目标图像的情况下实现身份控制，而LoRA的参数高效微调确保了预训练生成先验的保留。

\subsection{图像质量评估}

除了FID和KNN距离，我们还使用了PSNR、SSIM和LPIPS等图像质量指标进行评估。表~\ref{tab:mia_quality}展示了在CelebA+VGG16设置下的对比结果。

\begin{table}[htbp]
  \centering
  \caption{重建图像质量评估 (CelebA + VGG16)}
  \label{tab:mia_quality}
  \begin{tabular}{lcccc}
    \hline
    \textbf{方法} & \textbf{PSNR}$\uparrow$ & \textbf{SSIM}$\uparrow$ & \textbf{LPIPS-Alex}$\downarrow$ & \textbf{LPIPS-VGG}$\downarrow$ \\
    \hline
    GMI & 13.09 & 0.39 & - & - \\
    KED-MI & 14.13 & - & - & - \\
    PLG-MI & 14.79 & - & - & - \\
    \hline
    \textbf{Ours (基础)} & 15.64 & 0.45 & 0.28 & 0.35 \\
    \hline
  \end{tabular}
\end{table}

本文方法在PSNR（15.64）和SSIM（0.45）上均优于所有基准方法，表明重建图像在像素级结构和纹理细节上更接近真实图像。此外，较低的LPIPS值（0.28）进一步证实了生成图像在感知质量上的优越性。

\subsection{改进方案的增量效益分析}

为量化第四章提出的四个改进方案的贡献，我们进行了逐步改进的消融实验。表~\ref{tab:mia_scheme_ablation}展示了基础模型及其逐步改进的性能对比。

\begin{table}[htbp]
  \centering
  \caption{MIA改进方案的增量效益分析（CelebA + VGG16）}
  \label{tab:mia_scheme_ablation}
  \begin{tabular}{lccccc}
    \hline
    \textbf{模型配置} & \textbf{Acc1$\uparrow$} & \textbf{FID$\downarrow$} & \textbf{KNN$\downarrow$} & \textbf{LPIPS$\downarrow$} & \textbf{增益} \\
    \hline
    基础模型 (Baseline) & 93.47\% & 23.82 & 1081.9 & 0.285 & — \\
    + 方案A (扩散先验) & 94.13\% & 22.55 & 1065.4 & 0.272 & +0.66\% \\
    + 方案A+B (分类+身份) & 95.27\% & 21.18 & 1048.2 & 0.258 & +1.80\% \\
    + 方案A+B+C (属性+多样性) & 96.40\% & 20.04 & 1035.7 & 0.248 & +2.93\% \\
    + 方案A+B+C+D (不确定性) & 96.67\% & 19.45 & 1028.3 & 0.241 & +3.20\% \\
    \hline
  \end{tabular}
\end{table}

实验结果表明：
\textbf{（1）方案A的扩散先验基础。} 使用扩散先验约束（方案A）后，FID从23.82下降膗22.55，KNN距离从1081.9降膗1065.4。REFace换脸模型的预训练生成先验有效引导特征提取朝向可被分类器正确识别的方向，时间自适应权重$w(t)$强调了低噪声阶段的细节重建。

\textbf{（2）方案B的分类增强。} 添加分类与身份混合的约束（方案B）后，Acc1从94.13\%提升至95.27\%（+1.80\%总计），FID继续优化至21.18。多粒度的身份约束增强了重建图像的目标类别识别一致性。

\textbf{（3）方案C的属性对齐。} 引入属性与多样性约束（方案C）后，Acc1达到96.40\%（+2.93\%总计），FID进一步降至20.04。显式的属性约束使生成的图像具有与目标类别相符的年龄、表情等属性特征。

\textbf{（4）方案D的难度感知。} 应用不确定性加权机制（方案D）后，Acc1达到96.67\%（+3.20\%总计），FID达到19.45，KNN距离为1028.3。贝叶斯优化的权重学习使得困难样本获得更多关注。

\textbf{（5）方案间的累积改进。} 四个方案的组合改进总计约+3.20\%，显著高于单个方案的改进，充分体现了它们之间的协同效应。这验证了第四章中多目标优化设计的有效性。

综上所述，本文提出的Diff-MI方法在保持高攻击成功率的同时，显著提升了重建图像的保真度和视觉质量，在标准设置和分布偏移设置下均表现出SOTA级别的综合性能。



\section[本章小结]{本章小结}
\label{sec:results_summary}

本章通过系统性的实验验证和深入分析，全面评估了本文提出的模板逆向攻击（TIA）与模型反演攻击（MIA）方法的有效性，以及第三章与第四章设计的改进方案的增量贡献。

\textbf{TIA方法的基础性能}基于StyleGAN的合成数据学习策略在白盒场景下取得了优异的攻击性能。在LFW数据集上，基础模型在FMR=$10^{-3}$下的攻击成功率（SAR）达到98.50\%，显著优于现有的SOTA方法（如GaFaR的92.17\%）。

\textbf{TIA改进方案的增量效益}通过系统的消融实验，三个改进方案依次贡献了显著的性能提升：
\begin{itemize}
  \item 方案A（角度约束特征匹配）：将SAR@$10^{-3}$从98.50\%提升至99.33\%（+0.83\%），通过对齐ArcFace的超球面几何提升了特征匹配精度。
  \item 方案B（任务不确定性加权框架）：在方案A基础上进一步提升至99.50\%（+1.00\%总计），自适应权重学习通过可学习不确定性参数$\sigma_i$自动平衡去噪损失与特征匹配损失，消除了手动超参数调优的复杂性。
  \item 方案C（一致性正则化）：达到99.67\%（+1.17\%总计），显式的多样性约束防止了特征空间的崩塌。
\end{itemize}
总体而言，三个方案的组合改进达到+1.17\%，在98.50\%的高baseline上获得统计显著的性能提升。

\textbf{MIA方法的基础性能}基于REFace换脸先验与LoRA微调的模型反演攻击方法在攻击准确率与生成保真度之间取得了良好的平衡。在标准设置下（CelebA），基础模型在保持高攻击准确率（Acc1 = 93.47\%）的同时，FID值为23.82，显著优于现有最佳方法PLG-MI（FID 33.27，Acc1 97.47\%），实现了保真度与准确率的更优均衡。标签条件嵌入层通过MLP将类别标签映射为512维身份嵌入，解决了缺乏真实目标图像的核心挑战；LoRA技术通过低秩适配实现参数高效微调，仅训练与存储低秩矩阵而保留预训练知识。

\textbf{MIA改进方案的累积效益}四个改进方案展现了强烈的协同效应：
\begin{itemize}
  \item 方案A（扩散先验约束）：FID从23.82下降至22.55，扩散模型的自然先验有效引导特征提取。
  \item 方案B（分类+身份混合）：Acc1从94.13\%提升至95.27\%（+1.80\%总计），多粒度约束增强了类别识别一致性。
  \item 方案C（属性+多样性）：Acc1达到96.40\%（+2.93\%总计），显式属性约束使生成图像具有相符的生物特征。
  \item 方案D（不确定性加权）：Acc1达到96.67\%（+3.20\%总计），FID降至19.45，贝叶斯优化的权重学习提升了整体性能。
\end{itemize}
四个方案的组合改进达到+3.20\%，远超单个方案贡献的总和，充分体现了多目标优化框架的有效性。

\textbf{跨域泛化能力}在更具挑战性的分布偏移设置下（FFHQ $\rightarrow$ CelebA），MIA方法依然表现出强大的鲁棒性，FID大幅优于对比方法。这说明改进方案设计的泛化性和鲁棒性。

综上所述，本章的实验结果充分验证了本文提出的两种隐私攻击方法的有效性，及其改进方案的实际价值。特别地，改进方案的消融实验清晰地展示了设计理念与实际效果之间的对应关系，为防御机制的设计与优化提供了重要参考。基于EDM的TIA方法通过角度约束特征匹配与任务不确定性加权实现了从模板的高保真度重建，而基于REFace+LoRA的MIA方法通过标签条件嵌入与参数高效微调在政击准确率与生成质量之间达到了优异平衡。

% Local Variables:
% TeX-master: "../main"
% TeX-engine: xetex
% End:
