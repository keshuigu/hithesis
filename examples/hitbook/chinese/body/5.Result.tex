% !Mode:: "TeX:UTF-8"

% TODO (写作提示):
% - 对关键实验结果给出重复实验的统计（均值 ± 标准差 或 置信区间），并在表格或注释中标明重复次数 N。
% - 增加消融实验汇总表，系统化展示各模块（如微调策略、损失项权重）的贡献。
% - 在结果图/表下方标注用于生成/评估的脚本路径与参数（例如：scripts/eval.py, resources/metric_config.json）。

\chapter[实验结果与分析]{实验结果与分析}[Experimental Results and Analysis]
这是 \hithesis\ 的示例文档，基本上覆盖了模板中所有格式的设置。建议大家在使用模
板之前，除了阅读《\hithesis\:哈尔滨工业大学学位论文模板》\footnote{即
hithesis.pdf文件}，本示例文档也最好能看一看。此示例文档尽量使用到所有的排版格式
，然而对于一些不在我工规范中规定的文档，理论上是由用户自由发挥，这里不给出样例
。需要另行载入的宏包和自定义命令在文件`hithesis.sty'中有示例，这里不列举。

\section[实验结果]{实验结果}
针对以上的训练流程和推理流程方案,本实验采用公开的人脸图像数据集 CelebA 作为基础数据集进行了初步试验。CelebA 数据集包含10177个不同身份的202599张人脸图像, 广泛应用于人脸识别和生成模型等相关研究。在攻击目标模型的选择上, 本课题采用了当前主流的人脸识别模型 ArcFace。ArcFace是一种基于残差网络结构的人脸识别模型, 通过引入角度间隔损失, 显著提升了特征的判别性和区分度。该模型能够将同一身份的特征向量聚集在一起, 同时有效拉开不同身份之间的特征距离, 从而在大规模人脸识别任务中实现更高的准确率。

数据集的准备工作包括对 CelebA 数据集进行预处理, 提取人脸图像特征并保存为数据对, 具体步骤如下:
(1)根据CelebA数据集的提供的人脸关键点信息, 对人脸图像进行裁剪和对齐, 调整图片尺寸为112, 确保人脸位于图像中心, 并且大小一致。
(2)使用ArcFace模型对每张图像进行特征提取, 得到对应的特征模板, 设置与图像的对应关系。
(3)将裁剪后的图像根据图像与人物类别的对应关系进行标注, 并根据人物类别不相交的原则, 将数据集划分为训练和测试数据集, 其中训练集包含9669个人物共192241张人脸图像, 测试集包含508个人物共10358张图像。

训练过程中, 为平衡生成图像与特征模板之间的相似度和生成图像与原始输入图像之间的相似度, 采用了动态的线性权重 $\lambda$。具体来说, 在训练的初期, $\lambda$ 的值较小, 以确保模型能够先学习到图像的基本结构和特征; 随着训练的进行, 逐渐增大 $\lambda$ 的值, 以增强生成图像与特征模板之间的匹配度。这样可以有效地提高生成图像的质量和与目标模板的相似度。实验中, $\lambda$ 的初始值设置为0, 并在训练过程中逐渐增加到100。具体的调整策略为: 模型每学习1000张图像, 将 $\lambda$ 增加0.01, 在10000次迭代后, 直到达到最大值100。

训练中损失函数变化如图\ref{fig:edm_template_attack_loss}所示:

\begin{figure}[htbp]
  \centering
  \includegraphics[width=0.8\textwidth]{images/loss_curve.png}
  \caption{基于EDM的模板逆向攻击训练过程损失函数变化曲线}
  \label{fig:edm_template_attack_loss}
\end{figure}

其中 $id\,loss$ 和 $EDM\,loss$ 分别表示模板信息一致性损失和图像重建的像素损失。由于$id\,loss$实际值较小, 图中将其放大了1000倍以便于观察。可以看出, 随着训练的进行, 图像重建的像素损失先于模板信息一致性损失收敛, 表明模型在学习过程中首先关注的是还原人脸图像的基础结构和像素细节, 使生成图像能够在视觉上与原始图像保持较高的一致性。随着训练的深入, $\lambda$逐渐增加, 模型的优化重心逐渐转向提升生成图像与目标特征模板之间的匹配度。此时, 模板信息一致性损失开始显著下降, 模型不断学习如何更好地捕捉和还原与目标身份相关的深层特征。整体来看, 损失函数的变化趋势反映了模型从低层像素信息到高层语义特征的逐步学习过程。

在模板逆向攻击的推理阶段, 使用训练好的EDM扩散模型对测试集中的特征模板进行攻击。首先, 从分割好的测试集中随机选取1000个特征模板, 构建隐私数据库。随后, 将这些特征模板作为条件输入, 引导EDM扩散模型进行图像生成。

采样过程中, 参数设置如下: 迭代次数$steps = 18$,
终止点噪声幅度$\sigma_{\text{min}} = 0.002$,初始点噪声幅度$\sigma_{\text{max}} = 80$, 噪声调度参数$\rho = 7 $, 采样范围参数$S_{\text{churn}} = 0$, $S_{\text{min}} = 0$, $S_{\text{max}} = \infty$, 噪声扰动参数$S_{\text{noise}} = 1$。这些参数的选择基于EDM扩散模型的设计原则, 旨在平衡生成图像的多样性和质量。

生成的图像随后输入ArcFace模型进行特征提取, 并与隐私数据库中的特征模板进行匹配。通过计算生成图像特征与目标模板的相似度, 若相似度高于设定阈值(根据系统精度需求设定, 实验中采用0.5), 则认为该生成图像成功重建了与目标模板匹配的原始输入图像。

% - **迭代次数(steps=18)**: 扩散模型在生成图像时进行的去噪步数, 步数越多, 生成图像质量通常越高, 但计算量也越大。
% - **sigma_min=0.002**: 扩散过程中的最小噪声幅度, 决定了去噪的终止点, 影响最终生成图像的细节还原。
% - **sigma_max=80**: 扩散过程中的最大噪声幅度, 决定了初始噪声的强度, 影响生成过程的多样性。
% - **rho=7**: 控制噪声调度的参数, 影响噪声幅度在采样过程中的变化速率。
% - **S_churn=0**、**S_min=0**、**S_max=float("inf")**、**S_noise=1**: 这些参数用于进一步调节采样过程中的噪声扰动和采样范围, 通常用于提升生成图像的多样性和稳定性。

实验结果显示, 所提出的方法在模板逆向攻击任务中取得了较高的攻击准确率, 达到92\%。这表明生成的图像能够有效地欺骗目标识别模型, 使其输出与目标模板高度一致的特征。部分生成图像如图\ref{fig:edm_tia_sample}所示。可以看出, 所提出的方法能够有效地重建与目标特征模板相匹配的人脸图像。生成的人脸图像在整体结构、面部特征等方面与原始输入图像高度相似, 且具备较高的视觉质量, 但部分生成图像存在图像模糊、细节缺失等现象, 需要进一步提升效果。生成图像的质量评价指标结果如表\ref{tab:quality_metrics}所示。
\begin{figure}[!htbp]
  \centering
  \includegraphics[width=0.8\textwidth]{images/gen_vs_real_matrix.png}
  \caption{模板逆向攻击生成图像与真实图像对比样例}
  \label{fig:edm_tia_sample}
\end{figure}

\begin{table}[htbp]
  \centering
  \begin{tabular}{lc}
    \hline
    指标         & 数值              \\
    \hline
    FID        & 22.3193         \\
    KID        & 0.0075 ± 0.0005 \\
    LPIPS Alex & 0.3129          \\
    LPIPS Vgg  & 0.4854          \\
    \hline
  \end{tabular}
  \caption{各项图像质量评价指标结果}
  \label{tab:quality_metrics}
\end{table}

% LPIPS (alex): 0.31297400742024184
% LPIPS (vgg): 0.48543246793746947
% Frechet Inception Distance: 22.31930493655588
% Kernel Inception Distance: 0.007591125510510506 ± 0.0005495588712487208

% Local Variables:
% TeX-master: "../main"
% TeX-engine: xetex
% End:
