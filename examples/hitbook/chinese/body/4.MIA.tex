% !Mode:: "TeX:UTF-8"

% TODO (写作提示):
% - 注明所用先验换脸模型的具体来源（模型名称/论文/仓库链接）与预训练权重信息。
% - 说明微调时冻结/解冻了哪些网络层（例如冻结主干，只训练标签嵌入层），并给出对应层名或代码路径。
% - 建议补充评估协议与基线：使用哪些基线方法比较，评价指标如何统一计算。

\chapter[面向人脸分类模型的逆向重建方法]{面向人脸分类模型的逆向重建方法}[Reconstruction Method for Face Classification Models]
\section{引言}
本章讨论面向图像分类/人脸识别模型的模型反演攻击（Model Inversion Attack, MIA），重点研究如何在有限可用信息下利用生成式先验（以换脸/扩散生成模型为代表）重建训练数据的敏感样本。与针对模板/嵌入的逆向重建不同，面向分类器的反演通常只能获得类别标签或置信度分布，因此需要设计既能保留视觉质量又能提升分类器响应的条件生成与优化方法。

本章的目标是：
\begin{itemize}
\item 形式化面向分类器反演问题的输入/输出与攻击假设，明确白盒/半白盒/黑盒下的可行策略；
\item 提出一种结合生成式先验与判别模型引导的两阶段重建流程（基础生成 + LoRA 微调 / 优化），并给出可复现的训练与推理管线；
\item 设计系统化的实验与评估协议，用以衡量重建图像在分类器认同度、感知质量与多样性之间的权衡。
\end{itemize}

本章结构如下：第~\ref{sec:mia_objectives} 节给出攻击目标与评估协议；第~\ref{sec:mia_method} 节介绍结合生成模型的反演方法与训练细节；第~\ref{sec:mia_lora} 节讨论基于低秩适配的微调策略与工程实践；最后给出实验设计与本章小结。

\section{攻击目标与评估协议}
\label{sec:mia_objectives}
\subsection{攻击目标（形式化）}
设目标分类器为 $F:\mathcal{X}\to\Delta^{C-1}$，其中 $\mathcal{X}$ 为像素空间或潜在表示空间，$\Delta^{C-1}$ 为 $C$ 类的概率单纯形。攻击者给定目标类别索引 $y_t$，目标是构造一组生成样本 $\{\hat{x}_i\}_{i=1}^K$，使得对多数样本 $\hat{x}_i$，有 $F(\hat{x}_i)_{y_t}$ 足够大（大于阈值 $\tau$），同时图像具有较高的感知质量。更一般地，攻击者希望同时优化两个目标：
\begin{equation}
	ext{maximize}_{\hat{x}}\; \; F(\hat{x})_{y_t} \quad \text{s.t.} \quad \text{PerceptualDistance}(\hat{x},\mathcal{P}_{y_t}) \;\text{small},
\end{equation}
其中 $\mathcal{P}_{y_t}$ 表示真实类别 $y_t$ 的分布（未知），PerceptualDistance 可由 LPIPS 等衡量。

\subsection{威胁模型}
我们考虑下列常见威胁模型：
\begin{itemize}
\item 白盒（full white-box）: 攻击者可完全访问 $F$ 的权重、结构与梯度；可用于基于梯度的直接优化或将分类器融入训练损失。\
\item 得分/置信度可查询黑盒（score-query black-box）: 攻击者可以对 $F$ 输入样本并获得置信度向量或 logits，但无法访问内部权重。\
\item 标签/判决黑盒（label-only）: 仅获得类别决策或 top-k 输出，不返回置信度。\
\item 受限制查询（budgeted）: 在以上任一黑盒模型下，攻击者的查询次数受限（例如每个目标 $\leq Q$ 次）。
\end{itemize}

\subsection{评估协议与基线}
评估应从三方面衡量：
\begin{enumerate}
\item 识别一致性：衡量生成样本被目标分类器接受为目标类别的比率（例如 $\Pr[F(\hat{x})_{y_t}\ge\tau]$）及 TAR@FAR（把生成样本作为 probe，在指定 gallery 下计算真接受率）；\
\item 感知质量与多样性：使用 FID、LPIPS、SSIM 等衡量生成样本的视觉质量与与真实分布的距离，并报告样本多样性（例如基于嵌入的聚类半径）；\
\item 查询/计算成本：记录查询数量、微调所需计算（GPU·小时）与平均单样本生成时间。
\end{enumerate}

基线方法包括：随机初始化的梯度优化（DeepInversion/gradient-based inversion）、使用预训练生成模型的简单重构（无微调）、以及针对分类器的判别式优化方法。我们在实验中将与这些基线进行量化比较。

\section{结合生成式模型的重建方法}
\label{sec:mia_method}
本节提出一种实用的生成式反演框架，框架由三部分组成：先验生成器 $G$、识别器引导模块 $H$、以及微调/适配器模块 $\Delta$。总体思路是利用生成器提供高质量样本空间，再通过判别器/分类器的信号对生成过程进行引导或微调，使生成样本更易被目标分类器识别为 $y_t$。

\subsection{框架概述}
给定预训练生成器 $G_{\phi}$（可选为换脸模型或隐空间扩散模型）和目标分类器 $F$，我们考虑两类方法：
\begin{itemize}
\item 优化式引导（optimization-guided）: 固定 $G$，在潜在空间 $z$ 或输入空间上直接优化目标函数
$$\arg\max_z\; F(G_{\phi}(z))_{y_t} - \lambda\,\mathcal{R}(z),$$
其中 $\mathcal{R}$ 为正则化项（例如潜在正则或感知损失）。\
\item 微调式适配（adaptation-based）: 对 $G_{\phi}$ 应用轻量微调（例如 LoRA/Adapter），学习一个小的增量 $\Delta$ 使得 $G_{\phi+\Delta}$ 的输出更符合分类器的判别面。训练目标通常包含分类器损失与感知/重建损失的加权组合。
\end{itemize}

两类方法可以组合使用：先通过优化式引导寻找良好初始化，再对 $G$ 进行 LoRA 微调以扩大可接受样本空间。

\subsection{损失构成与训练目标}
训练时常用的损失项包括：
\begin{itemize}
\item 分类损失 $\mathcal{L}_{cls} = -\log F(\hat{x})_{y_t}$ 或交叉熵/对比损失；\
\item 感知损失 $\mathcal{L}_{perc}$（例如 VGG/LPIPS），保持视觉质量；\
\item 正则化项 $\mathcal{L}_{reg}$（潜在空间正则、参数范数），防止模式崩溃与过拟合；\
\item 可选对抗损失 $\mathcal{L}_{adv}$ 以提升细节真实感（若采用 GAN 风格判别器）。
\end{itemize}

综合目标：
$$\mathcal{L} = \lambda_{cls}\mathcal{L}_{cls} + \lambda_{perc}\mathcal{L}_{perc} + \lambda_{reg}\mathcal{L}_{reg} + \lambda_{adv}\mathcal{L}_{adv}.$$

在白盒情形下，可直接反向传播分类损失到生成器参数或潜在；在黑盒情形下，可使用基于评分的估计、近似梯度（ZSGrad）或查询-高效的进化/贝叶斯优化方法。

\subsection{推理与采样策略}
推理时可采用：
\begin{itemize}
\item 多次随机潜在采样 + 局部优化并选择最高置信度输出；\
\item 结合 classifier-free guidance 或能量引导（在扩散模型中）插入额外梯度以提升 $F(\cdot)_{y_t}$；\
\item 若可用 LoRA 权重，可先动态加载 LoRA 再采样，减少每次采样所需的优化步数。
\end{itemize}

\section{基于低秩适配技术的微调训练方法}
\label{sec:mia_lora}
针对分类器反演的微调策略，我们优先使用参数高效的低秩适配（LoRA）方法，以在少量样本和低算力环境下实现可重复的微调。

\subsection{作用层与参数化}
建议在生成器的下列子模块中应用 LoRA：跨注意力 (cross-attn) 的投影矩阵、注意力的 output projection、以及 MLP 的第一/第二线性层。对这些层应用低秩增量可显著改变生成输出而不影响原模型的全局稳定性。

参数化形式同 TIA 部分所述：$W' = W + BA$，仅学习小矩阵 $A,B$ 并记录秩 $r$ 与缩放 $\alpha$。

\subsection{训练流程与超参建议}
训练流程建议：
\begin{enumerate}
\item 数据准备：选取每一目标类别下的少量代表样本作为微调集（N-shot），并准备相应的替换源（若使用换脸输入）。\
\item 冻结主干：仅解冻并训练 LoRA 参数与少数条件层；使用小 lr（$\le 1\mathrm{e}{-4}$）与较强的权重衰减以减少过拟合。\
\item 校验与早停：在独立验证集上监控 $F(\hat{x})_{y_t}$ 与感知指标，采用早停或 checkpoint 平均策略。
\end{enumerate}

常用起始超参（建议记录并汇报）：$r\in\{4,8,16\}$，$\alpha\in\{8,16\}$，lr=$1\mathrm{e}{-5}\sim1\mathrm{e}{-4}$，微调步数 500--3000，batch size 根据显存调整（1--8）。

\subsection{合并、部署与可重复性}
训练完成后可选择将 LoRA 权重合并进 base checkpoint 以便部署，或保留增量以便快速切换不同目标。每次微调都应保存训练命令、环境信息、随机种子与中间检查点以保证可重复性。

\section{本章小结}
本章系统地讨论了面向分类模型的模型反演问题，提出了基于生成式先验与识别器引导相结合的两类方案（优化引导与微调适配），并详细说明了基于 LoRA 的参数高效微调策略与实验设计要点。下一章将实现并报告具体实验结果与消融研究。
% Local Variables:
% TeX-master: "../main"
% TeX-engine: xetex
% End:
