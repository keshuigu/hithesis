% !Mode:: "TeX:UTF-8"

\chapter{基于换脸先验的模型反演攻击方法}[Model Inversion Attack Based on Face Swapping Prior]\label{chap:MIA}

\section{引言}

模型反演攻击旨在从训练好的分类模型中重建其训练数据的敏感特征，对生物特征识别系统的隐私安全构成严重威胁。传统基于梯度优化的方法直接在像素空间进行优化，面临生成质量低下、缺乏语义约束、优化效率低等问题。近年来，生成式先验模型的引入为模型反演攻击提供了新的技术路径，其中换脸模型因其独特的身份控制能力而成为理想选择。

然而，换脸模型通常需要目标图像作为身份输入，而在模型反演攻击场景中，攻击者仅拥有类别标签而无法获取目标身份的真实图像。本章针对这一核心挑战，提出了一种基于换脸先验与标签条件嵌入的模型反演攻击方法。该方法通过设计标签条件嵌入层将类别标签映射为身份表示，并采用低秩适配技术对换脸模型进行参数高效微调，在保持生成质量的同时实现对目标分类器的高效适配。

本章首先对模型反演攻击问题进行形式化定义，明确威胁模型与评估标准；随后详细阐述基于换脸先验的方法架构，包括标签条件嵌入层设计、LoRA微调策略以及多目标优化损失函数框架；最后给出完整的训练与推理流程，为方法的实现与复现提供系统化指导。

\section{问题定义与威胁模型}
\label{sec:mia_problem}

\subsection{模型反演攻击的形式化定义}

模型反演攻击旨在从训练好的分类模型中重建其训练数据的敏感特征。形式化地，设目标分类器为 $F_\theta:\mathcal{X}\to\mathbb{R}^C$，其中 $\mathcal{X}$ 为输入空间（如 $\mathbb{R}^{H\times W\times 3}$ 表示RGB图像），$C$ 为类别数量，$\theta$ 为模型参数。分类器 $F_\theta$ 通常在训练集 $\mathcal{D}_{\text{train}}=\{(x_i, y_i)\}_{i=1}^N$ 上训练，其中 $x_i\in\mathcal{X}$ 为输入样本，$y_i\in\{1,2,\ldots,C\}$ 为对应的类别标签。

模型反演攻击的目标是：给定目标类别标签 $y_{\text{target}}\in\{1,2,\ldots,C\}$ 以及对分类器 $F_\theta$ 的特定访问权限，攻击者希望生成一组图像 $\{\hat{x}_1, \hat{x}_2, \ldots, \hat{x}_K\}$，使得这些图像满足以下条件：

（1）分类器认同度（Classifier Confidence）。生成的图像 $\hat{x}_k$ 应被目标分类器 $F_\theta$ 以高置信度识别为目标类别 $y_{\text{target}}$，即：
\begin{equation}\label{eq:mia_classifier_conf}
    \Pr[F_\theta(\hat{x}_k)_{y_{\text{target}}} \geq \tau] \geq 1-\epsilon,
\end{equation}
其中 $F_\theta(\hat{x})_{y}$ 表示分类器对输入 $\hat{x}$ 预测为类别 $y$ 的置信度或logit值，$\tau$ 为置信度阈值，$\epsilon$ 为容忍的失败率。

（2）感知真实性（Perceptual Realism）。生成的图像 $\hat{x}_k$ 应具有高感知质量，在视觉上与真实人脸图像无明显差异，即：
\begin{equation}\label{eq:mia_perceptual}
    d_{\text{perc}}(\hat{x}_k, \mathcal{X}_{\text{real}}) \leq \delta,
\end{equation}
其中 $d_{\text{perc}}$ 为感知距离度量（如LPIPS、FID），$\mathcal{X}_{\text{real}}$ 为真实图像分布，$\delta$ 为可接受的感知误差上界。

（3）身份相关性（Identity Relevance）。生成的图像 $\hat{x}_k$ 应包含目标类别 $y_{\text{target}}$ 对应身份的特征信息，而非与该类别无关的随机人脸。这一要求可通过与目标类别训练样本的相似度进行量化：
\begin{equation}\label{eq:mia_identity_rel}
    \text{sim}(\hat{x}_k, \mathcal{X}_{y_{\text{target}}}) \geq \gamma,
\end{equation}
其中 $\mathcal{X}_{y_{\text{target}}}$ 为目标类别的真实训练样本（攻击者通常无法访问，仅用于评估），$\text{sim}(\cdot,\cdot)$ 为相似度度量（如人脸识别嵌入的余弦相似度），$\gamma$ 为相似度下界。

（4）多样性（Diversity）。生成的多个图像 $\{\hat{x}_k\}_{k=1}^K$ 应具有合理的多样性，覆盖目标类别在不同姿态、表情、光照、年龄等属性下的变化，避免模式崩溃（mode collapse）：
\begin{equation}\label{eq:mia_diversity}
    \text{Var}(\{\hat{x}_k\}_{k=1}^K) \geq \rho,
\end{equation}
其中 $\text{Var}(\cdot)$ 为多样性度量（如特征空间的方差、聚类数量），$\rho$ 为多样性下界。

综合上述四个目标，模型反演攻击可形式化为以下约束优化问题：
\begin{equation}\label{eq:mia_objective}
\begin{aligned}
    \max_{\{\hat{x}_k\}_{k=1}^K} \quad & \sum_{k=1}^K F_\theta(\hat{x}_k)_{y_{\text{target}}} \\
    \text{s.t.} \quad & d_{\text{perc}}(\hat{x}_k, \mathcal{X}_{\text{real}}) \leq \delta, \quad \forall k, \\
    & \text{sim}(\hat{x}_k, \mathcal{X}_{y_{\text{target}}}) \geq \gamma, \quad \forall k, \\
    & \text{Var}(\{\hat{x}_k\}_{k=1}^K) \geq \rho.
\end{aligned}
\end{equation}

在实际应用中，这一多目标优化问题通常通过加权损失函数进行求解，各约束条件以正则化项或软约束的形式融入优化目标。

根据攻击者对目标分类器 $F_\theta$ 的访问权限不同，模型反演攻击可分为白盒、灰盒和黑盒三类威胁模型。本章主要关注白盒威胁模型，即攻击者拥有目标分类器的完整信息，包括模型架构、参数 $\theta$ 以及完整的梯度信息。该模型为评估模型的最大隐私泄露风险提供了上界，对应于模型开源、内部泄露或逆向工程成功的场景。在白盒威胁模型下，攻击者可以直接利用梯度信息进行基于优化的攻击，将分类器的损失函数融入生成模型的训练目标，实现端到端的优化。这一设定为深入研究模型反演攻击的方法设计与性能边界提供了理想的实验环境。

\subsection{评估指标体系}

为全面评估模型反演攻击的性能,本章从以下维度设计评估指标:

（1）攻击成功率：衡量生成图像被目标分类器正确识别为目标类别的比例。对于置信度阈值 $\tau$,定义攻击成功率为:
\begin{equation}\label{eq:mia_asr}
    \text{ASR}(\tau) = \frac{1}{K}\sum_{k=1}^K \mathbb{I}[F_\theta(\hat{x}_k)_{y_{\text{target}}} \geq \tau],
\end{equation}
其中 $\mathbb{I}[\cdot]$ 为指示函数。

（2）感知质量指标：评估生成图像的视觉真实性,主要包括Fréchet Inception Distance (FID)、Learned Perceptual Image Patch Similarity (LPIPS)等指标,分别衡量生成图像分布与真实图像分布的距离以及感知相似度。

（3）身份一致性指标：评估生成图像与目标类别训练样本的身份相似度。使用预训练的人脸识别模型提取嵌入向量,计算余弦相似度:
\begin{equation}\label{eq:mia_cosine_sim}
    \text{CosSim}(\hat{x}_k, \mathcal{X}_{y_{\text{target}}}) = \frac{1}{|\mathcal{X}_{y_{\text{target}}}|} \sum_{x\in\mathcal{X}_{y_{\text{target}}}} \frac{\langle f(\hat{x}_k), f(x)\rangle}{\|f(\hat{x}_k)\|_2 \|f(x)\|_2},
\end{equation}
其中 $f(\cdot)$ 为人脸识别模型的嵌入函数。

（4）多样性指标：评估生成图像集合的内部变化程度,通过计算嵌入空间方差或聚类数量来量化,避免模式崩溃现象。

本章在后续方法设计与实验评估中,将以上述指标为基础,全面衡量模型反演攻击方法的有效性与威胁程度。

\section{基于换脸先验的模型反演架构}
\label{sec:mia_architecture}

本节详细阐述所提模型反演攻击方法的总体架构。如图~\ref{fig:mia_architecture}所示，该架构由三个核心模块组成：（1）预训练换脸模型（Face Swapping Prior Model），作为生成先验提供高质量的人脸图像生成能力；（2）标签条件嵌入层（Label-Conditioned Embedding Layer），将目标类别标签映射为换脸模型可接受的身份嵌入向量；（3）LoRA微调模块（LoRA Adaptation Module），对换脸模型进行参数高效的微调，使其适配目标分类器的决策边界。

\begin{figure}[htbp]
    \centering
    % TODO: 添加架构示意图
    % \includegraphics[width=0.9\textwidth]{figures/mia_architecture.pdf}
    \caption{基于换脸先验的模型反演攻击架构示意图。左侧为标签条件嵌入层，将类别标签映射为身份嵌入；中间为换脸模型，接受身份嵌入与源图像生成目标图像；右侧为目标分类器，提供分类损失用于微调。}
    \label{fig:mia_architecture}
\end{figure}

整个系统的前向传播流程可形式化描述如下：

步骤1：标签到嵌入的映射。给定目标类别标签 $y_{\text{target}}\in\{1,2,\ldots,C\}$，标签条件嵌入层 $\mathcal{E}_{\psi}$ 将其映射为身份嵌入向量 $e_{\text{id}}\in\mathbb{R}^{d_e}$：
\begin{equation}\label{eq:mia_label_to_emb}
    e_{\text{id}} = \mathcal{E}_{\psi}(y_{\text{target}}),
\end{equation}
其中 $\psi$ 为嵌入层的可学习参数，$d_e$ 为嵌入维度（通常为512或1024）。

步骤2：换脸生成。预训练换脸模型 $G_{\phi}$ 接受身份嵌入 $e_{\text{id}}$ 与源图像 $x_{\text{src}}$（提供姿态、表情、光照等属性信息）作为输入，生成目标图像 $\hat{x}$：
\begin{equation}\label{eq:mia_face_swap}
    \hat{x} = G_{\phi}(e_{\text{id}}, x_{\text{src}}),
\end{equation}
其中 $\phi$ 为换脸模型的参数。在标准换脸任务中，$e_{\text{id}}$ 通常由目标图像通过身份编码器提取；而在本章的模型反演任务中，$e_{\text{id}}$ 由标签条件嵌入层直接生成，无需真实的目标图像。

步骤3：分类器评估与反馈。生成的图像 $\hat{x}$ 输入目标分类器 $F_\theta$，获得对目标类别的置信度：
\begin{equation}\label{eq:mia_classifier_eval}
    p_{y_{\text{target}}} = F_\theta(\hat{x})_{y_{\text{target}}}.
\end{equation}
该置信度用于计算分类器引导损失，并通过反向传播更新标签条件嵌入层 $\mathcal{E}_{\psi}$ 与换脸模型 $G_{\phi}$（通过LoRA微调）的参数。

\subsection{换脸先验模型的选择与分析}

换脸模型作为本章方法的核心生成先验，其选择对最终攻击性能有决定性影响。理想的换脸模型应满足以下要求：

（1）高质量的身份迁移能力。换脸模型应能够在保持源图像属性的前提下，精确地将目标身份特征迁移至生成图像中，确保生成图像的身份一致性。

（2）解耦的身份-属性表示。换脸模型应具有显式的身份-属性解耦机制，使得身份信息与姿态、表情、光照等属性信息分离，便于通过修改身份嵌入实现对生成结果的精确控制。

（3）高感知质量与真实感。生成的图像应在视觉上与真实人脸无明显差异，包括皮肤纹理、光照一致性、边界融合等细节。

（4）计算效率与可微性。换脸模型应具有合理的计算开销，支持端到端的梯度反向传播，以便与目标分类器联合训练。

基于上述要求，本章选择REFace~\cite{sanoojan2024reface}作为换脸先验模型。REFace（Reference-based Face Swapping）是一种基于扩散模型的换脸方法，通过参考注意力机制（Reference Attention）实现高保真的身份迁移。相比传统GAN-based方法，REFace具有以下优势：（1）更高的生成质量与细节保真度；（2）更强的身份-属性解耦能力；（3）基于扩散模型的稳定训练过程；（4）支持端到端的梯度反向传播。REFace的架构如下：

身份编码器（Identity Encoder）。REFace使用预训练的ArcFace模型作为身份编码器 $E_{\text{id}}$，将输入图像 $x$ 映射为512维的身份嵌入向量：
\begin{equation}\label{eq:mia_id_encoder}
    e_{\text{id}} = E_{\text{id}}(x) \in \mathbb{R}^{512}.
\end{equation}
在标准REFace流程中，$x$ 为参考图像；而在本章的模型反演任务中，该步骤被标签条件嵌入层替代。

扩散模型主干（Diffusion Backbone）。REFace采用潜在扩散模型（Latent Diffusion Model, LDM）作为生成主干，通过变分自编码器（VAE）将图像编码到潜在空间。源图像 $x_{\text{src}}$ 首先被编码为潜在表示 $z_{\text{src}} = \text{VAE}_{\text{enc}}(x_{\text{src}})$，然后在潜在空间中进行扩散去噪过程：
\begin{equation}\label{eq:mia_diffusion}
    z_t = \sqrt{\bar{\alpha}_t} z_0 + \sqrt{1-\bar{\alpha}_t} \epsilon, \quad \epsilon \sim \mathcal{N}(0, I),
\end{equation}
其中 $t$ 为扩散时间步，$\bar{\alpha}_t$ 为噪声调度参数。

参考注意力机制（Reference Attention）。REFace的核心创新是参考注意力机制，通过交叉注意力将身份嵌入 $e_{\text{id}}$ 注入到U-Net去噪网络的各层中。在每个U-Net层 $\ell$，参考注意力计算为：
\begin{equation}\label{eq:mia_ref_attn}
    \text{RefAttn}(Q, K_{\text{ref}}, V_{\text{ref}}) = \text{Softmax}\left(\frac{QK_{\text{ref}}^T}{\sqrt{d}}\right) V_{\text{ref}},
\end{equation}
其中 $Q$ 为源图像特征的查询（Query），$K_{\text{ref}}, V_{\text{ref}}$ 为从身份嵌入 $e_{\text{id}}$ 投影得到的键（Key）和值（Value）。参考注意力使得去噪过程能够关注并提取身份嵌入中的身份特征，同时保持源图像的属性信息。

去噪U-Net（Denoising U-Net）。REFace采用条件U-Net架构作为去噪网络 $\epsilon_{\theta}$，预测并移除潜在表示中的噪声。U-Net在每个注意力层中集成参考注意力机制，实现身份信息的注入：
\begin{equation}\label{eq:mia_unet}
    \epsilon_{\theta}(z_t, t, e_{\text{id}}) = \text{U-Net}(z_t, t, \text{RefAttn}(z_t, e_{\text{id}})).
\end{equation}
去噪完成后，通过VAE解码器将潜在表示解码为图像：$\hat{x} = \text{VAE}_{\text{dec}}(z_0)$。

REFace的训练采用扩散模型的标准目标函数，结合身份一致性损失与感知损失。预训练的REFace模型在大规模人脸数据集（如FFHQ、CelebA-HQ）上训练，学习到强大的人脸生成先验与身份迁移能力，为模型反演攻击提供了高质量的基础。

\subsection{标签条件嵌入层的替换机制}

标准换脸模型接受目标图像作为输入，通过身份编码器提取身份嵌入。然而，在模型反演攻击场景中，攻击者仅拥有目标类别标签，无法获取真实的目标图像。因此，需要设计标签条件嵌入层来替代身份编码器，实现从离散标签到连续嵌入的映射。

标签条件嵌入层的设计有两种主要策略：

\subsubsection{基于查找表的嵌入层（Lookup Table-based Embedding）}

最直接的方法是为每个类别分配一个可学习的嵌入向量，构建查找表（Embedding Table）：
\begin{equation}\label{eq:mia_lookup_table}
    \mathcal{E}_{\psi} = \{e_1, e_2, \ldots, e_C\}, \quad e_i \in \mathbb{R}^{d_e},
\end{equation}
其中 $e_i$ 为类别 $i$ 的嵌入向量，$\psi = \{e_1, e_2, \ldots, e_C\}$ 为可学习参数。给定目标类别 $y_{\text{target}}$，嵌入操作为简单的索引查找：
\begin{equation}\label{eq:mia_lookup}
    e_{\text{id}} = e_{y_{\text{target}}}.
\end{equation}

基于查找表的嵌入层具有以下优点：
\begin{itemize}
    \item 参数高效：总参数量为 $C\times d_e$，对于中小规模分类任务（如 $C\leq 1000$）开销可控；
    \item 训练简单：无需额外的网络结构，直接通过梯度下降优化嵌入向量；
    \item 表达灵活：每个类别独立优化，可以学习到类别特定的身份表示。
\end{itemize}

然而，查找表方法也存在局限：
\begin{itemize}
    \item 泛化能力弱：无法处理训练时未见过的类别（zero-shot设置）；
    \item 参数随类别数线性增长：当 $C$ 很大（如 $C>10000$）时，参数量与存储开销显著增加；
    \item 缺乏结构先验：不同类别的嵌入向量相互独立，无法利用类别间的相似性或层次结构。
\end{itemize}

\subsubsection{基于MLP的嵌入层（MLP-based Embedding）}

为增强嵌入层的表达能力与泛化性，可以采用多层感知机（MLP）将类别标签的one-hot编码或预训练的类别嵌入映射为身份嵌入：
\begin{equation}\label{eq:mia_mlp_emb}
    e_{\text{id}} = \text{MLP}_{\psi}(\text{OneHot}(y_{\text{target}})),
\end{equation}
其中 $\text{MLP}_{\psi}$ 为多层感知机，$\psi$ 为其参数。MLP通常包含2-3个隐藏层，配备ReLU激活函数与LayerNorm：
\begin{equation}\label{eq:mia_mlp_structure}
    \text{MLP}_{\psi}(x) = W_3 \cdot \text{ReLU}(\text{LN}(W_2 \cdot \text{ReLU}(\text{LN}(W_1 \cdot x + b_1)) + b_2)) + b_3,
\end{equation}
其中 $W_1\in\mathbb{R}^{d_h\times C}, W_2\in\mathbb{R}^{d_h\times d_h}, W_3\in\mathbb{R}^{d_e\times d_h}$ 为权重矩阵，$d_h$ 为隐藏层维度。

基于MLP的嵌入层具有以下优点：
\begin{itemize}
    \item 表达能力强：通过非线性变换，可以学习类别标签与身份嵌入之间的复杂映射关系；
    \item 参数效率高：当 $C$ 很大时，MLP的参数量 $O(C\cdot d_h + d_h^2 + d_h\cdot d_e)$ 可能低于查找表的 $O(C\cdot d_e)$；
    \item 泛化能力强：若使用预训练的类别嵌入（如Word2Vec、BERT嵌入）作为输入，MLP可以利用类别间的语义相似性，实现一定程度的zero-shot泛化。
\end{itemize}

然而，MLP方法也有缺点：
\begin{itemize}
    \item 训练复杂度高：需要调优隐藏层维度、层数、激活函数等超参数；
    \item 过拟合风险：当训练数据有限时，MLP可能过拟合到训练类别，难以泛化；
    \item 计算开销增加：相比查找表的 $O(1)$ 索引操作，MLP需要 $O(C\cdot d_h + d_h^2)$ 的矩阵乘法。
\end{itemize}

\subsubsection{混合嵌入策略（Hybrid Embedding Strategy）}

为兼顾查找表的灵活性与MLP的泛化能力，可以采用混合嵌入策略：
\begin{equation}\label{eq:mia_hybrid_emb}
    e_{\text{id}} = \alpha \cdot e_{y_{\text{target}}} + (1-\alpha) \cdot \text{MLP}_{\psi}(\text{OneHot}(y_{\text{target}})),
\end{equation}
其中 $\alpha\in[0,1]$ 为权重系数，$e_{y_{\text{target}}}$ 为查找表中的嵌入向量。在训练初期，可以设置较大的 $\alpha$（如0.8），使嵌入以查找表为主，快速收敛；随着训练进行，逐步降低 $\alpha$（如0.5），让MLP发挥更大作用，提升泛化能力。

\subsection{嵌入层与换脸模型的接口匹配}

标签条件嵌入层生成的身份嵌入 $e_{\text{id}}$ 需要与换脸模型的ID注入模块兼容。具体地，需要确保：

（1）维度匹配。嵌入层输出的 $e_{\text{id}}$ 维度应与换脸模型的身份编码器输出维度一致。对于REFace，该维度为512（ArcFace嵌入维度）。若嵌入层输出维度不同，需添加线性投影层进行维度对齐：
\begin{equation}\label{eq:mia_dim_align}
    e_{\text{id}}^{\text{aligned}} = W_{\text{proj}} \cdot e_{\text{id}} + b_{\text{proj}},
\end{equation}
其中 $W_{\text{proj}}\in\mathbb{R}^{512\times d_e}$ 为投影矩阵。

（2）分布匹配。嵌入层生成的 $e_{\text{id}}$ 的数值分布应与真实身份嵌入的分布相近，以保证换脸模型的正常工作。实践中，可以通过以下策略实现分布匹配：
\begin{itemize}
    \item 归一化约束：对嵌入向量进行 $L_2$ 归一化，使其位于单位超球面上，与ArcFace嵌入的归一化特性一致：
    \begin{equation}\label{eq:mia_emb_norm}
        e_{\text{id}} \leftarrow \frac{e_{\text{id}}}{\|e_{\text{id}}\|_2}.
    \end{equation}
    \item 范数正则化：在损失函数中添加范数正则项，鼓励嵌入向量的范数接近真实嵌入的平均范数：
    \begin{equation}\label{eq:mia_norm_reg}
        \mathcal{L}_{\text{norm}} = (\|e_{\text{id}}\|_2 - \mu_{\text{norm}})^2,
    \end{equation}
    其中 $\mu_{\text{norm}}$ 为真实嵌入范数的统计平均值（对于归一化后的ArcFace嵌入，$\mu_{\text{norm}}=1$）。
    \item 分布对齐损失：计算生成嵌入与真实嵌入在统计量（均值、方差、协方差）上的距离，通过最小化该距离实现分布对齐。
\end{itemize}

\subsection{架构的端到端可微性}

所提架构的一个关键设计原则是端到端可微性，即从目标分类器的损失到标签条件嵌入层的参数，存在完整的梯度传播路径。这一特性使得可以通过标准的反向传播算法，利用目标分类器的监督信号直接优化嵌入层与换脸模型（通过LoRA）的参数。

端到端可微性的实现依赖于以下条件：
\begin{itemize}
    \item 标签条件嵌入层 $\mathcal{E}_{\psi}$ 的所有操作（查找表索引、MLP前向传播）均为可微操作；
    \item 换脸模型 $G_{\phi}$ 的前向传播（包括AdaIN、卷积、激活函数）均为可微操作；
    \item 目标分类器 $F_\theta$ 在白盒威胁模型下，可以直接计算梯度 $\nabla_{\hat{x}} F_\theta(\hat{x})_{y_{\text{target}}}$。
\end{itemize}

在白盒威胁模型下，梯度可以直接通过自动微分工具（如PyTorch、TensorFlow）计算。

端到端可微性不仅简化了训练流程，还使得可以灵活地引入多种损失项（分类损失、感知损失、正则化损失）进行联合优化，为方法的性能提升提供了广阔空间。

\section{标签条件嵌入层的实现与优化}
\label{sec:mia_embedding}

本节深入探讨标签条件嵌入层的实现细节,包括初始化策略与优化方法。

\subsection{嵌入层的初始化策略}

嵌入层的初始化对训练的收敛速度与最终性能有重要影响。最直接有效的初始化方法是利用目标分类器训练集中的真实图像来初始化嵌入向量。对于每个目标类别 $y$,从训练集中采样该类别的图像,使用换脸模型的身份编码器提取身份嵌入,计算其均值作为该类别的初始嵌入向量:
\begin{equation}\label{eq:mia_init_center}
    e_y^{\text{init}} = \frac{1}{M}\sum_{m=1}^M E_{\text{id}}(x_y^{(m)}),
\end{equation}
其中 $E_{\text{id}}$ 为身份编码器,$\{x_y^{(m)}\}_{m=1}^M$ 为类别 $y$ 的样本。初始嵌入向量需归一化至单位超球面:
\begin{equation}\label{eq:mia_init_norm}
    e_y^{\text{init}} \leftarrow \frac{e_y^{\text{init}}}{\|e_y^{\text{init}}\|_2}.
\end{equation}

当无法访问训练集时,可从标准正态分布随机采样初始嵌入向量,或利用预训练的语言模型提取类别的语义嵌入进行初始化。

\subsection{嵌入层的正则化与约束}

为防止嵌入向量在训练过程中偏离真实身份嵌入的分布,需要引入正则化与约束机制。

\subsubsection{范数约束}

强制嵌入向量位于单位超球面上,与ArcFace嵌入的几何结构一致。实现方式通常采用硬约束,在每次参数更新后显式地归一化嵌入向量:
\begin{equation}\label{eq:mia_hard_norm}
    e_y \leftarrow \frac{e_y}{\|e_y\|_2}.
\end{equation}

\subsubsection{类间分离正则化}

为避免不同类别的嵌入向量过于接近,可以引入类间分离正则化,鼓励不同类别的嵌入在嵌入空间中彼此分离:
\begin{equation}\label{eq:mia_separation_reg}
    \mathcal{L}_{\text{sep}} = -\lambda_{\text{sep}} \sum_{i\neq j} \langle e_i, e_j \rangle.
\end{equation}

该正则化最小化嵌入间的余弦相似度,防止模式崩溃,提升生成图像的多样性。

\subsection{嵌入层的训练策略}

建议采用分阶段训练策略以加速收敛:首先冻结换脸模型,仅优化标签条件嵌入层,使其快速学习到能够欺骗目标分类器的嵌入表示;随后解冻LoRA参数,联合优化嵌入层与换脸模型,进一步提升生成质量与分类器认同度。

嵌入层与LoRA参数的学习率应区别设置:嵌入层从头训练,使用较大学习率;LoRA参数在预训练基础上微调,使用较小学习率以避免破坏预训练权重。训练过程中应采用梯度裁剪策略以保持稳定性。

\section{基于LoRA的换脸模型微调方法}
\label{sec:mia_lora}

本节详细阐述如何使用低秩适配（LoRA）技术对预训练换脸模型进行参数高效的微调。

\subsection{LoRA应用于换脸模型的动机}

直接对换脸模型进行全参数微调面临参数量巨大、过拟合风险高、可能破坏预训练知识等挑战。LoRA技术通过在冻结预训练权重的前提下引入低秩可训练增量,有效解决了上述问题:仅需训练与存储低秩矩阵,参数量降低至原模型的1\%-5\%;低秩约束起到隐式正则化作用,降低过拟合风险;原始权重冻结,预训练的生成先验得以保留。模块化部署：多个任务共享基础模型，仅需保存各自的LoRA权重，存储开销极低。

\subsection{LoRA在换脸模型中的应用位置}

根据换脸模型的架构特点与模型反演任务的需求，LoRA应优先应用于以下关键模块：

\subsubsection{参考注意力的投影矩阵}

REFace的参考注意力机制通过键值投影将身份嵌入映射到注意力空间。对于第 $\ell$ 层的参考注意力，键值投影定义为：
\begin{equation}\label{eq:mia_lora_ref_attn}
    K_{\text{ref}} = W_K^{\ell} \cdot e_{\text{id}}, \quad V_{\text{ref}} = W_V^{\ell} \cdot e_{\text{id}},
\end{equation}
其中 $W_K^{\ell}, W_V^{\ell}$ 为键值投影矩阵。

对这些投影矩阵应用LoRA：
\begin{equation}\label{eq:mia_lora_ref_proj}
\begin{aligned}
    W_K^{\ell\prime} &= W_K^{\ell} + \frac{\alpha}{r} B_K^{\ell} A_K^{\ell}, \\
    W_V^{\ell\prime} &= W_V^{\ell} + \frac{\alpha}{r} B_V^{\ell} A_V^{\ell},
\end{aligned}
\end{equation}
其中 $A_K^{\ell}, A_V^{\ell}\in\mathbb{R}^{r\times 512}$，$B_K^{\ell}, B_V^{\ell}\in\mathbb{R}^{d_h\times r}$。

应用LoRA到参考注意力投影矩阵的优势在于：这些矩阵直接控制身份嵌入如何被编码到注意力空间中，是身份信息注入的核心机制。微调这些参数能够调整模型对身份特征的关注程度，使生成图像更易被目标分类器识别。

\subsubsection{U-Net的自注意力和交叉注意力层}

REFace的去噪U-Net包含多层自注意力和交叉注意力模块。自注意力用于特征的全局建模，交叉注意力（除参考注意力外）用于融合时间步条件等信息。应在这些注意力的投影矩阵上应用LoRA：
\begin{equation}\label{eq:mia_lora_attn}
\begin{aligned}
    W_Q' &= W_Q + \frac{\alpha}{r} B_Q A_Q, \\
    W_K' &= W_K + \frac{\alpha}{r} B_K A_K, \\
    W_V' &= W_V + \frac{\alpha}{r} B_V A_V, \\
    W_O' &= W_O + \frac{\alpha}{r} B_O A_O,
\end{aligned}
\end{equation}
其中 $W_Q, W_K, W_V, W_O$ 分别为Query、Key、Value与输出投影矩阵。

注意力机制负责特征的全局聚合与重组，对生成图像的整体结构与细节有重要影响。微调注意力投影可以调整模型关注的特征区域，优先生成被分类器敏感的身份特征（如眼睛、鼻子、嘴巴的形状）。

\subsubsection{U-Net的残差块卷积层}

REFace的U-Net架构包含多个残差块（ResNet Block），每个残差块含有多个卷积层。可以在残差块中的$1\times1$点卷积层上应用LoRA。点卷积负责通道间的特征混合，其权重矩阵 $W\in\mathbb{R}^{C_{\text{out}}\times C_{\text{in}}\times 1\times 1}$ 可重塑为二维矩阵后应用LoRA分解：
\begin{equation}\label{eq:mia_lora_conv}
    W' = W + \frac{\alpha}{r} \text{reshape}(B A, [C_{\text{out}}, C_{\text{in}}, 1, 1]),
\end{equation}
其中 $A\in\mathbb{R}^{r\times C_{\text{in}}}, B\in\mathbb{R}^{C_{\text{out}}\times r}$。

\subsection{LoRA超参数配置}

LoRA的性能受秩 $r$、缩放因子 $\alpha$ 与学习率的影响。秩 $r$ 决定低秩子空间的表达能力,建议采用中等秩（$r=16$或$r=32$）以平衡参数效率与表达能力。缩放因子 $\alpha$ 通常设为 $r$ 或 $2r$,使更新幅度适中。LoRA参数的学习率应显著低于嵌入层学习率,以避免破坏预训练权重：
\begin{equation}\label{eq:mia_lora_lr}
    \eta_{\text{lora}} = \beta \cdot \eta_{\text{emb}}, \quad \beta\in[0.01, 0.1].
\end{equation}

\subsection{LoRA的初始化与训练稳定性}

LoRA采用标准初始化策略:矩阵 $A$ 采用高斯随机初始化 $A\sim\mathcal{N}(0, \sigma^2)$,矩阵 $B$ 采用零初始化,确保训练开始时模型行为与预训练状态一致。对LoRA参数施加L2正则化抑制参数过度增长：
\begin{equation}\label{eq:mia_lora_reg}
    \mathcal{L}_{\text{lora\_reg}} = \lambda_{\text{lora}} \sum_{\ell} (\|A_{\ell}\|_F^2 + \|B_{\ell}\|_F^2).
\end{equation}

为降低显存占用,可采用梯度累积与混合精度训练技术。

\subsection{LoRA的推理优化}

训练完成后,将LoRA增量合并到原始权重中,消除推理时的额外计算开销：
\begin{equation}\label{eq:mia_lora_merge}
    W_{\text{merged}} = W + \frac{\alpha}{r} BA.
\end{equation}

合并后的模型在推理时与标准模型无异。若需针对多个目标分类器进行攻击,可采用"一个基础模型 + 多组LoRA权重"的架构,实现参数高效的多任务部署。

\section{多目标优化损失函数设计}
\label{sec:mia_loss}

本节构建融合多个优化目标的损失函数框架，平衡生成图像的分类器认同度、感知质量、身份一致性与正则化约束。

\subsection{损失函数的总体架构}

完整的训练损失函数包含多个部分：
\begin{equation}\label{eq:mia_total_loss}
    \mathcal{L}_{\text{total}} = \lambda_{\text{cls}}\mathcal{L}_{\text{cls}} + \lambda_{\text{id}}\mathcal{L}_{\text{id}} + \lambda_{\text{perc}}\mathcal{L}_{\text{perc}} + \lambda_{\text{reg}}\mathcal{L}_{\text{reg}},
\end{equation}
其中 $\lambda_{\text{cls}}, \lambda_{\text{id}}, \lambda_{\text{perc}}, \lambda_{\text{reg}}$ 为各损失项的权重系数。

\subsection{分类器引导损失}

分类器引导损失是模型反演攻击的核心优化目标,旨在最大化生成图像被目标分类器识别为目标类别的置信度。最直接的形式是交叉熵损失：
\begin{equation}\label{eq:mia_ce_loss}
    \mathcal{L}_{\text{cls}} = -\log F_\theta(\hat{x})_{y_{\text{target}}},
\end{equation}
其中 $F_\theta(\hat{x})_{y_{\text{target}}}$ 为目标类别的后验概率。该损失直接优化目标类别的置信度。

\subsection{身份一致性损失}

身份一致性损失确保生成图像保持目标身份特征。使用预训练的人脸识别模型提取嵌入向量,计算余弦相似度损失：
\begin{equation}\label{eq:mia_id_cosine_loss}
    \mathcal{L}_{\text{id}} = 1 - \frac{\langle E_{\text{id}}(\hat{x}), e_{\text{id}} \rangle}{\|E_{\text{id}}(\hat{x})\|_2 \|e_{\text{id}}\|_2},
\end{equation}
其中 $E_{\text{id}}(\cdot)$ 为身份编码器,$e_{\text{id}}$ 为标签条件嵌入层生成的目标身份嵌入。

\subsection{感知质量损失}

感知质量损失确保生成图像在视觉上真实自然。采用基于深度网络的感知特征计算图像相似度：
\begin{equation}\label{eq:mia_lpips_loss}
    \mathcal{L}_{\text{perc}} = \sum_{\ell=1}^L w_{\ell} \|\phi_{\ell}(\hat{x}) - \phi_{\ell}(x_{\text{src}})\|_2^2,
\end{equation}
其中 $\phi_{\ell}$ 为预训练网络的第 $\ell$ 层特征。该损失鼓励生成图像与源图像在感知特征上接近,保持纹理、光照等属性的自然性。

\subsection{正则化损失}

正则化损失防止过拟合与参数发散：
\begin{equation}\label{eq:mia_reg_total}
    \mathcal{L}_{\text{reg}} = \sum_{y=1}^C (\|e_y\|_2 - 1)^2 + \lambda_{\text{lora}} \sum_{\ell} (\|A_{\ell}\|_F^2 + \|B_{\ell}\|_F^2),
\end{equation}
其中第一项为嵌入范数约束,第二项为LoRA参数的L2正则化。

\subsection{损失函数配置}

综合上述损失项,总损失函数为：
\begin{equation}\label{eq:mia_total_loss}
    \mathcal{L}_{\text{total}} = \lambda_{\text{cls}} \mathcal{L}_{\text{cls}} + \lambda_{\text{id}} \mathcal{L}_{\text{id}} + \lambda_{\text{perc}} \mathcal{L}_{\text{perc}} + \lambda_{\text{reg}} \mathcal{L}_{\text{reg}}.
\end{equation}

\section{训练与推理流程}
\label{sec:mia_training}

\subsection{训练流程}

训练过程分为两个阶段：首先固定换脸模型训练嵌入层,使其学习类别到身份嵌入的映射；随后联合优化嵌入层与LoRA参数,微调换脸模型以适配目标分类器。训练采用AdamW优化器,学习率分别设置为$\eta_{\text{emb}}$和$\eta_{\text{lora}}$,并通过验证集评估攻击成功率与图像质量。

\subsection{推理策略}

推理阶段根据目标类别$y$生成嵌入$e_{\text{id}} = \mathcal{E}_{\psi}(y)$,结合源图像$x_{\text{src}}$通过换脸模型生成攻击样本$\hat{x} = G_{\phi+\Delta}(e_{\text{id}}, x_{\text{src}})$。为提升攻击成功率,可采用多源图像采样策略,从候选集中选择使分类器置信度最高的生成图像。训练完成后将LoRA权重合并到基础模型以消除推理开销。

\section{本章小结}
\label{sec:mia_summary}

本章提出了基于换脸先验与标签条件嵌入的模型反演攻击方法,用于评估人脸分类模型的隐私泄露风险。该方法利用预训练换脸模型的生成能力,通过标签条件嵌入层将类别标签映射为身份嵌入,并采用LoRA技术进行参数高效微调,实现高质量的模型反演攻击。实验结果表明该方法在攻击成功率与图像质量方面均达到先进水平,为生物特征识别系统的安全性评估提供了有效工具。
% Local Variables:
% TeX-master: "../main"
% TeX-engine: xetex
% End:
