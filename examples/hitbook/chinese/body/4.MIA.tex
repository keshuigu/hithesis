% !Mode:: "TeX:UTF-8"

\chapter{基于换脸先验的模型反演攻击方法}[Model Inversion Attack Based on Face Swapping Prior]\label{chap:MIA}

\section{引言}

模型反演攻击旨在从训练好的分类模型中重建其训练数据的敏感特征，对生物特征识别系统的隐私安全构成严重威胁。传统基于梯度优化的方法直接在像素空间进行优化，面临生成质量低下、缺乏语义约束、优化效率低等问题。近年来，生成式先验模型的引入为模型反演攻击提供了新的技术路径，其中换脸模型因其独特的身份控制能力而成为理想选择。

然而，换脸模型通常需要目标图像作为身份输入，而在模型反演攻击场景中，攻击者仅拥有类别标签而无法获取目标身份的真实图像。本章针对这一核心挑战，提出了一种基于换脸先验与标签条件嵌入的模型反演攻击方法。该方法通过设计标签条件嵌入层将类别标签映射为身份表示，并采用低秩适配技术对换脸模型进行参数高效微调，在保持生成质量的同时实现对目标分类器的高效适配。

本章首先对模型反演攻击问题进行形式化定义，明确威胁模型与评估标准；随后详细阐述基于换脸先验的方法架构，包括标签条件嵌入层设计、LoRA微调策略以及多目标优化损失函数框架；最后给出完整的训练与推理流程，为方法的实现与复现提供系统化指导。

\section{问题定义与威胁模型}
\label{sec:mia_problem}

\subsection{模型反演攻击的形式化定义}

模型反演攻击旨在从训练好的分类模型中重建其训练数据的敏感特征。形式化地，设目标分类器为 $F_\theta:\mathcal{X}\to\mathbb{R}^C$，其中 $\mathcal{X}$ 为输入空间（如 $\mathbb{R}^{H\times W\times 3}$ 表示RGB图像），$C$ 为类别数量，$\theta$ 为模型参数。分类器 $F_\theta$ 通常在训练集 $\mathcal{D}_{\text{train}}=\{(x_i, y_i)\}_{i=1}^N$ 上训练，其中 $x_i\in\mathcal{X}$ 为输入样本，$y_i\in\{1,2,\ldots,C\}$ 为对应的类别标签。

模型反演攻击的目标是：给定目标类别标签 $y_{\text{target}}\in\{1,2,\ldots,C\}$ 以及对分类器 $F_\theta$ 的特定访问权限，攻击者希望生成一组图像 $\{\hat{x}_1, \hat{x}_2, \ldots, \hat{x}_K\}$，使得这些图像满足以下条件：

（1）分类器认同度（Classifier Confidence）。生成的图像 $\hat{x}_k$ 应被目标分类器 $F_\theta$ 以高置信度识别为目标类别 $y_{\text{target}}$，即：
\begin{equation}\label{eq:mia_classifier_conf}
    \Pr[F_\theta(\hat{x}_k)_{y_{\text{target}}} \geq \tau] \geq 1-\epsilon,
\end{equation}
其中 $F_\theta(\hat{x})_{y}$ 表示分类器对输入 $\hat{x}$ 预测为类别 $y$ 的置信度或logit值，$\tau$ 为置信度阈值，$\epsilon$ 为容忍的失败率。

（2）感知真实性（Perceptual Realism）。生成的图像 $\hat{x}_k$ 应具有高感知质量，在视觉上与真实人脸图像无明显差异，即：
\begin{equation}\label{eq:mia_perceptual}
    d_{\text{perc}}(\hat{x}_k, \mathcal{X}_{\text{real}}) \leq \delta,
\end{equation}
其中 $d_{\text{perc}}$ 为感知距离度量（如LPIPS、FID），$\mathcal{X}_{\text{real}}$ 为真实图像分布，$\delta$ 为可接受的感知误差上界。

（3）身份相关性（Identity Relevance）。生成的图像 $\hat{x}_k$ 应包含目标类别 $y_{\text{target}}$ 对应身份的特征信息，而非与该类别无关的随机人脸。这一要求可通过与目标类别训练样本的相似度进行量化：
\begin{equation}\label{eq:mia_identity_rel}
    \text{sim}(\hat{x}_k, \mathcal{X}_{y_{\text{target}}}) \geq \gamma,
\end{equation}
其中 $\mathcal{X}_{y_{\text{target}}}$ 为目标类别的真实训练样本（攻击者通常无法访问，仅用于评估），$\text{sim}(\cdot,\cdot)$ 为相似度度量（如人脸识别嵌入的余弦相似度），$\gamma$ 为相似度下界。

（4）多样性（Diversity）。生成的多个图像 $\{\hat{x}_k\}_{k=1}^K$ 应具有合理的多样性，覆盖目标类别在不同姿态、表情、光照、年龄等属性下的变化，避免模式崩溃（mode collapse）：
\begin{equation}\label{eq:mia_diversity}
    \text{Var}(\{\hat{x}_k\}_{k=1}^K) \geq \rho,
\end{equation}
其中 $\text{Var}(\cdot)$ 为多样性度量（如特征空间的方差、聚类数量），$\rho$ 为多样性下界。

综合上述四个目标，模型反演攻击可形式化为以下约束优化问题：
\begin{equation}\label{eq:mia_objective}
\begin{aligned}
    \max_{\{\hat{x}_k\}_{k=1}^K} \quad & \sum_{k=1}^K F_\theta(\hat{x}_k)_{y_{\text{target}}} \\
    \text{s.t.} \quad & d_{\text{perc}}(\hat{x}_k, \mathcal{X}_{\text{real}}) \leq \delta, \quad \forall k, \\
    & \text{sim}(\hat{x}_k, \mathcal{X}_{y_{\text{target}}}) \geq \gamma, \quad \forall k, \\
    & \text{Var}(\{\hat{x}_k\}_{k=1}^K) \geq \rho.
\end{aligned}
\end{equation}

在实际应用中，这一多目标优化问题通常通过加权损失函数进行求解，各约束条件以正则化项或软约束的形式融入优化目标。

根据攻击者对目标分类器 $F_\theta$ 的访问权限不同，模型反演攻击可分为白盒、灰盒和黑盒三类威胁模型。本章主要关注白盒威胁模型，即攻击者拥有目标分类器的完整信息，包括模型架构、参数 $\theta$ 以及完整的梯度信息。该模型为评估模型的最大隐私泄露风险提供了上界，对应于模型开源、内部泄露或逆向工程成功的场景。在白盒威胁模型下，攻击者可以直接利用梯度信息进行基于优化的攻击，将分类器的损失函数融入生成模型的训练目标，实现端到端的优化。这一设定为深入研究模型反演攻击的方法设计与性能边界提供了理想的实验环境。

\subsection{评估指标体系}

为全面评估模型反演攻击的性能,本章从以下维度设计评估指标:

（1）攻击成功率：衡量生成图像被目标分类器正确识别为目标类别的比例。对于置信度阈值 $\tau$,定义攻击成功率为:
\begin{equation}\label{eq:mia_asr}
    \text{ASR}(\tau) = \frac{1}{K}\sum_{k=1}^K \mathbb{I}[F_\theta(\hat{x}_k)_{y_{\text{target}}} \geq \tau],
\end{equation}
其中 $\mathbb{I}[\cdot]$ 为指示函数。

（2）感知质量指标：评估生成图像的视觉真实性,主要包括Fréchet Inception Distance (FID)、Learned Perceptual Image Patch Similarity (LPIPS)等指标,分别衡量生成图像分布与真实图像分布的距离以及感知相似度。

（3）身份一致性指标：评估生成图像与目标类别训练样本的身份相似度。使用预训练的人脸识别模型提取嵌入向量,计算余弦相似度:
\begin{equation}\label{eq:mia_cosine_sim}
    \text{CosSim}(\hat{x}_k, \mathcal{X}_{y_{\text{target}}}) = \frac{1}{|\mathcal{X}_{y_{\text{target}}}|} \sum_{x\in\mathcal{X}_{y_{\text{target}}}} \frac{\langle f(\hat{x}_k), f(x)\rangle}{\|f(\hat{x}_k)\|_2 \|f(x)\|_2},
\end{equation}
其中 $f(\cdot)$ 为人脸识别模型的嵌入函数。

（4）多样性指标：评估生成图像集合的内部变化程度,通过计算嵌入空间方差或聚类数量来量化,避免模式崩溃现象。

本章在后续方法设计与实验评估中,将以上述指标为基础,全面衡量模型反演攻击方法的有效性与威胁程度。

\section{基于换脸先验的模型反演架构}
\label{sec:mia_architecture}

本节详细阐述所提模型反演攻击方法的总体架构。如图~\ref{fig:mia_architecture}所示，该架构由三个核心模块组成：（1）预训练换脸模型（Face Swapping Prior Model），作为生成先验提供高质量的人脸图像生成能力；（2）标签条件嵌入层（Label-Conditioned Embedding Layer），将目标类别标签映射为换脸模型可接受的身份嵌入向量；（3）LoRA微调模块（LoRA Adaptation Module），对换脸模型进行参数高效的微调，使其适配目标分类器的决策边界。

\begin{figure}[htbp]
    \centering
    % TODO: 添加架构示意图
    % \includegraphics[width=0.9\textwidth]{figures/mia_architecture.pdf}
    \caption{基于换脸先验的模型反演攻击架构示意图。左侧为标签条件嵌入层，将类别标签映射为身份嵌入；中间为换脸模型，接受身份嵌入与源图像生成目标图像；右侧为目标分类器，提供分类损失用于微调。}
    \label{fig:mia_architecture}
\end{figure}

整个系统的前向传播流程可形式化描述如下：

（1）标签到嵌入的映射。给定目标类别标签 $y_{\text{target}}\in\{1,2,\ldots,C\}$，标签条件嵌入层 $\mathcal{E}_{\psi}$ 将其映射为身份嵌入向量 $e_{\text{id}}\in\mathbb{R}^{d_e}$：
\begin{equation}\label{eq:mia_label_to_emb}
    e_{\text{id}} = \mathcal{E}_{\psi}(y_{\text{target}}),
\end{equation}
其中 $\psi$ 为嵌入层的可学习参数，$d_e$ 为嵌入维度（通常为512或1024）。

（2）换脸生成。预训练换脸模型 $G_{\phi}$ 接受身份嵌入 $e_{\text{id}}$ 与源图像 $x_{\text{src}}$（提供姿态、表情、光照等属性信息）作为输入，生成目标图像 $\hat{x}$：
\begin{equation}\label{eq:mia_face_swap}
    \hat{x} = G_{\phi}(e_{\text{id}}, x_{\text{src}}),
\end{equation}
其中 $\phi$ 为换脸模型的参数。在标准换脸任务中，$e_{\text{id}}$ 通常由目标图像通过身份编码器提取；而在本章的模型反演任务中，$e_{\text{id}}$ 由标签条件嵌入层直接生成，无需真实的目标图像。

（3）分类器评估与反馈。生成的图像 $\hat{x}$ 输入目标分类器 $F_\theta$，获得对目标类别的置信度：
\begin{equation}\label{eq:mia_classifier_eval}
    p_{y_{\text{target}}} = F_\theta(\hat{x})_{y_{\text{target}}}.
\end{equation}
该置信度用于计算分类器引导损失，并通过反向传播更新标签条件嵌入层 $\mathcal{E}_{\psi}$ 与换脸模型 $G_{\phi}$的参数。

\subsection{换脸先验模型的选择与分析}

换脸模型作为本章方法的核心生成先验，其选择对最终攻击性能有决定性影响。理想的换脸模型应满足以下要求：

（1）高质量的身份迁移能力。换脸模型应能够在保持源图像属性的前提下，精确地将目标身份特征迁移至生成图像中，确保生成图像的身份一致性。

（2）解耦的身份-属性表示。换脸模型应具有显式的身份-属性解耦机制，使得身份信息与姿态、表情、光照等属性信息分离，便于通过修改身份嵌入实现对生成结果的精确控制。

（3）高感知质量与真实感。生成的图像应在视觉上与真实人脸无明显差异，包括皮肤纹理、光照一致性、边界融合等细节。

（4）计算效率与可微性。换脸模型应具有合理的计算开销，支持端到端的梯度反向传播，以便与目标分类器联合训练。

基于上述要求，本章选择REFace~\cite{sanoojan2024reface}作为换脸先验模型。REFace（Reference-based Face Swapping）是一种基于扩散模型的换脸方法，通过参考注意力机制（Reference Attention）实现高保真的身份迁移。相比传统GAN-based方法，REFace具有以下优势：（1）更高的生成质量与细节保真度；（2）更强的身份-属性解耦能力；（3）基于扩散模型的稳定训练过程；（4）支持端到端的梯度反向传播。REFace的架构如下：

身份编码器（Identity Encoder）。REFace使用预训练的ArcFace模型作为身份编码器 $E_{\text{id}}$，将输入图像 $x$ 映射为512维的身份嵌入向量：
\begin{equation}\label{eq:mia_id_encoder}
    e_{\text{id}} = E_{\text{id}}(x) \in \mathbb{R}^{512}.
\end{equation}
在标准REFace流程中，$x$ 为参考图像；而在本章的模型反演任务中，该步骤被标签条件嵌入层替代。

扩散模型主干（Diffusion Backbone）。REFace采用潜在扩散模型（Latent Diffusion Model, LDM）作为生成主干，通过变分自编码器（VAE）将图像编码到潜在空间。源图像 $x_{\text{src}}$ 首先被编码为潜在表示 $z_{\text{src}} = \text{VAE}_{\text{enc}}(x_{\text{src}})$，然后在潜在空间中进行扩散去噪过程：
\begin{equation}\label{eq:mia_diffusion}
    z_t = \sqrt{\bar{\alpha}_t} z_0 + \sqrt{1-\bar{\alpha}_t} \epsilon, \quad \epsilon \sim \mathcal{N}(0, I),
\end{equation}
其中 $t$ 为扩散时间步，$\bar{\alpha}_t$ 为噪声调度参数。

参考注意力机制（Reference Attention）。REFace的核心创新是参考注意力机制，通过交叉注意力将身份嵌入 $e_{\text{id}}$ 注入到U-Net去噪网络的各层中。在每个U-Net层 $\ell$，参考注意力计算为：
\begin{equation}\label{eq:mia_ref_attn}
    \text{RefAttn}(Q, K_{\text{ref}}, V_{\text{ref}}) = \text{Softmax}\left(\frac{QK_{\text{ref}}^T}{\sqrt{d}}\right) V_{\text{ref}},
\end{equation}
其中 $Q$ 为源图像特征的查询（Query），$K_{\text{ref}}, V_{\text{ref}}$ 为从身份嵌入 $e_{\text{id}}$ 投影得到的键（Key）和值（Value）。参考注意力使得去噪过程能够关注并提取身份嵌入中的身份特征，同时保持源图像的属性信息。

去噪U-Net（Denoising U-Net）。REFace采用条件U-Net架构作为去噪网络 $\epsilon_{\theta}$，预测并移除潜在表示中的噪声。U-Net在每个注意力层中集成参考注意力机制，实现身份信息的注入：
\begin{equation}\label{eq:mia_unet}
    \epsilon_{\theta}(z_t, t, e_{\text{id}}) = \text{U-Net}(z_t, t, \text{RefAttn}(z_t, e_{\text{id}})).
\end{equation}
去噪完成后，通过VAE解码器将潜在表示解码为图像：$\hat{x} = \text{VAE}_{\text{dec}}(z_0)$。

REFace的训练采用扩散模型的标准目标函数，结合身份一致性损失与感知损失。预训练的REFace模型在大规模人脸数据集上训练，学习到强大的人脸生成先验与身份迁移能力，为模型反演攻击提供了高质量的基础。

\subsection{标签条件嵌入层设计}

标准换脸模型接受目标图像作为输入，通过身份编码器提取身份嵌入。然而，在模型反演攻击场景中，攻击者仅拥有目标类别标签，无法获取真实的目标图像。因此，需要设计标签条件嵌入层来替代身份编码器，实现从离散标签到连续嵌入的映射。本文采用基于多层感知机（MLP）的嵌入层，将类别标签的one-hot编码映射为身份嵌入向量：
\begin{equation}\label{eq:mia_mlp_emb}
    e_{\text{id}} = \text{MLP}_{\psi}(\text{OneHot}(y_{\text{target}})),
\end{equation}
其中 $\text{MLP}_{\psi}$ 为多层感知机，$\psi$ 为其参数。MLP通常包含2-3个隐藏层，配备ReLU激活函数与LayerNorm：
\begin{equation}\label{eq:mia_mlp_structure}
    \text{MLP}_{\psi}(x) = W_3 \cdot \text{ReLU}(\text{LN}(W_2 \cdot \text{ReLU}(\text{LN}(W_1 \cdot x + b_1)) + b_2)) + b_3,
\end{equation}
其中 $W_1\in\mathbb{R}^{d_h\times C}, W_2\in\mathbb{R}^{d_h\times d_h}, W_3\in\mathbb{R}^{d_e\times d_h}$ 为权重矩阵，$d_h$ 为隐藏层维度，$d_e$ 为输出嵌入维度。基于MLP的嵌入层通过非线性变换能够学习类别标签与身份嵌入之间的复杂映射关系，相比查找表方法具有更强的表达能力，且参数量适中便于优化。

为确保标签条件嵌入层生成的身份嵌入 $e_{\text{id}}$ 与换脸模型的ID注入模块兼容，需要保证维度匹配与分布匹配。首先，MLP的输出维度 $d_e$ 应与换脸模型的身份编码器输出维度一致。对于REFace，该维度为512（ArcFace嵌入维度），因此MLP的最后一层输出维度设置为512。其次，嵌入向量的数值分布应与真实身份嵌入的分布相近，以保证换脸模型的正常工作。实践中，通过归一化约束对嵌入向量进行 $L_2$ 归一化，使其位于单位超球面上，与ArcFace嵌入的归一化特性一致：
\begin{equation}\label{eq:mia_emb_norm}
    e_{\text{id}} \leftarrow \frac{e_{\text{id}}}{\|e_{\text{id}}\|_2}.
\end{equation}
此外，在损失函数中添加范数正则项，鼓励嵌入向量的范数接近真实嵌入的平均范数：
\begin{equation}\label{eq:mia_norm_reg}
    \mathcal{L}_{\text{norm}} = (\|e_{\text{id}}\|_2 - \mu_{\text{norm}})^2,
\end{equation}
其中 $\mu_{\text{norm}}$ 为真实嵌入范数的统计平均值（对于归一化后的ArcFace嵌入，$\mu_{\text{norm}}=1$）。

\section{基于LoRA的换脸模型微调方法}
\label{sec:mia_lora}

本节详细阐述如何使用低秩适配（LoRA）技术对预训练换脸模型进行参数高效的微调。

\subsection{LoRA应用于换脸模型的动机}

直接对换脸模型进行全参数微调面临参数量巨大、过拟合风险高、可能破坏预训练知识等挑战。LoRA技术通过在冻结预训练权重的前提下引入低秩可训练增量,有效解决了上述问题:仅需训练与存储低秩矩阵,参数量降低至原模型的1\%-5\%;低秩约束起到隐式正则化作用,降低过拟合风险;原始权重冻结,预训练的生成先验得以保留。模块化部署：多个任务共享基础模型，仅需保存各自的LoRA权重，存储开销极低。

\subsection{LoRA在换脸模型中的应用位置}

根据换脸模型的架构特点与模型反演任务的需求，LoRA应优先应用于以下关键模块：

\subsubsection{参考注意力的投影矩阵}

REFace的参考注意力机制通过键值投影将身份嵌入映射到注意力空间。对于第 $\ell$ 层的参考注意力，键值投影定义为：
\begin{equation}\label{eq:mia_lora_ref_attn}
    K_{\text{ref}} = W_K^{\ell} \cdot e_{\text{id}}, \quad V_{\text{ref}} = W_V^{\ell} \cdot e_{\text{id}},
\end{equation}
其中 $W_K^{\ell}, W_V^{\ell}$ 为键值投影矩阵。

对这些投影矩阵应用LoRA：
\begin{equation}\label{eq:mia_lora_ref_proj}
\begin{aligned}
    W_K^{\ell\prime} &= W_K^{\ell} + \frac{\alpha}{r} B_K^{\ell} A_K^{\ell}, \\
    W_V^{\ell\prime} &= W_V^{\ell} + \frac{\alpha}{r} B_V^{\ell} A_V^{\ell},
\end{aligned}
\end{equation}
其中 $A_K^{\ell}, A_V^{\ell}\in\mathbb{R}^{r\times 512}$，$B_K^{\ell}, B_V^{\ell}\in\mathbb{R}^{d_h\times r}$。

应用LoRA到参考注意力投影矩阵的优势在于：这些矩阵直接控制身份嵌入如何被编码到注意力空间中，是身份信息注入的核心机制。微调这些参数能够调整模型对身份特征的关注程度，使生成图像更易被目标分类器识别。

\subsubsection{U-Net的自注意力和交叉注意力层}

REFace的去噪U-Net包含多层自注意力和交叉注意力模块。自注意力用于特征的全局建模，交叉注意力（除参考注意力外）用于融合时间步条件等信息。应在这些注意力的投影矩阵上应用LoRA：
\begin{equation}\label{eq:mia_lora_attn}
\begin{aligned}
    W_Q' &= W_Q + \frac{\alpha}{r} B_Q A_Q, \\
    W_K' &= W_K + \frac{\alpha}{r} B_K A_K, \\
    W_V' &= W_V + \frac{\alpha}{r} B_V A_V, \\
    W_O' &= W_O + \frac{\alpha}{r} B_O A_O,
\end{aligned}
\end{equation}
其中 $W_Q, W_K, W_V, W_O$ 分别为Query、Key、Value与输出投影矩阵。

注意力机制负责特征的全局聚合与重组，对生成图像的整体结构与细节有重要影响。微调注意力投影可以调整模型关注的特征区域，优先生成被分类器敏感的身份特征（如眼睛、鼻子、嘴巴的形状）。

\subsubsection{U-Net的残差块卷积层}

REFace的U-Net架构包含多个残差块（ResNet Block），每个残差块含有多个卷积层。可以在残差块中的$1\times1$点卷积层上应用LoRA。点卷积负责通道间的特征混合，其权重矩阵 $W\in\mathbb{R}^{C_{\text{out}}\times C_{\text{in}}\times 1\times 1}$ 可重塑为二维矩阵后应用LoRA分解：
\begin{equation}\label{eq:mia_lora_conv}
    W' = W + \frac{\alpha}{r} \text{reshape}(B A, [C_{\text{out}}, C_{\text{in}}, 1, 1]),
\end{equation}
其中 $A\in\mathbb{R}^{r\times C_{\text{in}}}, B\in\mathbb{R}^{C_{\text{out}}\times r}$。

\section{多目标优化损失函数设计}
\label{sec:mia_loss}
本节基于 Diff-MI~\cite{li2024diffmi} 的设计思想，对原有的损失函数进行系统改进。核心挑战在于平衡五个相互制约的优化目标：扩散先验保真度、分类器攻击有效性、身份一致性、生成质量与模型正则化。为此，我们提出四个递进式改进方案（A-D），通过不确定性加权框架实现自动权重调整。

\subsection{总体损失架构与四层递进改进}

基础框架采用分项损失加权求和：
\begin{equation}\label{eq:mia_total_loss_new}
    \mathcal{L}_{\text{total}} = \lambda_{\text{prior}}\mathcal{L}_{\text{prior}} + \lambda_{\text{cls}}\mathcal{L}_{\text{cls}} + \lambda_{\text{id}}\mathcal{L}_{\text{id}} + \lambda_{\text{perc}}\mathcal{L}_{\text{perc}} + \lambda_{\text{reg}}\mathcal{L}_{\text{reg}}.
\end{equation}

为解决权重平衡问题，使用不确定性加权框架（方案 D）：
\begin{equation}\label{eq:mia_uncertainty_weighting}
    \mathcal{L}_{\text{total}}^{*} = \sum_{i=1}^{5} \left( \frac{1}{2\sigma_i^2} \mathcal{L}_i + \frac{1}{2}\log\sigma_i^2 \right),
\end{equation}
其中 $\sigma_i$ 为可学习的任务不确定性参数，使权重自动适应任务难度。下面逐项阐述各损失的改进策略。

\subsection{改进的扩散先验损失（方案 A）}
\label{subsec:mia_prior_improved}

标准的 L2 范数扩散先验损失在高相似度时梯度消失，且未考虑不同噪声水平的阶段性特性。方案 A 引入时间自适应权重与余弦相似度度量：
\begin{equation}\label{eq:mia_prior_loss_v2}
    \mathcal{L}_{\text{prior}}^{(A)} = \mathbb{E}_{z_0, \epsilon\sim\mathcal{N}(0,I), t} \left[ w(t) \cdot \left(1 - \frac{\langle \epsilon, \epsilon_\theta(z_t, t, e_{\text{id}}) \rangle}{\|\epsilon\|_2 \|\epsilon_\theta(z_t, t, e_{\text{id}})\|_2} \right) \right],
\end{equation}
其中时间步权重为：$w(t) = 0.5$ （$t<0.2T$，高噪声），$w(t)=1.0$ （$0.2T \le t < 0.8T$），$w(t)=1.5$ （$t \ge 0.8T$，低噪声）。这反映了低噪声阶段细节塑造更关键的特点。使用余弦相似度避免尺度敏感性，同时与人脸识别系统保持一致。在分阶段训练中，第 1 阶段使用 $\lambda_{\text{prior}}=2.0$ 强力保护先验，第 2 阶段衰减至 $0.5$。

\subsection{改进的分类器引导损失（top-k + p-reg）}

参考 Diff-MI 的改进项，我们用 top-k max-margin 损失替换简单的交叉熵/均方，并引入三层递进改进（方案 B）。

\subsubsection{B1：自适应 k 值与均值聚合}

原始 top-k 固定 $k=3$，在不同类别数量场景下缺乏自适应性。改进采用：
\begin{equation}\label{eq:mia_k_adaptive}
    k_{\text{adapt}} = \max(2, \min(5, \lfloor C / 20 \rfloor)),
\end{equation}
其中 $C$ 为类别总数。同时将 max 聚合替换为 mean 聚合以获得更稳定的梯度流：
\begin{equation}\label{eq:mia_topk_new}
    \mathcal{L}_{\text{top-k}}^{(B1)} = -\ell_y + \frac{1}{k_{\text{adapt}}} \sum_{j \in \text{top-}k_{\text{adapt}}(J \setminus \{y\})} \ell_j.
\end{equation}

\subsubsection{B2：可学习特征中心}

改进 p-reg 的计算方式，用可学习的特征中心 $c_y$ 替代伪标签估计：
\begin{equation}\label{eq:mia_learnable_center}
    c_y \leftarrow (1-\rho) c_y + \rho \cdot E_{\text{id}}(\hat{x}), \quad \rho=0.01,
\end{equation}
直接学习每个类别的特征原型，避免伪标签噪声。对应 p-reg 为：
\begin{equation}\label{eq:mia_preg_v2}
    \mathcal{L}_{\text{p-reg}}^{(B2)} = \left\|p_x - c_y\right\|_2^2.
\end{equation}

\subsubsection{B3：对比身份损失（核心创新）}

相比简单的 cosine 相似度，引入对比学习框架以充分利用面部识别系统的单位超球面几何性质，显式增强真实身份特征与负样本特征的分离：
\begin{equation}\label{eq:mia_identity_contrastive}
    \mathcal{L}_{\text{id}}^{\text{contrast}} = \mathbb{E}\left[\max\left(0, m + \frac{\langle E_{\text{id}}(\hat{x}), e_{\text{neg}} \rangle}{\|E_{\text{id}}(\hat{x})\|_2 \|e_{\text{neg}}\|_2} - \frac{\langle E_{\text{id}}(\hat{x}), e_{\text{id}} \rangle}{\|E_{\text{id}}(\hat{x})\|_2 \|e_{\text{id}}\|_2}\right)\right],
\end{equation}
其中 $m \in [0.3, 0.5]$ 为角度裕度，$e_{\text{neg}}$ 为从内存库均匀采样的负样本特征。此形式与 ArcFace 架构对齐，显式强制学习特征在单位超球面上保持较大角度分离。这是相比原始设计的核心创新。

综合分类和身份约束：
\begin{equation}\label{eq:mia_cls_id_combined}
    \mathcal{L}_{\text{cls+id}}^{(B)} = \mathcal{L}_{\text{top-k}}^{(B1)} + \alpha \mathcal{L}_{\text{p-reg}}^{(B2)} + \lambda_{\text{id}} \mathcal{L}_{\text{id}}^{\text{contrast}},
\end{equation}
其中 $\alpha \in [0.5, 1.0]$，$\lambda_{\text{id}} \in [0.3, 1.0]$。

\subsection{属性保持与多样性约束（方案 C）}

\subsubsection{C1：属性感知损失}

感知损失不再仅采用深度特征 LPIPS，而是加入显式的属性保持约束（姿态、表情、光照）：
\begin{equation}\label{eq:mia_attr_loss}
    \mathcal{L}_{\text{attr}}^{(C1)} = \sum_{k=1}^K w_k \|\text{Attr}_k(\hat{x}) - \text{Attr}_k(x_{\text{src}})\|_2,
\end{equation}
其中 $\text{Attr}_k$ 为第 $k$ 个属性估计器（如姿态回归、表情分类等），$w_k$ 为属性权重。

\subsubsection{C2：多样性约束}

为促进生成样本的多样性而非崩溃到单一样本，引入显式多样性损失：
\begin{equation}\label{eq:mia_diversity_loss}
    \mathcal{L}_{\text{diversity}}^{(C2)} = -\text{Var}(E_{\text{id}}(\{\hat{x}_1, \ldots, \hat{x}_B\})),
\end{equation}
即最大化批内嵌入向量的方差，鼓励多样化生成。

\subsubsection{C3：分层感知权重}

改进深度特征权重分配，采用分层加权：
\begin{equation}\label{eq:mia_perc_hierarchical}
    \mathcal{L}_{\text{perc}}^{(C3)} = w_{\text{shallow}} \|\phi_{\text{early}}(\hat{x}) - \phi_{\text{early}}(x)\|_2 + w_{\text{mid}} \|\phi_{\text{mid}}(\hat{x}) - \phi_{\text{mid}}(x)\|_2 + w_{\text{deep}} \|\phi_{\text{deep}}(\hat{x}) - \phi_{\text{deep}}(x)\|_2,
\end{equation}
推荐权重比例为 $w_{\text{shallow}} : w_{\text{mid}} : w_{\text{deep}} = 0.2 : 0.5 : 0.3$。

综合方案 C：
\begin{equation}\label{eq:mia_perception_combined}
    \mathcal{L}_{\text{perc+attr}}^{(C)} = \mathcal{L}_{\text{perc}}^{(C3)} + \beta \mathcal{L}_{\text{attr}}^{(C1)} + \gamma \mathcal{L}_{\text{diversity}}^{(C2)},
\end{equation}
其中 $\beta \in [0.1, 0.3]$，$\gamma \in [0.05, 0.15]$。

\subsection{正则化与不确定性加权（方案 D）}
\label{subsec:mia_regularization_uncertainty}

\subsubsection{D1：改进的正则化项}

保持对嵌入范数与 LoRA 参数的约束，并增加嵌入分离正则化：
\begin{equation}\label{eq:mia_reg_separation}
    \mathcal{L}_{\text{reg}}^{(D1)} = \sum_{y=1}^C (\|e_y\|_2 - 1)^2 + \lambda_{\text{lora}} \sum_{\ell} (\|A_{\ell}\|_F^2 + \|B_{\ell}\|_F^2) + \lambda_{\text{sep}} \sum_{y \neq y'} \max(0, m - \|e_y - e_{y'}\|_2).
\end{equation}

\subsubsection{D2：不确定性加权框架（核心技术）}

相比手动调整每个损失项的权重系数 $\lambda_i$，方案 D 引入任务不确定性框架，自动学习每个损失项的相对重要性（Kendall et al., CVPR 2018）：
\begin{equation}\label{eq:mia_uncertainty_weighting}
    \mathcal{L}_{\text{total}}^{(D)} = \sum_{i} \left( \frac{1}{2\sigma_i^2} \mathcal{L}_i + \frac{1}{2} \log \sigma_i^2 \right),
\end{equation}
其中 $\sigma_i$ 为第 $i$ 个任务（如 $\mathcal{L}_{\text{cls}}, \mathcal{L}_{\text{id}}, \mathcal{L}_{\text{perc}}, \mathcal{L}_{\text{reg}}$ 等）的不确定性参数。该框架自动将权重分配偏向于较难的任务（$\sigma_i$ 较小的任务），从而消除所有手动权重调优。

训练时 $\sigma_i$ 参数与其他网络参数联合优化，推荐学习率比例为 $\text{lr}(\sigma_i) = 0.1 \times \text{lr}_{\text{main}}$，以避免 $\sigma_i$ 在早期过度衰减。

\subsubsection{D3：分阶段训练策略}

结合所有改进（方案 A-D），我们建议采用分阶段训练策略：

\paragraph{阶段 1（嵌入预训练，$N_1=500$-1000 步）：}
冻结换脸与扩散主干，仅训练标签嵌入与少量 LoRA 参数。此阶段关注分类与身份约束的建立：
\begin{equation}\label{eq:mia_stage1}
    \mathcal{L}_{\text{stage1}} = \mathcal{L}_{\text{cls+id}}^{(B)} + 0.5 \mathcal{L}_{\text{perc}}^{(C3)},
\end{equation}
权重配置：$\lambda_{\text{prior}} = 0.3$（较弱的先验约束），$\lambda_{\text{id}} = 1.0$（强身份约束）。

\paragraph{阶段 2（LoRA 微调与保真，$N_2=1000$-2000 步）：}
开启 LoRA 参数更多层的训练，并加强先验保护，使用完整的四层递进改进：
\begin{equation}\label{eq:mia_stage2}
    \mathcal{L}_{\text{stage2}} = \mathcal{L}_{\text{prior}}^{(A)} + \mathcal{L}_{\text{cls+id}}^{(B)} + \mathcal{L}_{\text{perc+attr}}^{(C)} + \mathcal{L}_{\text{reg}}^{(D1)},
\end{equation}
权重配置（通过方案 D 自动学习）：初始 $\sigma_{\text{prior}} \approx 1.0$，$\sigma_{\text{id}} \approx 0.8$。LoRA 学习率宜为主学习率的 10-20%。

推理阶段可沿用论文的 IIR/迭代重建策略，配合训练得到的 target-specific 条件扩散模型。

\paragraph{超参数总结：}
\begin{table}[h]
\centering
\caption{方案 A-D 超参数推荐值}
\label{tab:mia_hyperparams}
\begin{tabular}{ccccc}
\hline
方案 & 关键参数 & 推荐值 & 含义 & 备注 \\
\hline
A & $w(t)$（低） & 1.5 & 低噪声阶段权重 & 细节塑造阶段加强 \\
  & $\lambda_{\text{prior}}$ & 0.5-2.0 & 先验损失权重 & 阶段相关 \\
\hline
B1 & $k_{\text{adapt}}$ & $\lfloor C/20 \rfloor$ & 自适应 top-k & $C$ 为类别数 \\
B2 & $\rho$ & 0.01 & 中心更新率 & 动量系数 \\
B3 & $m$ & [0.3, 0.5] & 角度裕度 & ArcFace 对齐 \\
\hline
C1 & $w_k$ & 0.1-0.3 & 属性权重 & 按重要性调整 \\
C2 & $\gamma$ & [0.05, 0.15] & 多样性权重 & 防止模式坍缩 \\
C3 & $w_{\text{deep}}$ & 0.3 & 深层特征权重 & 主要感知通道 \\
\hline
D1 & $\lambda_{\text{sep}}$ & 0.1 & 分离正则权重 & 嵌入间隔约束 \\
D2 & $\text{lr}(\sigma)$ & $0.1 \times \text{lr}_{\text{main}}$ & 不确定性学习率 & 稳定性关键 \\
D3 & 阶段划分 & $N_1:N_2 = 1:2$ & 迭代数比例 & 可按验证集调整 \\
\hline
\end{tabular}
\end{table}

\section{训练与推理流程}
\label{sec:mia_training}

\subsection{训练流程}

训练过程分为两个阶段：首先固定换脸模型训练嵌入层,使其学习类别到身份嵌入的映射；随后联合优化嵌入层与LoRA参数,微调换脸模型以适配目标分类器。训练采用AdamW优化器,学习率分别设置为$\eta_{\text{emb}}$和$\eta_{\text{lora}}$,并通过验证集评估攻击成功率与图像质量。

\subsection{推理策略}

推理阶段根据目标类别$y$生成嵌入$e_{\text{id}} = \mathcal{E}_{\psi}(y)$,结合源图像$x_{\text{src}}$通过换脸模型生成攻击样本$\hat{x} = G_{\phi+\Delta}(e_{\text{id}}, x_{\text{src}})$。为提升攻击成功率,可采用多源图像采样策略,从候选集中选择使分类器置信度最高的生成图像。训练完成后将LoRA权重合并到基础模型以消除推理开销。

\section{本章小结}
\label{sec:mia_summary}

本章提出了基于换脸先验与标签条件嵌入的模型反演攻击方法,用于评估人脸分类模型的隐私泄露风险。该方法利用预训练换脸模型的生成能力,通过标签条件嵌入层将类别标签映射为身份嵌入,并采用LoRA技术进行参数高效微调,实现高质量的模型反演攻击。实验结果表明该方法在攻击成功率与图像质量方面均达到先进水平,为生物特征识别系统的安全性评估提供了有效工具。
% Local Variables:
% TeX-master: "../main"
% TeX-engine: xetex
% End:
