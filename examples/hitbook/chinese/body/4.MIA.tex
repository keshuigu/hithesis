% !Mode:: "TeX:UTF-8"

% TODO (写作提示):
% - 注明所用先验换脸模型的具体来源（模型名称/论文/仓库链接）与预训练权重信息。
% - 说明微调时冻结/解冻了哪些网络层（例如冻结主干，只训练标签嵌入层），并给出对应层名或代码路径。
% - 建议补充评估协议与基线：使用哪些基线方法比较，评价指标如何统一计算。

\chapter[面向人脸分类模型的逆向重建方法]{面向人脸分类模型的逆向重建方法}[Reconstruction Method for Face Classification Models]
\section{引言}
% 以下为原始占位文本（已保留为注释，以便回溯）
% \input{./4.MIA_original.tex}
本章讨论面向图像分类/人脸识别模型的模型反演攻击（Model Inversion Attack, MIA），重点研究如何在有限可用信息下利用生成式先验（以换脸/扩散生成模型为代表）重建训练数据的敏感样本。与针对模板/嵌入的逆向重建不同，面向分类器的反演通常只能获得类别标签或置信度分布，因此需要设计既能保留视觉质量又能提升分类器响应的条件生成与优化方法。

本章的目标是：
\begin{itemize}
\item 形式化面向分类器反演问题的输入/输出与攻击假设，明确白盒/半白盒/黑盒下的可行策略；
\item 提出一种结合生成式先验与判别模型引导的两阶段重建流程（基础生成 + LoRA 微调 / 优化），并给出可复现的训练与推理管线；
\item 设计系统化的实验与评估协议，用以衡量重建图像在分类器认同度、感知质量与多样性之间的权衡。
\end{itemize}

本章结构如下：第~\ref{sec:mia_objectives} 节给出攻击目标与评估协议；第~\ref{sec:mia_method} 节介绍结合生成模型的反演方法与训练细节；第~\ref{sec:mia_lora} 节讨论基于低秩适配的微调策略与工程实践；最后给出实验设计与本章小结。

\section{攻击目标与评估协议}
\label{sec:mia_objectives}
\subsection{攻击目标（形式化）}
设目标分类器为 $F:\mathcal{X}\to\Delta^{C-1}$，其中 $\mathcal{X}$ 为像素空间或潜在表示空间，$\Delta^{C-1}$ 为 $C$ 类的概率单纯形。攻击者给定目标类别索引 $y_t$，目标是构造一组生成样本 $\{\hat{x}_i\}_{i=1}^K$，使得对多数样本 $\hat{x}_i$，有 $F(\hat{x}_i)_{y_t}$ 足够大（大于阈值 $\tau$），同时图像具有较高的感知质量。更一般地，攻击者希望同时优化两个目标：
\begin{equation}
	ext{maximize}_{\hat{x}}\; \; F(\hat{x})_{y_t} \quad \text{s.t.} \quad \text{PerceptualDistance}(\hat{x},\mathcal{P}_{y_t}) \;\text{small},
\end{equation}
其中 $\mathcal{P}_{y_t}$ 表示真实类别 $y_t$ 的分布（未知），PerceptualDistance 可由 LPIPS 等衡量。

\subsection{威胁模型}
我们考虑下列常见威胁模型：
\begin{itemize}
\item 白盒（full white-box）: 攻击者可完全访问 $F$ 的权重、结构与梯度；可用于基于梯度的直接优化或将分类器融入训练损失。\
\item 得分/置信度可查询黑盒（score-query black-box）: 攻击者可以对 $F$ 输入样本并获得置信度向量或 logits，但无法访问内部权重。\
\item 标签/判决黑盒（label-only）: 仅获得类别决策或 top-k 输出，不返回置信度。\
\item 受限制查询（budgeted）: 在以上任一黑盒模型下，攻击者的查询次数受限（例如每个目标 $\leq Q$ 次）。
\end{itemize}

\subsection{评估协议与基线}
评估应从三方面衡量：
\begin{enumerate}
\item 识别一致性：衡量生成样本被目标分类器接受为目标类别的比率（例如 $\Pr[F(\hat{x})_{y_t}\ge\tau]$）及 TAR@FAR（把生成样本作为 probe，在指定 gallery 下计算真接受率）；\
\item 感知质量与多样性：使用 FID、LPIPS、SSIM 等衡量生成样本的视觉质量与与真实分布的距离，并报告样本多样性（例如基于嵌入的聚类半径）；\
\item 查询/计算成本：记录查询数量、微调所需计算（GPU·小时）与平均单样本生成时间。
\end{enumerate}

基线方法包括：随机初始化的梯度优化（DeepInversion/gradient-based inversion）、使用预训练生成模型的简单重构（无微调）、以及针对分类器的判别式优化方法。我们在实验中将与这些基线进行量化比较。

\section{结合生成式模型的重建方法}
\label{sec:mia_method}
本节提出一种实用的生成式反演框架，框架由三部分组成：先验生成器 $G$、识别器引导模块 $H$、以及微调/适配器模块 $\Delta$。总体思路是利用生成器提供高质量样本空间，再通过判别器/分类器的信号对生成过程进行引导或微调，使生成样本更易被目标分类器识别为 $y_t$。

\subsection{框架概述}
给定预训练生成器 $G_{\phi}$（可选为换脸模型或隐空间扩散模型）和目标分类器 $F$，我们考虑两类方法：
\begin{itemize}
\item 优化式引导（optimization-guided）: 固定 $G$，在潜在空间 $z$ 或输入空间上直接优化目标函数
$$\arg\max_z\; F(G_{\phi}(z))_{y_t} - \lambda\,\mathcal{R}(z),$$
其中 $\mathcal{R}$ 为正则化项（例如潜在正则或感知损失）。\
\item 微调式适配（adaptation-based）: 对 $G_{\phi}$ 应用轻量微调（例如 LoRA/Adapter），学习一个小的增量 $\Delta$ 使得 $G_{\phi+\Delta}$ 的输出更符合分类器的判别面。训练目标通常包含分类器损失与感知/重建损失的加权组合。
\end{itemize}

两类方法可以组合使用：先通过优化式引导寻找良好初始化，再对 $G$ 进行 LoRA 微调以扩大可接受样本空间。

\subsection{损失构成与训练目标}
训练时常用的损失项包括：
\begin{itemize}
\item 分类损失 $\mathcal{L}_{cls} = -\log F(\hat{x})_{y_t}$ 或交叉熵/对比损失；\
\item 感知损失 $\mathcal{L}_{perc}$（例如 VGG/LPIPS），保持视觉质量；\
\item 正则化项 $\mathcal{L}_{reg}$（潜在空间正则、参数范数），防止模式崩溃与过拟合；\
\item 可选对抗损失 $\mathcal{L}_{adv}$ 以提升细节真实感（若采用 GAN 风格判别器）。
\end{itemize}

综合目标：
$$\mathcal{L} = \lambda_{cls}\mathcal{L}_{cls} + \lambda_{perc}\mathcal{L}_{perc} + \lambda_{reg}\mathcal{L}_{reg} + \lambda_{adv}\mathcal{L}_{adv}.$$ 

在白盒情形下，可直接反向传播分类损失到生成器参数或潜在；在黑盒情形下，可使用基于评分的估计、近似梯度（ZSGrad）或查询-高效的进化/贝叶斯优化方法。

\subsection{推理与采样策略}
推理时可采用：
\begin{itemize}
\item 多次随机潜在采样 + 局部优化并选择最高置信度输出；\
\item 结合 classifier-free guidance 或能量引导（在扩散模型中）插入额外梯度以提升 $F(\cdot)_{y_t}$；\
\item 若可用 LoRA 权重，可先动态加载 LoRA 再采样，减少每次采样所需的优化步数。
\end{itemize}

\section{基于低秩适配技术的微调训练方法}
\label{sec:mia_lora}
针对分类器反演的微调策略，我们优先使用参数高效的低秩适配（LoRA）方法，以在少量样本和低算力环境下实现可重复的微调。

\subsection{作用层与参数化}
建议在生成器的下列子模块中应用 LoRA：跨注意力 (cross-attn) 的投影矩阵、注意力的 output projection、以及 MLP 的第一/第二线性层。对这些层应用低秩增量可显著改变生成输出而不影响原模型的全局稳定性。

参数化形式同 TIA 部分所述：$W' = W + BA$，仅学习小矩阵 $A,B$ 并记录秩 $r$ 与缩放 $\alpha$。

\subsection{训练流程与超参建议}
训练流程建议：
\begin{enumerate}
\item 数据准备：选取每一目标类别下的少量代表样本作为微调集（N-shot），并准备相应的替换源（若使用换脸输入）。\
\item 冻结主干：仅解冻并训练 LoRA 参数与少数条件层；使用小 lr（$\le 1\mathrm{e}{-4}$）与较强的权重衰减以减少过拟合。\
\item 校验与早停：在独立验证集上监控 $F(\hat{x})_{y_t}$ 与感知指标，采用早停或 checkpoint 平均策略。
\end{enumerate}

常用起始超参（建议记录并汇报）：$r\in\{4,8,16\}$，$\alpha\in\{8,16\}$，lr=$1\mathrm{e}{-5}\sim1\mathrm{e}{-4}$，微调步数 500--3000，batch size 根据显存调整（1--8）。

\subsection{合并、部署与可重复性}
训练完成后可选择将 LoRA 权重合并进 base checkpoint 以便部署，或保留增量以便快速切换不同目标。每次微调都应保存训练命令、环境信息、随机种子与中间检查点以保证可重复性。

\section{实验设计（概览）}
本章后续的实验将包括：少样本微调（1/5/10-shot）对比、白盒与黑盒场景下的成功率对比、以及与梯度优化与无微调生成器的基线比较。评价指标按第~\ref{sec:mia_objectives} 节制定。

\subsection{方法细化与比较矩阵}
为便于系统比较，我们将在实验中实现并对比下列方法（实现细节见各自子节）：
\begin{enumerate}
	\item 优化式潜在反演（Optimization in latent）：固定生成器 $G$，在潜在空间 $z$ 上用梯度/进化搜索最大化分类器响应；适用于白盒/可查询得分情形。
	\item 黑盒估计（Query-based estimation）：在得分/标签黑盒下使用 NES/SPSA/ZSGrad 进行近似梯度估计，结合潜在优化或像素域优化；评测查询效率与性能曲线。
	\item LoRA 微调（Adaptation-based）：对生成器应用 LoRA 增量并以分类器损失 + 感知损失训练；适合低查询或无查询但可微调先验的情形。
	\item 混合方案（Init+Adapt）：先用优化式方法找到良好 $z$ 初始化，再以少量 LoRA 步微调生成器以放大成功样本空间。
\end{enumerate}

对于每种方法，我们会报告：平均 top-1 置信度、TAR@FAR 曲线、FID/LPIPS、样本多样性与平均查询/时间成本。

\subsection{查询高效算法与实现建议}
在黑盒情形下，查询预算是关键限制。建议在实现时考虑：
\begin{itemize}
	\item NES / Natural Evolution Strategies：用高斯扰动进行黑盒梯度估计，易于并行化；对高维像素空间代价高，但在低维潜在空间中表现良好。\
	\item SPSA / Simultaneous Perturbation：每次仅需两次查询估计梯度，适合极低查询预算场景；需对扰动尺度与平滑参数仔细调优。\
	\item ZSGrad（zero-shot gradient）与代理模型：通过在外部数据上训练代理分类器近似目标分类器，或用迁移学习减少实际查询需求。\
	\item 贝叶斯优化 / 进化算法：在预算非常紧张时可采用基于代理的全局搜索（但对响应面平滑性敏感）。
\end{itemize}

实现建议：优先在潜在空间而不是像素空间做黑盒搜索；在每轮搜索中保留 top-k 候选并对其局部优化以提高样本质量与多样性。

\subsection{防御与缓解措施（工程化建议）}
对抗模型反演的实用防御包括：
\begin{itemize}
	\item 模板/模型输出保护：对外返回的嵌入/分数进行量化、添加噪声或签名化以降低可逆性。\
	\item 差分隐私训练：在训练阶段对梯度或输出进行 DP 处理，可在保护隐私的同时降低模型 utility（需权衡）。\
	\item 查询策略与速率限制：对外部查询施加认证、速率限制与异常检测，以防止大规模黑盒攻击。\
	\item 可疑合成检测：开发用于检测合成/反演生成图像的鉴别器或水印检测方法，作为后验防护层。\
\end{itemize}

在论文讨论中应同时给出防御成本（对模型精度、延迟的影响）与可行性建议。

\subsection{可复现性清单与超参数表（示例）}
为保证实验可复现，请在每次实验记录并发布以下信息：
\begin{itemize}
	\item 代码/脚本版本（commit id）、运行命令、配置文件（YAML/JSON）；\
	\item 依赖环境（Python/PyTorch 版本、CUDA/cuDNN、关键库版本）；\
	\item 随机种子、硬件规格（GPU 型号、显存）、每次实验的 wall-clock 时间与平均单样本耗时；\
	\item 完整的超参数表（见示例表）。
\end{itemize}

示例超参数表：
\begin{center}
\begin{tabular}{l l}
\hline
参数 & 建议值 \\
\hline
潜在维度 (LDM) & 64x64x4 \\
LoRA 秩 $r$ & 4,8,16 \\
LoRA 缩放 $\alpha$ & 8,16 \\
微调 lr & $1\times10^{-5}\sim5\times10^{-4}$ \\
黑盒查询预算 $Q$ & 100--10k \\
投影步长 $\eta$ & $1\times10^{-3}\sim5\times10^{-3}$ \\
CFG scale (若适用) & 1.0--6.0 \\
采样步数 & 18, 50, 100 \\
\hline
\end{tabular}
\end{center}

\subsection{示例复现命令}
示例训练/微调与推理命令（基于仓库 scripts/）：
\begin{verbatim}
# LoRA 微调针对分类器反演
python scripts/finetune_lora_mia.py --ckpt checkpoints/edm_base.pt \
	--target_class 123 --out_dir experiments/mia_lora_r16 \
	--r 16 --alpha 16 --lr 1e-4 --steps 2000

# 黑盒潜在优化（SPSA/NES）示例
python scripts/optimize_latent_blackbox.py --model checkpoints/edm_base.pt \
	--target_class 123 --method NES --budget 2000 --out_dir experiments/mia_nes

# 推理/采样
python scripts/infer_mia.py --ckpt experiments/mia_lora_r16/checkpoint.pt \
	--target_class 123 --steps 50 --cfg_scale 2.0 --proj_steps 1
\end{verbatim}

\section{本章小结}
本章系统地讨论了面向分类模型的模型反演问题，提出了基于生成式先验与识别器引导相结合的两类方案（优化引导与微调适配），并详细说明了基于 LoRA 的参数高效微调策略与实验设计要点。下一章将实现并报告具体实验结果与消融研究。
% Local Variables:
% TeX-master: "../main"
% TeX-engine: xetex
% End:
