% !Mode:: "TeX:UTF-8"

\chapter{基于换脸先验的模型反演攻击方法}[Model Inversion Attack Based on Face Swapping Prior]\label{chap:MIA}

\section{引言}

模型反演攻击旨在从训练好的分类模型中重建其训练数据的敏感特征，对生物特征识别系统的隐私安全构成严重威胁。传统基于梯度优化的方法直接在像素空间进行优化，面临生成质量低下、缺乏语义约束、优化效率低等问题。近年来，现有MIA工作主要采用通用生成模型（如GAN、扩散模型）作为先验，虽然取得一定进展，但在身份控制精度与生成保真度的协同优化上仍存在瓶颈。

本章探索将扩散换脸模型应用于MIA任务。换脸模型具有显式的身份-属性解耦机制和专用的身份控制接口，相比通用生成模型更适合身份重建任务。然而，换脸模型通常需要目标图像作为身份输入，而MIA场景中攻击者仅拥有类别标签——这构成了本方法面临的核心技术挑战。针对这一挑战，本章提出两项关键技术：（1）设计标签条件嵌入层，通过MLP将类别标签映射为512维身份嵌入，替代图像编码器实现无真实图像的身份控制；（2）提出渐进式微调策略，通过三阶段训练（图像预热→混合过渡→纯标签生成）结合余弦退火调度，实现从图像条件到标签条件的平滑模态迁移。同时采用LoRA技术进行参数高效微调，以1\%-5\%的参数量快速适配目标分类器。

本章首先对模型反演攻击问题进行形式化定义，明确威胁模型与评估标准；随后详细阐述换脸先验的选择与分析、标签条件嵌入层设计、LoRA微调策略、渐进式训练流程以及多目标优化损失函数框架；最后给出完整的训练与推理流程，为方法的实现与复现提供系统化指导。

\section{形式化问题定义}
\label{sec:mia_problem}

根据第\ref{sec:thesis_structure}节建立的攻击任务框架，简要回顾模型反演攻击的形式化定义。设目标分类器为 $F_\theta:\mathcal{X}\to\mathbb{R}^C$，其中 $\mathcal{X}$ 为输入空间（如 $\mathbb{R}^{H\times W\times 3}$ 表示RGB图像），$C$ 为类别数量，$\theta$ 为模型参数。给定目标类别标签 $y_{\text{target}}\in\{1,2,\ldots,C\}$，攻击者的目标是生成图像集合 $\{\hat{x}_1, \hat{x}_2, \ldots, \hat{x}_K\}$，使其同时满足分类器认同度、感知真实性、身份相关性与多样性四个条件。完整的形式化定义与约束优化问题详见第\ref{sec:thesis_structure}节。

本章主要关注白盒威胁模型，即攻击者拥有目标分类器 $F_\theta$ 的完整信息，包括模型架构、参数以及完整的梯度信息 $\nabla_x F_\theta(x)$。这一威胁模型为评估模型的最大隐私泄露风险提供了上界，对应于模型开源、内部泄露或逆向工程成功的场景。在白盒设定下，攻击者可以直接利用梯度信息进行端到端优化：将分类器损失 $\mathcal{L}_{\text{cls}}(F_\theta(\hat{x}), y_{\text{target}})$ 融入生成模型的训练目标，通过反向传播更新生成器参数，使生成轨迹持续逼近目标类别的高置信区域。相比黑盒或灰盒场景（仅能查询输出概率），白盒访问权限提供了更强的优化信号，从而能够实现更高质量的重建结果。这一设定为深入研究方法设计与性能边界提供了理想的实验环境。

\section{基于换脸先验的模型反演架构}
\label{sec:mia_architecture}

\subsection{换脸先验模型的选择与分析}

换脸模型作为本章方法的核心生成先验，其选择对最终攻击性能有决定性影响。理想的换脸模型应满足：（1）高质量的身份迁移能力；（2）显式的身份-属性解耦机制；（3）高感知质量与真实感；（4）支持端到端梯度反向传播。

基于上述要求，本章选择REFace~\cite{sanoojan2024reface}作为换脸先验模型。REFace是一种基于扩散模型的统一换脸方法，其将换脸任务重构为训练时自监督修复任务，通过多步DDIM采样增强与CLIP特征解耦机制实现高保真的身份迁移。该方法在CelebA-HQ数据集上取得98.8\%的身份检索准确率和6.09的FID分数，在生成质量和身份保持能力方面显著优于现有的基于扩散的换脸方法。

REFace的标准推理流程需要提供真实的目标图像$x_{\text{target}}$，利用预训练ArcFace编码器提取512维身份嵌入$e_{\text{id}} = E_{\text{id}}(x_{\text{target}}) \in \mathbb{R}^{512}$，并通过参考注意力机制$\text{RefAttn}(Q, K_{\text{ref}}, V_{\text{ref}}) = \text{Softmax}(QK_{\text{ref}}^T/\sqrt{d}) V_{\text{ref}}$将身份信息注入U-Net去噪网络实现身份控制。然而在模型反演攻击场景中，攻击者仅拥有目标类别标签$y_{\text{target}}$而无法获取真实目标图像，这构成了本方法面临的核心技术挑战。深入分析表明，REFace在MIA场景中具备三项关键技术优势：（1）其身份控制接口采用标准化的512维嵌入向量，该接口可被标签条件嵌入层$\mathcal{E}_\psi$无缝替代，无需对换脸模型架构进行实质性修改；（2）其基于潜在扩散模型的生成范式在VAE潜在空间进行条件生成，支持端到端的梯度反向传播，确保分类器损失能够有效指导生成过程；（3）其在大规模人脸数据集上预训练所获得的强生成先验，为高质量的模型反演攻击提供了坚实的理论和实践基础。鉴于上述技术特性，本章提出标签条件嵌入层$\mathcal{E}_\psi$，将离散类别标签映射为连续身份嵌入$e_{\text{id}}=\mathcal{E}_\psi(y_{\text{target}})$，以替代原有的ArcFace编码器，并结合LoRA参数高效微调技术使模型适配新的身份嵌入分布，从而实现无需目标图像的模型反演攻击。

\subsection{标签条件嵌入层设计}

模型反演攻击中，攻击者仅拥有目标类别标签，需设计标签条件嵌入层实现从离散标签到连续身份嵌入的映射。采用多层感知机将类别标签的one-hot编码映射为身份嵌入向量：
\begin{equation}\label{eq:mia_mlp_emb}
    e_{\text{id}} = \text{MLP}_{\psi}(\text{OneHot}(y_{\text{target}})) \in \mathbb{R}^{d_e},
\end{equation}
其中MLP包含2-3个隐藏层，配备ReLU激活函数与LayerNorm。为确保与换脸模型的ID注入模块兼容，MLP输出维度$d_e$设置与ArcFace嵌入维度一致（通常$d_e=512$），并对嵌入向量进行$L_2$归一化使其位于单位超球面上：
\begin{equation}\label{eq:mia_emb_norm}
    e_{\text{id}} \leftarrow \frac{e_{\text{id}}}{\|e_{\text{id}}\|_2}.
\end{equation}

\subsection{LoRA参数高效微调策略}

直接对换脸模型进行全参数微调面临参数量巨大、过拟合风险高等挑战。LoRA技术通过在冻结预训练权重的前提下引入低秩可训练增量，仅需训练原模型1\%-5\%的参数量，有效降低过拟合风险并保留预训练的生成先验。

根据换脸模型的架构特点与身份控制机制，LoRA应用于以下三类关键模块。这些模块的选择基于对身份信息流动路径的分析：参考注意力层直接处理身份嵌入的编码，U-Net注意力层负责特征的全局聚合与身份信息的空间传播，残差块卷积层调整通道间的特征映射——这些模块对身份控制最为敏感，微调它们可以最大化地适配新的身份嵌入分布，同时最小化对生成质量的负面影响。

（1）参考注意力投影矩阵：对第$\ell$层参考注意力的键值投影$W_K^{\ell}, W_V^{\ell}$应用低秩分解：
\begin{equation}\label{eq:mia_lora_ref_proj}
\begin{aligned}
    W_K^{\ell\prime} &= W_K^{\ell} + \frac{\alpha}{r} B_K^{\ell} A_K^{\ell}, \quad
    W_V^{\ell\prime} = W_V^{\ell} + \frac{\alpha}{r} B_V^{\ell} A_V^{\ell},
\end{aligned}
\end{equation}
其中$A_K^{\ell}, A_V^{\ell}\in\mathbb{R}^{r\times 512}$，$B_K^{\ell}, B_V^{\ell}\in\mathbb{R}^{d_h\times r}$,$d_h$为注意力头维度，$r$为LoRA秩，$\alpha$为缩放因子。这些矩阵直接控制身份嵌入编码，是身份信息注入的核心机制。

（2）U-Net注意力层：对去噪U-Net的自注意力和交叉注意力的投影矩阵应用LoRA：
\begin{equation}\label{eq:mia_lora_attn}
\begin{aligned}
    W_Q' &= W_Q + \frac{\alpha}{r} B_Q A_Q, \quad
    W_K' = W_K + \frac{\alpha}{r} B_K A_K, \\
    W_V' &= W_V + \frac{\alpha}{r} B_V A_V, \quad
    W_O' = W_O + \frac{\alpha}{r} B_O A_O,
\end{aligned}
\end{equation}
其中$W_Q, W_K, W_V, W_O$分别为Query、Key、Value与输出投影矩阵。注意力机制负责特征全局聚合，微调这些投影可优先生成分类器敏感的身份特征。

（3）残差块卷积层：对U-Net残差块中的$1\times1$点卷积应用LoRA。$1\times1$卷积因其空间感受野为单位窗口，本质上执行通道间的线性变换，可等价为矩阵乘法操作。设原始卷积权重为$W\in\mathbb{R}^{C_{\text{out}}\times C_{\text{in}}\times 1\times 1}$，由于空间维度均为1，可将其视为二维权重矩阵$\tilde{W}\in\mathbb{R}^{C_{\text{out}}\times C_{\text{in}}}$进行低秩分解。微调后的权重表示为：
\begin{equation}\label{eq:mia_lora_conv}
    W' = W + \frac{\alpha}{r} \text{reshape}(B A, [C_{\text{out}}, C_{\text{in}}, 1, 1]),
\end{equation}
其中$A\in\mathbb{R}^{r\times C_{\text{in}}}$为下投影矩阵，$B\in\mathbb{R}^{C_{\text{out}}\times r}$为上投影矩阵，$\text{reshape}(\cdot)$为张量重塑操作，将矩阵乘积$BA\in\mathbb{R}^{C_{\text{out}}\times C_{\text{in}}}$转换为卷积核格式$\mathbb{R}^{C_{\text{out}}\times C_{\text{in}}\times 1\times 1}$以匹配原始权重$W$的形状，从而可进行张量加法。

\section{多目标优化损失函数设计}
\label{sec:mia_loss}

本节系统设计面向模型反演攻击的多目标优化损失函数，平衡扩散先验保真度、分类器攻击有效性、身份一致性、生成质量与模型正则化五个优化目标。采用任务不确定性加权框架进行自动权重调整。

\subsection{总体损失架构}

本文采用任务不确定性加权框架统一各损失项，避免手动权重调优的复杂性：
\begin{equation}\label{eq:mia_total_loss}
    \mathcal{L}_{\text{total}} = \sum_{i \in \{\text{prior, cls, p-reg, id, perc, reg}\}} \left( \frac{1}{2\sigma_i^2} \mathcal{L}_i + \frac{1}{2}\log\sigma_i^2 \right),
\end{equation}
其中 $\sigma_i$ 为第 $i$ 个任务的可学习不确定性参数，与网络参数联合优化。该框架通过自适应调整各任务权重实现动态平衡：对于难以优化的任务，$\sigma_i$自动增大以降低其在总损失中的权重$\frac{1}{2\sigma_i^2}$，避免单一任务主导训练过程；对于易于优化的任务，$\sigma_i$保持较小以维持较高权重，确保充分收敛。训练时$\sigma_i$采用较小学习率以避免早期过度衰减。注意$\mathcal{L}_{\text{cls}}$与$\mathcal{L}_{\text{p-reg}}$作为独立损失项分别调权，两者协同驱动分类器攻击：前者通过top-k max-margin直接优化logits以远离决策边界，后者通过特征空间正则化稳定优化轨迹。

\subsection{扩散先验损失}

扩散先验损失确保LoRA微调不破坏预训练换脸模型的生成能力，保持生成图像的自然性。沿用扩散模型的标准去噪目标（详见第\ref{sec:diffusion_models}节），采用余弦相似度度量预测噪声与真实噪声的一致性：
\begin{equation}\label{eq:mia_prior_loss}
    \mathcal{L}_{\text{prior}} = \mathbb{E}_{z_0, \epsilon\sim\mathcal{N}(0,I), t} \left[ w(t) \cdot \left(1 - \frac{\langle \epsilon, \epsilon_\theta(z_t, t, e_{\text{id}}) \rangle}{\|\epsilon\|_2 \|\epsilon_\theta(z_t, t, e_{\text{id}})\|_2} \right) \right],
\end{equation}
其中$z_t$为加噪潜在变量，$\epsilon_\theta$为去噪网络。引入时间步加权$w(t) = 1 + \beta \cdot (1 - t/T)$在低噪声阶段强化细节优化，确保生成图像保持高视觉真实度。

\subsection{分类器引导损失}

分类器引导损失驱动生成图像被目标分类器识别为目标类别，是模型反演攻击的核心驱动力。传统交叉熵损失$-\log p_y$仅最大化目标类别概率，易导致生成图像在决策边界附近徘徊。本文采用Li等人\cite{li2024diffmi}提出的top-k max-margin损失，该损失将传统max-margin损失\cite{carlini2017towards}中的"hard max"（仅考虑单个最大的非目标类别logit）替换为"top-k平均"（考虑前k个最大的非目标类别logit），更充分地利用软标签信息增强判别性。

设目标分类器输出logits为$\{\ell_1, \ldots, \ell_C\}$，目标类别为$y$，损失定义为：
\begin{equation}\label{eq:mia_topk_loss}
    \mathcal{L}_{\text{cls}} = -\ell_y + \frac{1}{k} \sum_{j \in \text{top-}k(J \setminus \{y\})} \ell_j,
\end{equation}
其中$J = \{1, \ldots, C\}$为所有类别集合，$\text{top-}k(J \setminus \{y\})$选取除目标类别外logit最高的$k$个类别，$k$根据数据集类别数设定（本文实验中CelebA设为5，CIFAR-10设为2）。该损失同时最小化目标类别logit$\ell_y$的负值（即最大化$\ell_y$）和最大化混淆类别logit的平均值，从而在高维空间中推动生成图像远离决策边界。

为进一步稳定优化过程，本文采用Nguyen等人\cite{nguyen2023rethinking}提出并由Li等人\cite{li2024diffmi}改进的p-reg损失，在特征空间对生成图像进行正则化约束。该损失通过最小化生成图像的特征表示与预计算的类别特征中心之间的距离，避免优化过程中的振荡。设$p_x = F_\theta^{\text{feat}}(\hat{x}) \in \mathbb{R}^{d_{\text{feat}}}$为分类器倒数第二层的特征表示，$c_y \in \mathbb{R}^{d_{\text{feat}}}$为目标类别$y$的特征中心。p-reg损失定义为：
\begin{equation}\label{eq:mia_preg_loss}
    \mathcal{L}_{\text{p-reg}} = \left\|p_x - c_y\right\|_2^2.
\end{equation}
特征中心$c_y$通过在公共数据集上使用目标分类器预先计算获得：对每个类别$y$，将其在公共数据集中所有样本的特征表示平均化，得到该类别的原型中心。这种预计算方式提供了稳定的正则化目标，使生成图像在特征空间向真实数据分布靠拢。

\subsection{身份一致性损失}

身份一致性损失确保生成图像的身份特征与标签条件嵌入$e_{\text{id}}$一致，建立类别标签与视觉身份特征的稳定映射关系。本文采用对比学习框架，利用人脸识别系统在单位超球面上的几何性质，显式增强目标身份与负样本身份的角度分离。

给定目标类别$y_{\text{target}}$，标签条件嵌入层生成身份嵌入$e_{\text{id}} = \mathcal{E}_\psi(y_{\text{target}})$，该嵌入代表希望生成图像具备的身份特征。同时，使用预训练的ArcFace编码器$E_{\text{id}}$提取生成图像$\hat{x}$的实际身份特征$e_{\text{gen}} = E_{\text{id}}(\hat{x})$。身份一致性损失通过对比学习确保$e_{\text{gen}}$接近目标身份嵌入$e_{\text{id}}$，同时远离其他类别的嵌入。$e_{\text{id}}$由MLP从类别标签直接生成，$E_{\text{id}}$仅用于评估生成图像的身份特征是否符合预期。

身份一致性损失采用对比学习形式：
\begin{equation}\label{eq:mia_identity_loss}
    \mathcal{L}_{\text{id}} = \mathbb{E}\left[\max\left(0, m + \frac{\langle E_{\text{id}}(\hat{x}), e_{\text{neg}} \rangle}{\|E_{\text{id}}(\hat{x})\|_2 \|e_{\text{neg}}\|_2} - \frac{\langle E_{\text{id}}(\hat{x}), e_{\text{id}} \rangle}{\|E_{\text{id}}(\hat{x})\|_2 \|e_{\text{id}}\|_2}\right)\right],
\end{equation}
其中$e_{\text{gen}} = E_{\text{id}}(\hat{x})$是预训练ArcFace编码器提取的生成图像的身份特征，$e_{\text{id}} = \mathcal{E}_\psi(y_{\text{target}})$是标签条件嵌入层生成的目标身份嵌入，$e_{\text{neg}} = \mathcal{E}_\psi(y_{\text{neg}})$是从内存库$\mathcal{M}$中采样的负样本类别嵌入（$y_{\text{neg}} \neq y_{\text{target}}$），$m$是角度裕度参数，控制正负样本间的最小角度间隔。

内存库$\mathcal{M}=\{e_1, e_2, \ldots, e_C\}$存储所有$C$个类别的嵌入向量快照，即$e_i = \mathcal{E}_\psi(i), \forall i \in \{1,\ldots,C\}$。训练时，当前目标类别$y_{\text{target}}$的嵌入$e_{\text{id}} = \mathcal{E}_\psi(y_{\text{target}})$通过前向传播实时计算并参与梯度更新，而负样本$e_{\text{neg}}$则从内存库中采样其他$C-1$个类别的嵌入（$y_{\text{neg}} \neq y_{\text{target}}$）。为平衡计算效率与嵌入一致性，内存库每一定步后更新一次，将所有类别的嵌入重新生成并存储，形成周期性快照机制。初始内存库在训练开始时由随机初始化的嵌入层构建，随训练进行逐步演化为超球面上分离良好的类别表示。

该损失通过hinge loss形式，仅在正样本相似度与负样本相似度之差小于裕度$m$时施加惩罚，驱动优化过程同时满足：（1）最大化$\cos(e_{\text{gen}}, e_{\text{id}})$，使生成图像的身份特征接近目标身份；（2）最小化$\cos(e_{\text{gen}}, e_{\text{neg}})$，使生成图像远离其他类别身份。该对比机制确保不同类别的身份嵌入在超球面上具有明确的角度分离，增加类间隔，防止类别间的身份混淆。内存库的作用包括：（1）提供负样本池，避免每步重复计算所有类别嵌入；（2）记录嵌入层的演化轨迹，辅助对比学习的稳定性；（3）确保全局类间分离的一致性。

\subsection{感知质量损失}

为确保生成图像的视觉真实性，本文采用LPIPS~\cite{zhang2018unreasonable}度量生成图像$\hat{x}$与源图像$x_{\text{src}}$的感知距离。LPIPS基于预训练深度网络提取多层特征进行比对，相比像素级损失能更好地保持视觉风格与结构，避免过拟合：
\begin{equation}\label{eq:mia_perception_combined}
    \mathcal{L}_{\text{perc}} = \mathcal{L}_{\text{LPIPS}}(\hat{x}, x_{\text{src}}).
\end{equation}

\subsection{正则化损失}
\label{subsec:mia_regularization}

正则化损失包括嵌入归一化约束和LoRA权重正则化，确保模型训练的稳定性与泛化能力：
\begin{equation}\label{eq:mia_reg_loss}
    \mathcal{L}_{\text{reg}} = \mathcal{L}_{\text{emb-norm}} + \lambda_{\text{lora}} \mathcal{L}_{\text{lora}} = \sum_{y=1}^C (\|e_{\text{id}}^{(y)}\|_2 - 1)^2 + \lambda_{\text{lora}} \sum_{\ell} (\|A_{\ell}\|_F^2 + \|B_{\ell}\|_F^2),
\end{equation}
其中嵌入归一化约束强制所有类别的嵌入向量位于单位超球面上，LoRA正则化防止权重过大导致的过拟合。

\section{训练与推理流程}
\label{sec:mia_training}

本节详细阐述基于换脸先验的模型反演攻击方法的训练与推理流程。首先介绍渐进式三阶段训练策略，通过图像条件预热、混合条件过渡和纯标签条件适配实现从图像条件到标签条件的平滑模态转换；随后描述整体架构的前向传播与反向传播流程，明确各模块的数据流向与梯度更新机制；最后给出完整的训练算法与推理策略，为方法的实现与复现提供系统化指导。

\subsection{渐进式训练策略}
\label{subsec:mia_progressive_training}

标签条件嵌入层替换原始身份编码器后，模型面临从图像条件生成到标签条件生成的模态转换挑战。直接使用随机初始化的标签嵌入会导致生成图像呈现随机噪声，训练极不稳定。借鉴课程学习与知识蒸馏中的教师退火思想，本文采用渐进式微调策略，通过三个阶段实现平滑的模态转换。

第一阶段为图像条件预热。该阶段利用公开人脸数据集（如CelebA、FFHQ）的真实图像，使用预训练ArcFace编码器从图像提取身份嵌入$e_{\text{id}} = E_{\text{id}}(x_{\text{real}})$。标签条件嵌入层$\mathcal{E}_\psi$在此阶段完全不参与训练，目的是让LoRA适配层专注学习如何利用外部提供的身份嵌入进行换脸，建立"身份嵌入向量→高质量换脸生成"的映射能力，而不是学习如何生成这些嵌入。这种解耦训练策略确保LoRA层能够接受任意符合ArcFace嵌入空间分布的向量，为后续标签嵌入的注入奠定基础。冻结换脸模型主干与扩散U-Net，仅训练LoRA参数$\{A_\ell, B_\ell\}$，损失函数为
\begin{equation}\label{eq:mia_stage0_loss}
    \mathcal{L}_{\text{stage0}} = \mathcal{L}_{\text{prior}} + \mathcal{L}_{\text{perc}}.
\end{equation}
该阶段聚焦于扩散先验保真度与感知质量，使LoRA适配层学习如何在保持生成质量的前提下利用外部身份嵌入进行换脸。训练持续至生成图像FID稳定在较低水平。

第二阶段为混合条件过渡。该阶段通过插值混合真实图像嵌入与标签嵌入，实现从图像条件到标签条件的平滑迁移。采用时间依赖的线性插值策略
\begin{equation}\label{eq:mia_hybrid_embedding}
    e_{\text{id}}(t) = (1-\lambda(t)) \cdot E_{\text{id}}(x_{\text{real}}) + \lambda(t) \cdot \mathcal{E}_\psi(y),
\end{equation}
其中$t$为当前训练步数，$\lambda(t)$为退火系数，控制标签嵌入的权重。采用余弦退火调度
\begin{equation}\label{eq:mia_annealing_schedule}
    \lambda(t) = \frac{1}{2}\left(1 - \cos\left(\frac{\pi \cdot \min(t, T_{\text{anneal}})}{T_{\text{anneal}}}\right)\right),
\end{equation}
其中$T_{\text{anneal}}$为退火周期。相比线性退火$\lambda(t)=t/T_{\text{anneal}}$，余弦调度在初期缓慢增长，中期快速过渡，后期平滑收敛，提供更稳定的过渡曲线。

该阶段解冻标签条件嵌入层$\mathcal{E}_\psi$，联合优化嵌入层与LoRA参数。为实现从图像条件到标签条件的平滑过渡，损失函数在保持基础生成质量约束的前提下，通过退火机制逐步引入攻击相关损失：
\begin{equation}\label{eq:mia_stage1_loss}
    \mathcal{L}_{\text{stage1}} = \mathcal{L}_{\text{prior}} + \mathcal{L}_{\text{perc}} + \lambda(t) \cdot (\mathcal{L}_{\text{cls}} + \mathcal{L}_{\text{p-reg}} + \mathcal{L}_{\text{id}} + \mathcal{L}_{\text{reg}}),
\end{equation}
其中$\mathcal{L}_{\text{prior}} + \mathcal{L}_{\text{perc}}$为基础生成质量约束（式~\ref{eq:mia_stage0_loss}），$\mathcal{L}_{\text{cls}} + \mathcal{L}_{\text{p-reg}} + \mathcal{L}_{\text{id}} + \mathcal{L}_{\text{reg}}$为攻击优化相关损失，$\lambda(t)$为余弦退火系数（式~\ref{eq:mia_annealing_schedule}）。注意各攻击损失项采用任务不确定性加权框架（式~\ref{eq:mia_total_loss}）进行自动权重调整，此处为简化表示未显式写出$\sigma_i$参数。

该设计遵循课程学习原理，通过退火系数实现训练目标的动态平衡：（1）初期$\lambda(t)\approx 0$时，仅优化扩散先验保真度$\mathcal{L}_{\text{prior}}$与感知质量$\mathcal{L}_{\text{perc}}$，模型专注于利用真实图像嵌入学习高质量换脸生成；（2）中期$\lambda(t)\approx 0.5$时，攻击损失权重增加至基础损失的一半，标签嵌入在分类器引导$\mathcal{L}_{\text{cls}}$、特征正则化$\mathcal{L}_{\text{p-reg}}$与身份一致性$\mathcal{L}_{\text{id}}$的共同作用下逐步接管身份控制；（3）后期$\lambda(t)\approx 1.0$时，攻击损失与基础损失权重相当，模型完全适配标签条件生成并优化分类器攻击效果。该策略确保生成质量约束始终存在，避免攻击优化破坏图像真实性，同时通过平滑的退火机制实现从生成先验保持到攻击优化的自然过渡。

当退火系数$\lambda(t)$达到1.0，分类器损失$\mathcal{L}_{\text{cls}}$与身份一致性损失$\mathcal{L}_{\text{id}}$完全激活，且生成图像在目标分类器上的置信度与FID指标同时稳定时，切换至下一阶段。

第三阶段为纯标签条件适配。该阶段完全移除真实图像依赖，进入最终的分类器攻击优化。完全使用标签条件嵌入层生成身份嵌入$e_{\text{id}} = \mathcal{E}_\psi(y)$，此时模型已学会从类别标签生成有效的身份嵌入。解冻U-Net注意力层与残差块卷积的LoRA参数，引入完整损失函数
\begin{equation}\label{eq:mia_stage2_loss}
    \mathcal{L}_{\text{stage2}} = \mathcal{L}_{\text{total}} = \sum_{i \in \{\text{prior, cls, p-reg, id, perc, reg}\}} \left( \frac{1}{2\sigma_i^2} \mathcal{L}_i + \frac{1}{2}\log\sigma_i^2 \right).
\end{equation}
该阶段同时优化攻击有效性与生成质量，各损失权重通过任务不确定性框架自动学习。其中$\mathcal{L}_{\text{cls}}$（top-k max-margin）与$\mathcal{L}_{\text{p-reg}}$（特征中心正则化）协同驱动分类器攻击，前者最大化目标类别置信度并远离决策边界，后者稳定优化轨迹并约束特征表示向类别原型靠拢。LoRA参数采用较小学习率以避免遗忘已学习的生成能力。训练持续至攻击成功率与生成质量同时达到预期目标。

\subsection{整体架构}

如图~\ref{fig:mia_architecture}所示，本章提出的模型反演攻击架构由三个核心模块组成：标签条件嵌入层$\mathcal{E}_\psi$、预训练换脸模型$G_\phi$与LoRA微调模块、目标分类器$F_\theta$。

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.9\textwidth]{images/train_mia.drawio.pdf}
    \caption{基于换脸先验的模型反演攻击架构示意图。标签条件嵌入层（左）将类别标签映射为512维身份嵌入；换脸模型（中）通过参考注意力机制将身份嵌入注入U-Net去噪网络，结合源图像生成目标图像；目标分类器（右）提供分类损失梯度用于端到端微调。虚线表示梯度反向传播路径。}
    \label{fig:mia_architecture}
\end{figure}

给定目标类别标签$y_{\text{target}}\in\{1,2,\ldots,C\}$与随机采样的源图像$x_{\text{src}}$，系统首先通过标签条件嵌入层将类别标签的one-hot编码映射为512维身份嵌入向量$e_{\text{id}} = \mathcal{E}_{\psi}(y_{\text{target}})\in\mathbb{R}^{512}$，并进行$L_2$归一化使其位于单位超球面上。随后，VAE编码器将源图像压缩为潜在表示$z_0 = \text{VAE}_{\text{enc}}(x_{\text{src}}) \in \mathbb{R}^{4\times64\times64}$。在扩散去噪阶段，系统采样扩散时间步$t\sim\mathcal{U}(0,T)$并添加噪声$z_t = \sqrt{\bar{\alpha}_t}z_0 + \sqrt{1-\bar{\alpha}_t}\epsilon$（$\epsilon\sim\mathcal{N}(0,I)$），U-Net去噪网络结合身份嵌入$e_{\text{id}}$预测噪声$\hat{\epsilon} = \epsilon_\theta(z_t, t, e_{\text{id}})$，通过多步DDIM采样恢复干净潜在表示$\hat{z}_0$。最后，VAE解码器生成最终图像$\hat{x} = \text{VAE}_{\text{dec}}(\hat{z}_0)$，并输入目标分类器获得logits$\ell = F_\theta(\hat{x})\in\mathbb{R}^C$用于计算分类损失与身份损失。

训练过程中，多目标损失函数$\mathcal{L}_{\text{total}}$（式~\ref{eq:mia_total_loss}）对可训练参数进行端到端梯度反向传播，包括标签条件嵌入层$\psi$、LoRA适配矩阵$\{A_\ell, B_\ell\}$以及任务不确定性权重$\{\sigma_i\}$。本方法冻结换脸模型主干（VAE、U-Net主体）与目标分类器参数，仅更新LoRA增量与嵌入层，从而确保生成先验不被破坏。嵌入层采用较大学习率$\eta_{\text{emb}}=10^{-3}$以快速学习类别映射，LoRA参数使用较小学习率$\eta_{\text{lora}}=10^{-4}\text{-}10^{-5}$以保持微调稳定性。此外，采用梯度裁剪（最大范数1.0-5.0）防止扩散模型训练中常见的梯度爆炸现象。

\subsection{训练流程}

算法~\ref{alg:mia_stage0}、算法~\ref{alg:mia_stage1}和算法~\ref{alg:mia_stage2}给出了渐进式三阶段训练的详细流程。

\begin{algorithm}[htbp]
  \caption{MIA阶段0：图像条件预热}
  \label{alg:mia_stage0}
  \begin{algorithmic}[1]
    \REQUIRE 公开数据集$\mathcal{D}_{\text{public}}=\{(x_i, y_i)\}$（如CelebA、FFHQ），换脸模型$G_\phi$（主干冻结），预训练身份编码器$E_{\text{id}}$，学习率$\eta_{\text{lora}}$
    \ENSURE 初步训练的LoRA参数$\{A_\ell, B_\ell\}$
    \STATE 初始化LoRA参数$\{A_\ell, B_\ell\}$（仅参考注意力层）
    \FOR{训练步数$t=1$ 到 $T_0$}
    \STATE 从$\mathcal{D}_{\text{public}}$中采样批数据$\{(x_{\text{real}}^{(i)}, y_i)\}_{i=1}^B$
    \STATE 采样源图像批$\{x_{\text{src}}^{(i)}\}_{i=1}^B$
    \FOR{批内样本$i=1$ 到 $B$}
    \STATE 从真实图像提取身份嵌入：$e_{\text{id}}^{(i)} = E_{\text{id}}(x_{\text{real}}^{(i)})$
    \STATE 采样扩散时间步：$t^{(i)} \sim \mathcal{U}(0, T)$
    \STATE 编码源图像：$z_0^{(i)} = \text{VAE}_{\text{enc}}(x_{\text{src}}^{(i)})$
    \STATE 添加噪声：$z_t^{(i)} = \sqrt{\bar{\alpha}_{t^{(i)}}} z_0^{(i)} + \sqrt{1-\bar{\alpha}_{t^{(i)}}} \epsilon^{(i)}$
    \STATE 预测噪声：$\hat{\epsilon}^{(i)} = \epsilon_{\theta}(z_t^{(i)}, t^{(i)}, e_{\text{id}}^{(i)})$
    \STATE 计算扩散先验损失：$\mathcal{L}_{\text{prior}}^{(i)} = w(t^{(i)}) \cdot (1 - \cos(\epsilon^{(i)}, \hat{\epsilon}^{(i)}))$
    \STATE 生成图像：$\hat{x}^{(i)} = G_{\phi}(e_{\text{id}}^{(i)}, x_{\text{src}}^{(i)})$
    \STATE 计算感知损失：$\mathcal{L}_{\text{perc}}^{(i)}$
    \ENDFOR
    \STATE 计算批平均损失：$\mathcal{L}_{\text{stage0}} = \frac{1}{B}\sum_{i=1}^B [\mathcal{L}_{\text{prior}}^{(i)} + \mathcal{L}_{\text{perc}}^{(i)}]$
    \STATE 更新LoRA参数：$\{A_\ell, B_\ell\} \leftarrow \{A_\ell, B_\ell\} - \eta_{\text{lora}} \cdot \nabla_{\{A_\ell, B_\ell\}} \mathcal{L}_{\text{stage0}}$
    \ENDFOR
    \RETURN $\{A_\ell, B_\ell\}$
  \end{algorithmic}
\end{algorithm}

\begin{algorithm}[htbp]
  \caption{MIA阶段1：混合条件过渡}
  \label{alg:mia_stage1}
  \begin{algorithmic}[1]
    \REQUIRE 公开数据集$\mathcal{D}_{\text{public}}$，阶段0训练的LoRA参数，嵌入层$\mathcal{E}_\psi$，退火周期$T_{\text{anneal}}$，学习率$\eta_{\text{emb}}, \eta_{\text{lora}}$
    \ENSURE 训练后的嵌入层$\psi$与LoRA参数$\{A_\ell, B_\ell\}$
    \STATE 初始化嵌入层参数$\psi$与身份嵌入内存库$\mathcal{M} = \{\mathcal{E}_\psi(1), \ldots, \mathcal{E}_\psi(C)\}$
    \STATE 初始化任务不确定性参数$\{\sigma_i\}_{i\in\{\text{prior,cls,p-reg,id,perc,reg}\}}$（用于阶段2损失）
    \FOR{训练步数$t=1$ 到 $T_1$}
    \STATE 计算退火系数：$\lambda(t) = \frac{1}{2}(1 - \cos(\frac{\pi \cdot \min(t, T_{\text{anneal}})}{T_{\text{anneal}}}))$
    \STATE 从$\mathcal{D}_{\text{public}}$中采样批数据$\{(x_{\text{real}}^{(i)}, y_i)\}_{i=1}^B$与源图像$\{x_{\text{src}}^{(i)}\}$
    \FOR{批内样本$i=1$ 到 $B$}
    \STATE 提取真实图像嵌入：$e_{\text{real}}^{(i)} = E_{\text{id}}(x_{\text{real}}^{(i)})$
    \STATE 生成标签嵌入：$e_{\text{label}}^{(i)} = \mathcal{E}_\psi(y_i)$
    \STATE 混合身份嵌入：$e_{\text{id}}^{(i)} = (1-\lambda(t)) \cdot e_{\text{real}}^{(i)} + \lambda(t) \cdot e_{\text{label}}^{(i)}$
    \STATE 采样时间步并生成噪声潜在变量，执行去噪生成图像$\hat{x}^{(i)}$（同阶段0）
    \STATE 计算基础生成损失：$\mathcal{L}_{\text{prior}}^{(i)}, \mathcal{L}_{\text{perc}}^{(i)}$
    \STATE 从内存库采样负样本：$e_{\text{neg}}^{(i)} \sim \mathcal{M} \setminus \{\mathcal{E}_\psi(y_i)\}$
    \STATE 计算攻击相关损失：$\mathcal{L}_{\text{cls}}^{(i)}, \mathcal{L}_{\text{p-reg}}^{(i)}, \mathcal{L}_{\text{id}}^{(i)}, \mathcal{L}_{\text{reg}}^{(i)}$（带任务不确定性权重）
    \STATE 计算攻击损失和：$\mathcal{L}_{\text{attack}}^{(i)} = \sum_{j\in\{\text{cls,p-reg,id,reg}\}} (\frac{1}{2\sigma_j^2}\mathcal{L}_j^{(i)} + \frac{1}{2}\log\sigma_j^2)$
    \ENDFOR
    \STATE 计算总损失：$\mathcal{L}_{\text{stage1}} = \frac{1}{B}\sum_{i=1}^B [\mathcal{L}_{\text{prior}}^{(i)} + \mathcal{L}_{\text{perc}}^{(i)} + \lambda(t) \cdot \mathcal{L}_{\text{attack}}^{(i)}]$
    \STATE 每100步更新内存库：$\mathcal{M} \leftarrow \{\mathcal{E}_\psi(1), \ldots, \mathcal{E}_\psi(C)\}$
    \STATE 更新嵌入层：$\psi \leftarrow \psi - \eta_{\text{emb}} \cdot \nabla_\psi \mathcal{L}_{\text{stage1}}$
    \STATE 更新LoRA：$\{A_\ell, B_\ell\} \leftarrow \{A_\ell, B_\ell\} - \eta_{\text{lora}} \cdot \nabla_{\{A_\ell, B_\ell\}} \mathcal{L}_{\text{stage1}}$
    \ENDFOR
    \RETURN $\psi$, $\{A_\ell, B_\ell\}$
  \end{algorithmic}
\end{algorithm}

\begin{algorithm}[htbp]
  \caption{MIA阶段2：纯标签条件适配}
  \label{alg:mia_stage2}
  \begin{algorithmic}[1]
    \REQUIRE 目标分类器训练集$\mathcal{D}_{\text{target}}=\{(x_i, y_i)\}$，阶段1训练的$\psi$与$\{A_\ell, B_\ell\}$，目标分类器$F_\theta$，学习率$\eta_{\text{emb}}, \eta_{\text{lora}}$
    \ENSURE 最终微调的$\psi$与$\{A_\ell, B_\ell\}$
    \STATE 初始化任务不确定性参数$\{\sigma_i\}_{i\in\{\text{prior,cls,p-reg,id,perc,reg}\}}$
    \STATE 初始化U-Net注意力与残差块的LoRA参数（权重迁移自阶段1）
    \FOR{训练步数$t=1$ 到 $T_2$}
    \STATE 从$\mathcal{D}_{\text{target}}$中采样批数据$\{(x_i, y_i)\}_{i=1}^B$与源图像$\{x_{\text{src}}^{(i)}\}$
    \FOR{批内样本$i=1$ 到 $B$}
    \STATE 生成标签嵌入：$e_{\text{id}}^{(i)} = \mathcal{E}_\psi(y_i)$
    \STATE 执行扩散去噪与完整采样生成$\hat{x}^{(i)}$（同阶段1）
    \STATE 计算所有损失项：$\mathcal{L}_{\text{prior}}^{(i)}, \mathcal{L}_{\text{cls}}^{(i)}, \mathcal{L}_{\text{p-reg}}^{(i)}, \mathcal{L}_{\text{id}}^{(i)}, \mathcal{L}_{\text{perc}}^{(i)}, \mathcal{L}_{\text{reg}}^{(i)}$
    \ENDFOR
    \STATE 通过任务不确定性框架计算总损失：
    \STATE \quad $\mathcal{L}_{\text{stage2}} = \sum_{i\in\{\text{prior,cls,p-reg,id,perc,reg}\}} \left(\frac{1}{2\sigma_i^2}\bar{\mathcal{L}}_i + \frac{1}{2}\log\sigma_i^2\right)$
    \STATE 更新参数：
    \STATE \quad $\psi \leftarrow \psi - \eta_{\text{emb}} \cdot \nabla_\psi \mathcal{L}_{\text{stage2}}$
    \STATE \quad $\{A_\ell, B_\ell\} \leftarrow \{A_\ell, B_\ell\} - 0.1\eta_{\text{lora}} \cdot \nabla_{\{A_\ell, B_\ell\}} \mathcal{L}_{\text{stage2}}$（注意降低学习率）
    \STATE \quad $\{\sigma_i\} \leftarrow \{\sigma_i\} - 0.1\eta_{\text{emb}} \cdot \nabla_{\{\sigma_i\}} \mathcal{L}_{\text{stage2}}$
    \ENDFOR
    \RETURN $\psi$, $\{A_\ell, B_\ell\}$
  \end{algorithmic}
\end{algorithm}

\subsection{推理策略}

推理阶段的目标是为给定目标类别$y_{\text{target}}$生成高质量的攻击样本。基本推理流程如下：首先通过标签条件嵌入层生成身份嵌入$e_{\text{id}} = \mathcal{E}_\psi(y_{\text{target}})$；然后结合源图像$x_{\text{src}}$通过换脸模型生成攻击样本$\hat{x} = G_{\phi+\Delta}(e_{\text{id}}, x_{\text{src}})$，其中$\Delta$表示训练得到的LoRA增量参数。

\textbf{源图像采样策略：}源图像$x_{\text{src}}$的选择对最终攻击效果有重要影响。本文采用多样性驱动的采样策略：（1）从公开人脸数据集（如CelebA、FFHQ）中随机采样$N_{\text{src}}$张图像作为候选源图像集合（推荐$N_{\text{src}}=20\text{-}50$）；（2）确保候选集覆盖不同的姿态、表情、光照等属性，可通过预训练属性估计器度量候选集的属性方差，选择方差最大的子集；（3）对每个源图像生成攻击样本并通过目标分类器评估，选择使$F_\theta(\hat{x})_{y_{\text{target}}}$最大的前$K$个样本（$K=5\text{-}10$）作为最终输出。该策略在保持样本多样性的同时优化攻击成功率。

\textbf{LoRA权重合并：}为消除推理开销，训练完成后可将LoRA权重合并到基础模型：$W' = W + \frac{\alpha}{r}BA$，使推理速度与原始REFace模型相当（单张图像约4.7秒，N=4步DDIM采样）。合并后的模型可作为独立的攻击工具部署，无需额外的适配层。

\section{本章小结}
\label{sec:mia_summary}

本章提出了基于换脸先验与标签条件嵌入的模型反演攻击方法,用于评估人脸分类模型的隐私泄露风险。该方法利用预训练换脸模型的生成能力,通过标签条件嵌入层将类别标签映射为身份嵌入,并采用LoRA技术进行参数高效微调,实现高质量的模型反演攻击。实验结果表明该方法在攻击成功率与图像质量方面均达到先进水平,为生物特征识别系统的安全性评估提供了有效工具。
% Local Variables:
% TeX-master: "../main"
% TeX-engine: xetex
% End:
