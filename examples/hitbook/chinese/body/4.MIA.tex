% !Mode:: "TeX:UTF-8"

\chapter{基于换脸先验的模型反演攻击方法}[Model Inversion Attack Based on Face Swapping Prior]\label{chap:MIA}

\section{引言}

模型反演攻击旨在从训练完成的分类模型中重建其训练数据的敏感特征。传统基于梯度优化的方法直接在像素空间进行优化，面临生成质量低下、优化效率不足等问题。近年来引入生成式先验可提升攻击效果，但现有工作在身份控制精度与生成保真度的平衡上仍存在不足。

本章将扩散换脸模型应用于模型反演攻击任务。换脸模型具有显式的身份属性解耦机制，但其标准推理流程依赖真实目标图像，而攻击场景中仅拥有类别标签。本章设计标签条件嵌入层、低秩适应微调、渐进式训练策略与多目标优化框架，将离散标签映射为连续身份嵌入，实现从类别标签到高保真攻击样本的生成。

本章首先形式化定义问题与威胁模型，随后阐述换脸先验模型的选择、标签条件嵌入层设计、低秩适应微调策略、多目标优化损失函数框架与渐进式训练策略，最后给出完整的训练算法与推理流程。

\section{形式化问题定义}
\label{sec:mia_problem}

根据第\ref{sec:thesis_structure}节建立的攻击任务框架，简要回顾模型反演攻击的形式化定义。设目标分类器为 $F_\theta:\mathcal{X}\to\mathbb{R}^C$，其中 $\mathcal{X}$ 为输入空间（如 $\mathbb{R}^{H\times W\times 3}$ 表示RGB图像），$C$ 为类别数量，$\theta$ 为模型参数。给定目标类别标签 $y_{\text{target}}\in\{1,2,\ldots,C\}$，攻击者的目标是生成图像集合 $\{\hat{x}_1, \hat{x}_2, \ldots, \hat{x}_K\}$，使其同时满足分类器认同度、感知真实性、身份相关性与多样性四个条件。完整的形式化定义与约束优化问题详见第\ref{sec:thesis_structure}节。

本章主要关注白盒威胁模型，即攻击者拥有目标分类器 $F_\theta$ 的完整信息，包括模型架构、参数以及完整的梯度信息 $\nabla_x F_\theta(x)$。这一威胁模型为评估模型的最大隐私泄露风险提供了上界，对应于模型开源、内部泄露或逆向工程成功的场景。在白盒设定下，攻击者可以直接利用梯度信息进行端到端优化：将分类器损失 $\mathcal{L}_{\text{cls}}(F_\theta(\hat{x}), y_{\text{target}})$ 融入生成模型的训练目标，通过反向传播更新生成器参数，使生成轨迹持续逼近目标类别的高置信区域。相比黑盒或灰盒场景（仅能查询输出概率），白盒访问权限提供了更强的优化信号，从而能够实现更高质量的重建结果。这一设定为深入研究方法设计与性能边界提供了理想的实验环境。

\section{基于换脸先验的模型反演架构}
\label{sec:mia_architecture}

\subsection{换脸先验模型的选择与分析}

换脸模型作为本章方法的核心生成先验，其选择对最终攻击性能有决定性影响。理想的换脸模型应满足：（1）高质量的身份迁移能力；（2）显式的身份-属性解耦机制；（3）高感知质量与真实感；（4）支持端到端梯度反向传播。

基于上述要求，本章选择REFace~\cite{sanoojan2024reface}作为换脸先验模型。REFace是一种基于扩散模型的统一换脸方法，其将换脸任务重构为训练时自监督修复任务，通过多步DDIM采样增强与CLIP特征解耦机制实现高保真的身份迁移。该方法在CelebA-HQ数据集上取得98.8\%的身份检索准确率和6.09的FID分数，在生成质量和身份保持能力方面显著优于现有的基于扩散的换脸方法。

REFace的标准推理流程需要提供真实的目标图像$x_{\text{target}}$，利用预训练ArcFace编码器提取512维身份嵌入$e_{\text{id}} = E_{\text{id}}(x_{\text{target}}) \in \mathbb{R}^{512}$，并通过参考注意力机制$\text{RefAttn}(Q, K_{\text{ref}}, V_{\text{ref}}) = \text{Softmax}(QK_{\text{ref}}^T/\sqrt{d}) V_{\text{ref}}$将身份信息注入U-Net去噪网络实现身份控制。然而在模型反演攻击场景中，攻击者仅拥有目标类别标签$y_{\text{target}}$而无法获取真实目标图像，这构成了本方法面临的核心技术挑战。深入分析表明，REFace在MIA场景中具备三项关键技术优势：（1）其身份控制接口采用标准化的512维嵌入向量，该接口可被标签条件嵌入层$\mathcal{E}_\psi$无缝替代，无需对换脸模型架构进行实质性修改；（2）其基于潜在扩散模型的生成范式在VAE潜在空间进行条件生成，支持端到端的梯度反向传播，确保分类器损失能够有效指导生成过程；（3）其在大规模人脸数据集上预训练所获得的强生成先验，为高质量的模型反演攻击提供了坚实的理论和实践基础。鉴于上述技术特性，本章提出标签条件嵌入层$\mathcal{E}_\psi$，将离散类别标签映射为连续身份嵌入$e_{\text{id}}=\mathcal{E}_\psi(y_{\text{target}})$，以替代原有的ArcFace编码器，并结合LoRA参数高效微调技术使模型适配新的身份嵌入分布，从而实现无需目标图像的模型反演攻击。

\subsection{标签条件嵌入层设计}

模型反演攻击中，攻击者仅拥有目标类别标签，需设计标签条件嵌入层实现从离散标签到连续身份嵌入的映射。采用多层感知机将类别标签的one-hot编码映射为身份嵌入向量：
\begin{equation}\label{eq:mia_mlp_emb}
    e_{\text{id}} = \text{MLP}_{\psi}(\text{OneHot}(y_{\text{target}})) \in \mathbb{R}^{d_e},
\end{equation}
其中MLP包含2-3个隐藏层，配备ReLU激活函数与LayerNorm。为确保与换脸模型的ID注入模块兼容，MLP输出维度$d_e$设置与ArcFace嵌入维度一致（通常$d_e=512$），并对嵌入向量进行$L_2$归一化使其位于单位超球面上：
\begin{equation}\label{eq:mia_emb_norm}
    e_{\text{id}} \leftarrow \frac{e_{\text{id}}}{\|e_{\text{id}}\|_2}.
\end{equation}

\subsection{LoRA参数高效微调策略}

直接对换脸模型进行全参数微调面临参数量巨大、过拟合风险高等挑战。LoRA技术通过在冻结预训练权重的前提下引入低秩可训练增量，仅需训练原模型1\%-5\%的参数量，有效降低过拟合风险并保留预训练的生成先验。

根据换脸模型的架构特点与身份控制机制，LoRA应用于以下三类关键模块。这些模块的选择基于对身份信息流动路径的分析：参考注意力层直接处理身份嵌入的编码，U-Net注意力层负责特征的全局聚合与身份信息的空间传播，残差块卷积层调整通道间的特征映射——这些模块对身份控制最为敏感，微调它们可以最大化地适配新的身份嵌入分布，同时最小化对生成质量的负面影响。

（1）参考注意力投影矩阵：对第$\ell$层参考注意力的键值投影$W_K^{\ell}, W_V^{\ell}$应用低秩分解：
\begin{equation}\label{eq:mia_lora_ref_proj}
\begin{aligned}
    W_K^{\ell\prime} &= W_K^{\ell} + \frac{\alpha}{r} B_K^{\ell} A_K^{\ell}, \quad
    W_V^{\ell\prime} = W_V^{\ell} + \frac{\alpha}{r} B_V^{\ell} A_V^{\ell},
\end{aligned}
\end{equation}
其中$A_K^{\ell}, A_V^{\ell}\in\mathbb{R}^{r\times 512}$，$B_K^{\ell}, B_V^{\ell}\in\mathbb{R}^{d_h\times r}$,$d_h$为注意力头维度，$r$为LoRA秩，$\alpha$为缩放因子。这些矩阵直接控制身份嵌入编码，是身份信息注入的核心机制。

（2）U-Net注意力层：对去噪U-Net的自注意力和交叉注意力的投影矩阵应用LoRA：
\begin{equation}\label{eq:mia_lora_attn}
\begin{aligned}
    W_Q' &= W_Q + \frac{\alpha}{r} B_Q A_Q, \quad
    W_K' = W_K + \frac{\alpha}{r} B_K A_K, \\
    W_V' &= W_V + \frac{\alpha}{r} B_V A_V, \quad
    W_O' = W_O + \frac{\alpha}{r} B_O A_O,
\end{aligned}
\end{equation}
其中$W_Q, W_K, W_V, W_O$分别为Query、Key、Value与输出投影矩阵。注意力机制负责特征全局聚合，微调这些投影可优先生成分类器敏感的身份特征。

（3）残差块卷积层：对U-Net残差块中的$1\times1$点卷积应用LoRA。$1\times1$卷积因其空间感受野为单位窗口，本质上执行通道间的线性变换，可等价为矩阵乘法操作。设原始卷积权重为$W\in\mathbb{R}^{C_{\text{out}}\times C_{\text{in}}\times 1\times 1}$，由于空间维度均为1，可将其视为二维权重矩阵$\tilde{W}\in\mathbb{R}^{C_{\text{out}}\times C_{\text{in}}}$进行低秩分解。微调后的权重表示为：
\begin{equation}\label{eq:mia_lora_conv}
    W' = W + \frac{\alpha}{r} \text{reshape}(B A, [C_{\text{out}}, C_{\text{in}}, 1, 1]),
\end{equation}
其中$A\in\mathbb{R}^{r\times C_{\text{in}}}$为下投影矩阵，$B\in\mathbb{R}^{C_{\text{out}}\times r}$为上投影矩阵，$\text{reshape}(\cdot)$为张量重塑操作，将矩阵乘积$BA\in\mathbb{R}^{C_{\text{out}}\times C_{\text{in}}}$转换为卷积核格式$\mathbb{R}^{C_{\text{out}}\times C_{\text{in}}\times 1\times 1}$以匹配原始权重$W$的形状，从而可进行张量加法。

\section{多目标优化损失函数设计}
\label{sec:mia_loss}

本节系统设计面向模型反演攻击的多目标优化损失函数，平衡扩散先验保真度、分类器攻击有效性、身份一致性、生成质量与模型正则化五个优化目标。采用任务不确定性加权框架进行自动权重调整。

\subsection{总体损失架构}

本文采用任务不确定性加权框架统一各损失项，避免手动权重调优的复杂性：
\begin{equation}\label{eq:mia_total_loss}
    \mathcal{L}_{\text{total}} = \sum_{i \in \{\text{prior, cls, p-reg, id, perc, reg}\}} \left( \frac{1}{2\sigma_i^2} \mathcal{L}_i + \frac{1}{2}\log\sigma_i^2 \right),
\end{equation}
其中 $\sigma_i$ 为第 $i$ 个任务的可学习不确定性参数，与网络参数联合优化。该框架通过自适应调整各任务权重实现动态平衡：对于难以优化的任务，$\sigma_i$自动增大以降低其在总损失中的权重$\frac{1}{2\sigma_i^2}$，避免单一任务主导训练过程；对于易于优化的任务，$\sigma_i$保持较小以维持较高权重，确保充分收敛。训练时$\sigma_i$采用较小学习率以避免早期过度衰减。注意$\mathcal{L}_{\text{cls}}$与$\mathcal{L}_{\text{p-reg}}$作为独立损失项分别调权，两者协同驱动分类器攻击：前者通过top-k max-margin直接优化logits以远离决策边界，后者通过特征空间正则化稳定优化轨迹。

\subsection{扩散先验损失}

扩散先验损失确保LoRA微调不破坏预训练换脸模型的生成能力，保持生成图像的自然性。沿用扩散模型的标准去噪目标（详见第\ref{sec:diffusion_models}节），采用余弦相似度度量预测噪声与真实噪声的一致性：
\begin{equation}\label{eq:mia_prior_loss}
    \mathcal{L}_{\text{prior}} = \mathbb{E}_{z_0, \epsilon\sim\mathcal{N}(0,I), t} \left[ w(t) \cdot \left(1 - \frac{\langle \epsilon, \epsilon_\theta(z_t, t, e_{\text{id}}) \rangle}{\|\epsilon\|_2 \|\epsilon_\theta(z_t, t, e_{\text{id}})\|_2} \right) \right],
\end{equation}
其中$z_t$为加噪潜在变量，$\epsilon_\theta$为去噪网络。引入时间步加权$w(t) = 1 + \beta \cdot (1 - t/T)$在低噪声阶段强化细节优化，确保生成图像保持高视觉真实度。

\subsection{分类器引导损失}

分类器引导损失驱动生成图像被目标分类器识别为目标类别，是模型反演攻击的核心驱动力。传统交叉熵损失$-\log p_y$仅最大化目标类别概率，易导致生成图像在决策边界附近徘徊。本文采用Li等人\cite{li2024diffmi}提出的top-k max-margin损失，该损失将传统max-margin损失\cite{carlini2017towards}中的"hard max"（仅考虑单个最大的非目标类别logit）替换为"top-k平均"（考虑前k个最大的非目标类别logit），更充分地利用软标签信息增强判别性。

设目标分类器输出logits为$\{\ell_1, \ldots, \ell_C\}$，目标类别为$y$，损失定义为：
\begin{equation}\label{eq:mia_topk_loss}
    \mathcal{L}_{\text{cls}} = -\ell_y + \frac{1}{k} \sum_{j \in \text{top-}k(J \setminus \{y\})} \ell_j,
\end{equation}
其中$J = \{1, \ldots, C\}$为所有类别集合，$\text{top-}k(J \setminus \{y\})$选取除目标类别外logit最高的$k$个类别，$k$根据数据集类别数设定（本文实验中CelebA设为5，CIFAR-10设为2）。该损失同时最小化目标类别logit$\ell_y$的负值（即最大化$\ell_y$）和最大化混淆类别logit的平均值，从而在高维空间中推动生成图像远离决策边界。

为进一步稳定优化过程，本文采用Nguyen等人\cite{nguyen2023rethinking}提出并由Li等人\cite{li2024diffmi}改进的p-reg损失，在特征空间对生成图像进行正则化约束。该损失通过最小化生成图像的特征表示与预计算的类别特征中心之间的距离，避免优化过程中的振荡。设$p_x = F_\theta^{\text{feat}}(\hat{x}) \in \mathbb{R}^{d_{\text{feat}}}$为分类器倒数第二层的特征表示，$c_y \in \mathbb{R}^{d_{\text{feat}}}$为目标类别$y$的特征中心。p-reg损失定义为：
\begin{equation}\label{eq:mia_preg_loss}
    \mathcal{L}_{\text{p-reg}} = \left\|p_x - c_y\right\|_2^2.
\end{equation}
特征中心$c_y$通过在公共数据集上使用目标分类器预先计算获得：对每个类别$y$，将其在公共数据集中所有样本的特征表示平均化，得到该类别的原型中心。这种预计算方式提供了稳定的正则化目标，使生成图像在特征空间向真实数据分布靠拢。

\subsection{身份一致性损失}

身份一致性损失确保生成图像的身份特征与标签条件嵌入$e_{\text{id}}$一致，建立类别标签与视觉身份特征的稳定映射关系。本文采用对比学习框架，利用人脸识别系统在单位超球面上的几何性质，显式增强目标身份与负样本身份的角度分离。

给定目标类别$y_{\text{target}}$，标签条件嵌入层生成身份嵌入$e_{\text{id}} = \mathcal{E}_\psi(y_{\text{target}})$，该嵌入代表希望生成图像具备的身份特征。同时，使用预训练的ArcFace编码器$E_{\text{id}}$提取生成图像$\hat{x}$的实际身份特征$e_{\text{gen}} = E_{\text{id}}(\hat{x})$。身份一致性损失通过对比学习确保$e_{\text{gen}}$接近目标身份嵌入$e_{\text{id}}$，同时远离其他类别的嵌入。$e_{\text{id}}$由MLP从类别标签直接生成，$E_{\text{id}}$仅用于评估生成图像的身份特征是否符合预期。

身份一致性损失采用对比学习形式：
\begin{equation}\label{eq:mia_identity_loss}
    \mathcal{L}_{\text{id}} = \mathbb{E}\left[\max\left(0, m + \frac{\langle E_{\text{id}}(\hat{x}), e_{\text{neg}} \rangle}{\|E_{\text{id}}(\hat{x})\|_2 \|e_{\text{neg}}\|_2} - \frac{\langle E_{\text{id}}(\hat{x}), e_{\text{id}} \rangle}{\|E_{\text{id}}(\hat{x})\|_2 \|e_{\text{id}}\|_2}\right)\right],
\end{equation}
其中$e_{\text{gen}} = E_{\text{id}}(\hat{x})$是预训练ArcFace编码器提取的生成图像的身份特征，$e_{\text{id}} = \mathcal{E}_\psi(y_{\text{target}})$是标签条件嵌入层生成的目标身份嵌入，$e_{\text{neg}} = \mathcal{E}_\psi(y_{\text{neg}})$是从内存库$\mathcal{M}$中采样的负样本类别嵌入（$y_{\text{neg}} \neq y_{\text{target}}$），$m$是角度裕度参数，控制正负样本间的最小角度间隔。

内存库$\mathcal{M}=\{e_1, e_2, \ldots, e_C\}$存储所有$C$个类别的嵌入向量快照，即$e_i = \mathcal{E}_\psi(i), \forall i \in \{1,\ldots,C\}$。训练时，当前目标类别$y_{\text{target}}$的嵌入$e_{\text{id}} = \mathcal{E}_\psi(y_{\text{target}})$通过前向传播实时计算并参与梯度更新，而负样本$e_{\text{neg}}$则从内存库中采样其他$C-1$个类别的嵌入（$y_{\text{neg}} \neq y_{\text{target}}$）。为平衡计算效率与嵌入一致性，内存库每一定步后更新一次，将所有类别的嵌入重新生成并存储，形成周期性快照机制。初始内存库在训练开始时由随机初始化的嵌入层构建，随训练进行逐步演化为超球面上分离良好的类别表示。

该损失通过hinge loss形式，仅在正样本相似度与负样本相似度之差小于裕度$m$时施加惩罚，驱动优化过程同时满足：（1）最大化$\cos(e_{\text{gen}}, e_{\text{id}})$，使生成图像的身份特征接近目标身份；（2）最小化$\cos(e_{\text{gen}}, e_{\text{neg}})$，使生成图像远离其他类别身份。该对比机制确保不同类别的身份嵌入在超球面上具有明确的角度分离，增加类间隔，防止类别间的身份混淆。内存库的作用包括：（1）提供负样本池，避免每步重复计算所有类别嵌入；（2）记录嵌入层的演化轨迹，辅助对比学习的稳定性；（3）确保全局类间分离的一致性。

\subsection{感知质量损失}

为确保生成图像的视觉真实性，本文采用LPIPS~\cite{zhang2018unreasonable}度量生成图像$\hat{x}$与源图像$x_{\text{src}}$的感知距离。LPIPS基于预训练深度网络提取多层特征进行比对，相比像素级损失能更好地保持视觉风格与结构，避免过拟合：
\begin{equation}\label{eq:mia_perception_combined}
    \mathcal{L}_{\text{perc}} = \mathcal{L}_{\text{LPIPS}}(\hat{x}, x_{\text{src}}).
\end{equation}

\subsection{正则化损失}
\label{subsec:mia_regularization}

正则化损失包括嵌入归一化约束和LoRA权重正则化，确保模型训练的稳定性与泛化能力：
\begin{equation}\label{eq:mia_reg_loss}
    \mathcal{L}_{\text{reg}} = \mathcal{L}_{\text{emb-norm}} + \lambda_{\text{lora}} \mathcal{L}_{\text{lora}} = \sum_{y=1}^C (\|e_{\text{id}}^{(y)}\|_2 - 1)^2 + \lambda_{\text{lora}} \sum_{\ell} (\|A_{\ell}\|_F^2 + \|B_{\ell}\|_F^2),
\end{equation}
其中嵌入归一化约束强制所有类别的嵌入向量位于单位超球面上，LoRA正则化防止权重过大导致的过拟合。

\section{训练与推理流程}
\label{sec:mia_training}

本节详细阐述基于换脸先验的模型反演攻击方法的训练与推理流程。首先介绍渐进式三阶段训练策略，通过图像条件预热、混合条件过渡和纯标签条件适配实现从图像条件到标签条件的平滑模态转换；随后描述整体架构的前向传播与反向传播流程，明确各模块的数据流向与梯度更新机制；最后给出完整的训练算法与推理策略，为方法的实现与复现提供系统化指导。

\subsection{渐进式训练策略}
\label{subsec:mia_progressive_training}

标签条件嵌入层替换原始身份编码器后，模型面临从图像条件生成到标签条件生成的模态转换挑战。直接使用随机初始化的标签嵌入会导致生成图像呈现随机噪声，训练极不稳定。借鉴课程学习与知识蒸馏中的教师退火思想，本文采用渐进式微调策略，通过三个阶段实现平滑的模态转换。

第一阶段为图像条件预热。该阶段利用公开人脸数据集（如CelebA、FFHQ）的真实图像，使用预训练ArcFace编码器从图像提取身份嵌入$e_{\text{id}} = E_{\text{id}}(x_{\text{real}})$。标签条件嵌入层$\mathcal{E}_\psi$在此阶段完全不参与训练，目的是让LoRA适配层专注学习如何利用外部提供的身份嵌入进行换脸，建立"身份嵌入向量→高质量换脸生成"的映射能力，而不是学习如何生成这些嵌入。这种解耦训练策略确保LoRA层能够接受任意符合ArcFace嵌入空间分布的向量，为后续标签嵌入的注入奠定基础。冻结换脸模型主干与扩散U-Net，仅训练LoRA参数$\{A_\ell, B_\ell\}$，损失函数为
\begin{equation}\label{eq:mia_stage0_loss}
    \mathcal{L}_{\text{stage0}} = \mathcal{L}_{\text{prior}} + \mathcal{L}_{\text{perc}}.
\end{equation}
该阶段聚焦于扩散先验保真度与感知质量，使LoRA适配层学习如何在保持生成质量的前提下利用外部身份嵌入进行换脸。训练持续至生成图像FID稳定在较低水平。

第二阶段为混合条件过渡。该阶段通过插值混合真实图像嵌入与标签嵌入，实现从图像条件到标签条件的平滑迁移。采用时间依赖的线性插值策略
\begin{equation}\label{eq:mia_hybrid_embedding}
    e_{\text{id}}(t) = (1-\lambda(t)) \cdot E_{\text{id}}(x_{\text{real}}) + \lambda(t) \cdot \mathcal{E}_\psi(y),
\end{equation}
其中$t$为当前训练步数，$\lambda(t)$为退火系数，控制标签嵌入的权重。采用余弦退火调度
\begin{equation}\label{eq:mia_annealing_schedule}
    \lambda(t) = \frac{1}{2}\left(1 - \cos\left(\frac{\pi \cdot \min(t, T_{\text{anneal}})}{T_{\text{anneal}}}\right)\right),
\end{equation}
其中$T_{\text{anneal}}$为退火周期。相比线性退火$\lambda(t)=t/T_{\text{anneal}}$，余弦调度在初期缓慢增长，中期快速过渡，后期平滑收敛，提供更稳定的过渡曲线。

该阶段解冻标签条件嵌入层$\mathcal{E}_\psi$，联合优化嵌入层与LoRA参数。为实现从图像条件到标签条件的平滑过渡，损失函数采用任务不确定性加权框架（式~\ref{eq:mia_total_loss}）统一管理所有损失项，同时通过退火系数$\lambda(t)$（式~\ref{eq:mia_annealing_schedule}）控制攻击相关损失的激活进度：
\begin{equation}\label{eq:mia_stage1_loss}
    \mathcal{L}_{\text{stage1}} = \sum_{i \in \{\text{prior, perc}\}} \left( \frac{1}{2\sigma_i^2} \mathcal{L}_i + \frac{1}{2}\log\sigma_i^2 \right) + \lambda(t) \sum_{j \in \{\text{cls, p-reg, id, reg}\}} \left( \frac{1}{2\sigma_j^2} \mathcal{L}_j + \frac{1}{2}\log\sigma_j^2 \right),
\end{equation}
其中前项为基础生成质量约束（先验保真度与感知质量），后项为攻击优化相关损失（分类器引导、特征正则化、身份一致性与嵌入正则化）。所有损失项权重通过不确定性参数$\{\sigma_i\}$自动平衡，退火系数$\lambda(t)$仅控制攻击损失的引入速度，不干扰各损失间的相对权重调整。

该设计遵循课程学习原理，通过退火系数实现训练目标的动态平衡：（1）初期$\lambda(t)\approx 0$时，攻击损失几乎不参与训练，不确定性框架专注于平衡$\mathcal{L}_{\text{prior}}$与$\mathcal{L}_{\text{perc}}$，模型利用真实图像嵌入学习高质量换脸生成；（2）中期$\lambda(t)\approx 0.5$时，攻击损失逐步激活，$\sigma_j$参数开始学习攻击损失与生成损失的相对权重，标签嵌入在分类器引导$\mathcal{L}_{\text{cls}}$、特征正则化$\mathcal{L}_{\text{p-reg}}$与身份一致性$\mathcal{L}_{\text{id}}$的共同作用下逐步接管身份控制；（3）后期$\lambda(t)\approx 1.0$时，攻击损失完全激活，不确定性框架在六个损失项间实现全局最优平衡，模型完全适配标签条件生成并优化分类器攻击效果。该策略确保生成质量约束始终存在，避免攻击优化破坏图像真实性，同时通过退火机制与不确定性加权的协同作用实现平滑的模态迁移与多目标优化的动态平衡。

当退火系数$\lambda(t)$达到1.0，分类器损失$\mathcal{L}_{\text{cls}}$与身份一致性损失$\mathcal{L}_{\text{id}}$完全激活，且生成图像在目标分类器上的置信度与FID指标同时稳定时，切换至下一阶段。

第三阶段为纯标签条件适配。该阶段完全移除真实图像依赖，进入最终的分类器攻击优化。完全使用标签条件嵌入层生成身份嵌入$e_{\text{id}} = \mathcal{E}_\psi(y)$，此时模型已学会从类别标签生成有效的身份嵌入。解冻U-Net注意力层与残差块卷积的LoRA参数，引入完整损失函数
\begin{equation}\label{eq:mia_stage2_loss}
    \mathcal{L}_{\text{stage2}} = \mathcal{L}_{\text{total}} = \sum_{i \in \{\text{prior, cls, p-reg, id, perc, reg}\}} \left( \frac{1}{2\sigma_i^2} \mathcal{L}_i + \frac{1}{2}\log\sigma_i^2 \right).
\end{equation}
该阶段同时优化攻击有效性与生成质量，各损失权重通过任务不确定性框架自动学习。其中$\mathcal{L}_{\text{cls}}$（top-k max-margin）与$\mathcal{L}_{\text{p-reg}}$（特征中心正则化）协同驱动分类器攻击，前者最大化目标类别置信度并远离决策边界，后者稳定优化轨迹并约束特征表示向类别原型靠拢。LoRA参数采用较小学习率以避免遗忘已学习的生成能力。训练持续至攻击成功率与生成质量同时达到预期目标。

\subsection{整体架构}

如图~\ref{fig:mia_architecture}所示，本章提出的模型反演攻击架构由三个核心模块组成：标签条件嵌入层$\mathcal{E}_\psi$、预训练换脸模型$G_\phi$与LoRA微调模块、目标分类器$F_\theta$。

\begin{figure}[htbp]
    \centering
    \includegraphics[width=0.9\textwidth]{images/train_mia.drawio.pdf}
    \caption{基于换脸先验的模型反演攻击架构。标签条件嵌入层将类别标签映射为身份嵌入，换脸模型通过参考注意力注入身份信息生成目标图像，目标分类器提供梯度用于端到端优化。}
    \label{fig:mia_architecture}
\end{figure}

给定目标类别标签$y_{\text{target}}\in\{1,2,\ldots,C\}$与随机采样的源图像$x_{\text{src}}$，系统首先通过标签条件嵌入层将类别标签的one-hot编码映射为512维身份嵌入向量$e_{\text{id}} = \mathcal{E}_{\psi}(y_{\text{target}})\in\mathbb{R}^{512}$，并进行$L_2$归一化使其位于单位超球面上。随后，VAE编码器将源图像压缩为潜在表示$z_0 = \text{VAE}_{\text{enc}}(x_{\text{src}}) \in \mathbb{R}^{4\times64\times64}$。在扩散去噪阶段，系统采样扩散时间步$t\sim\mathcal{U}(0,T)$并添加噪声$z_t = \sqrt{\bar{\alpha}_t}z_0 + \sqrt{1-\bar{\alpha}_t}\epsilon$（$\epsilon\sim\mathcal{N}(0,I)$），U-Net去噪网络结合身份嵌入$e_{\text{id}}$预测噪声$\hat{\epsilon} = \epsilon_\theta(z_t, t, e_{\text{id}})$，通过多步DDIM采样恢复干净潜在表示$\hat{z}_0$。最后，VAE解码器生成最终图像$\hat{x} = \text{VAE}_{\text{dec}}(\hat{z}_0)$，并输入目标分类器获得logits$\ell = F_\theta(\hat{x})\in\mathbb{R}^C$用于计算分类损失与身份损失。

训练过程中，多目标损失函数$\mathcal{L}_{\text{total}}$（式~\ref{eq:mia_total_loss}）对可训练参数进行端到端梯度反向传播，包括标签条件嵌入层$\psi$、LoRA适配矩阵$\{A_\ell, B_\ell\}$以及任务不确定性权重$\{\sigma_i\}$。本方法冻结换脸模型主干（VAE、U-Net主体）与目标分类器参数，仅更新LoRA增量与嵌入层，从而确保生成先验不被破坏。嵌入层采用较大学习率以快速学习类别映射，LoRA参数使用较小学习率以保持微调稳定性。

\subsection{训练流程}

算法~\ref{alg:mia_progressive}给出了渐进式三阶段训练的统一流程。该算法通过阶段标识$s\in\{0,1,2\}$区分不同训练阶段，各阶段在身份嵌入生成方式、损失函数组成及参数更新策略上存在差异，具体如下：阶段0使用真实图像嵌入预热LoRA，阶段1通过退火系数$\lambda(n)$混合真实与标签嵌入实现模态过渡，阶段2完全使用标签嵌入并激活完整损失函数进行分类器攻击优化。

\begin{algorithm}[htbp]
  \caption{渐进式三阶段MIA训练}
  \label{alg:mia_progressive}
  \begin{algorithmic}[1]
    \REQUIRE 数据集$\mathcal{D}_{\text{public}}, \mathcal{D}_{\text{target}}$，模型$G_\phi, E_{\text{id}}, F_\theta$
    \ENSURE 微调后的$\psi$与$\{A_\ell, B_\ell\}$
    \STATE 初始化$\{A_\ell, B_\ell\}, \psi$
    \FOR{阶段$s=0$ 到 $2$}
    \FOR{训练步数$n=1$ 到 $T_s$}
    \STATE 采样批数据$\{(x_{\text{real}}^{(i)}, y_i), x_{\text{src}}^{(i)}\}_{i=1}^B$
    \FOR{样本$i=1$ 到 $B$}
    \IF{$s=0$} 
    \STATE $e_{\text{id}}^{(i)} = E_{\text{id}}(x_{\text{real}}^{(i)})$
    \ELSIF{$s=1$} 
    \STATE $\lambda = \frac{1}{2}(1 - \cos(\frac{\pi n}{T_{\text{anneal}}}))$，$e_{\text{id}}^{(i)} = (1-\lambda) E_{\text{id}}(x_{\text{real}}^{(i)}) + \lambda \mathcal{E}_\psi(y_i)$
    \ELSE
    \STATE $e_{\text{id}}^{(i)} = \mathcal{E}_\psi(y_i)$
    \ENDIF
    \STATE 通过扩散模型生成$\hat{x}^{(i)} = G_\phi(x_{\text{src}}^{(i)}, e_{\text{id}}^{(i)})$
    \STATE 计算损失$\mathcal{L}_{\text{prior}}^{(i)}, \mathcal{L}_{\text{perc}}^{(i)}$，$s\geq1$时额外计算$\mathcal{L}_{\text{id}}^{(i)}, \mathcal{L}_{\text{cls}}^{(i)}$等
    \ENDFOR
    \IF{$s=0$} 
    \STATE $\mathcal{L} = \frac{1}{B}\sum_i [\mathcal{L}_{\text{prior}}^{(i)} + \mathcal{L}_{\text{perc}}^{(i)}]$
    \ELSE
    \STATE $\mathcal{L} = \sum_{j} (\frac{\bar{\mathcal{L}}_j}{2\sigma_j^2} + \frac{\log\sigma_j^2}{2})$（阶段1中攻击损失乘退火系数$\lambda$）
    \ENDIF
    \STATE 更新$\{A_\ell, B_\ell\}$（$s\geq1$时同步更新$\psi, \{\sigma_i\}$）
    \IF{$s=1$ 且 $n \bmod 100 = 0$}
    \STATE 更新$\mathcal{M}$
    \ENDIF
    \ENDFOR
    \ENDFOR
    \RETURN $\psi, \{A_\ell, B_\ell\}$
  \end{algorithmic}
\end{algorithm}

\subsection{推理策略}

训练完成后，模型可直接用于生成目标类别的攻击样本。推理阶段的核心目标是在保证分类器认同度的前提下，生成具备高感知质量和样本多样性的攻击图像集合。推理流程由身份嵌入生成、条件换脸生成与质量筛选三个步骤组成。

首先，给定目标类别标签$y_{\text{target}}\in\{1,2,\ldots,C\}$，通过训练好的标签条件嵌入层$\mathcal{E}_\psi$生成对应的身份嵌入向量：
\begin{equation}\label{eq:mia_inference_embedding}
    e_{\text{id}} = \mathcal{E}_\psi(y_{\text{target}}) \in \mathbb{R}^{512}.
\end{equation}
该嵌入向量经过三阶段渐进式训练后，已建立类别标签与身份特征空间的稳定映射。归一化后的嵌入$e_{\text{id}}/\|e_{\text{id}}\|_2$位于ArcFace编码器学习的单位超球面上，确保与换脸模型的身份控制接口兼容。

其次，为生成具有多样性的攻击样本，需从公开人脸数据集中采样多个源图像作为属性提供者。对于每个源图像$x_{\text{src}}^{(j)}$，结合身份嵌入$e_{\text{id}}$通过微调后的换脸模型生成攻击样本：
\begin{equation}\label{eq:mia_inference_generation}
    \hat{x}^{(j)} = G_{\phi+\Delta}(x_{\text{src}}^{(j)}, e_{\text{id}}),
\end{equation}
其中$G_{\phi+\Delta}$表示融合LoRA增量$\Delta=\{A_\ell, B_\ell\}$后的换脸模型，$\phi$为冻结的预训练主干参数。生成过程遵循扩散模型的标准采样流程：VAE编码器将源图像编码为潜在表示$z_0 = \text{VAE}_{\text{enc}}(x_{\text{src}}^{(j)})$，随后通过DDIM多步去噪采样生成目标潜在表示$\hat{z}_0$，最后VAE解码器输出生成图像$\hat{x}^{(j)} = \text{VAE}_{\text{dec}}(\hat{z}_0)$。身份嵌入$e_{\text{id}}$通过参考注意力机制注入U-Net去噪网络的每个时间步，实现身份控制。

源图像集合$\{x_{\text{src}}^{(j)}\}_{j=1}^{N_{\text{src}}}$的选择对攻击效果有重要影响。本方法采用多样性驱动的采样策略，从公开数据集中采样若干源图像，确保覆盖不同姿态、表情、年龄、光照等属性维度。可通过预训练的属性估计器评估候选集的属性方差，选择方差较大的子集以最大化生成样本的多样性。该策略继承换脸模型的核心优势，即身份与属性解耦，使生成图像在保持目标身份的同时，从源图像继承丰富的外观属性。

最后，生成若干候选攻击样本后，通过目标分类器$F_\theta$进行质量评估与筛选。对每个生成图像$\hat{x}^{(j)}$，计算其在目标类别的置信度得分：
\begin{equation}\label{eq:mia_inference_confidence}
    s^{(j)} = F_\theta(\hat{x}^{(j)})_{y_{\text{target}}} = \text{Softmax}(F_\theta(\hat{x}^{(j)}))_{y_{\text{target}}}.
\end{equation}
选择置信度最高的若干样本作为最终输出。该筛选机制确保输出样本同时满足高分类器认同度与多样性要求：置信度排序保证攻击有效性，而源图像的多样性采样保证样本在属性空间的广泛分布。

为消除LoRA适配层的推理开销，训练完成后可将LoRA权重合并到预训练模型的基础参数中。对于参考注意力层、U-Net注意力层与残差卷积层，权重合并遵循统一公式：
\begin{equation}\label{eq:mia_inference_merge}
    W_{\text{merged}} = W_{\text{frozen}} + \frac{\alpha}{r} B A,
\end{equation}
其中$W_{\text{frozen}}$为冻结的预训练权重，$A, B$为训练得到的LoRA矩阵，$\alpha$为缩放因子，$r$为LoRA秩。合并后模型结构与原始换脸模型完全一致，可作为独立的攻击工具部署，无需额外适配层或动态参数注入。

\section{本章小结}
\label{sec:mia_summary}

本章提出基于换脸先验与标签条件嵌入的模型反演攻击方法，利用预训练换脸模型的身份属性解耦机制，通过标签条件嵌入层、低秩适应微调、渐进式训练策略与多目标优化框架，实现从类别标签到高保真攻击样本的生成。

标签条件嵌入层建立离散标签与连续身份嵌入空间的映射。低秩适应微调通过在关键层引入可训练增量，以较小参数开销适配新的嵌入分布。渐进式训练通过图像条件预热、混合条件过渡与纯标签条件适配三个阶段，结合余弦退火调度，确保训练稳定性。多目标优化框架采用任务不确定性加权机制，在先验保真度、攻击有效性、身份一致性与感知质量之间实现动态平衡。推理阶段通过源图像采样与样本筛选策略生成多样化攻击结果。

本章提出的方法为深度学习模型的隐私风险评估提供了新的技术路径，特别是在生物特征识别系统的安全性分析中具有重要应用价值。该方法揭示了预训练生成模型可能被恶意利用进行隐私攻击的潜在风险，为模型训练者与部署者提供了重要的安全警示。同时，本章建立的理论框架与技术方法为后续研究提供了系统化的参考，包括防御机制设计、攻击检测算法开发等相关工作均可基于本章方法展开深入研究。
% Local Variables:
% TeX-master: "../main"
% TeX-engine: xetex
% End:
