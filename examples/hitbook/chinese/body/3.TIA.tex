% !Mode:: "TeX:UTF-8"

% TODO (写作提示):
% - 在方法开头形式化输入/输出：明确 $x$ (图像) 的尺寸、特征模板 $t$ 的维度、y 的含义等。
% - 在训练/推理小节后增加超参数表（batch size、lr、迭代次数、lambda 调度、随机种子）。
% - 在推理流程图下方给出示例推理命令（便于复现），例如：\texttt{python infer.py --ckpt model.pt --template tpl.npy --steps 18}
% - 若有关键实现文件或脚本，补充路径或仓库链接。

\chapter[面向人脸特征提取模型的逆向重建方法]{面向人脸特征提取模型的逆向重建方法}[Reconstruction Method for Face Feature Extraction Models]
\section{引言}
% 原占位（空）已被扩写，原文保留为注释。
本章聚焦于针对人脸识别系统中基于模板（embedding/template）匹配机制的逆向重建问题。我们以实际系统中常见的“模板—比对”验证流程为背景，系统化地研究如何在不同攻击假设下利用生成模型（尤其是隐空间扩散模型）将被泄露或可获的模板信息映射回可感知的图像样本。章节目标包括：

- 明确模板逆向问题的形式化定义与攻击假设（白盒/黑盒/中度可见情形）；
- 提出并实现一种基于隐空间扩散（LDM/EDM）并结合嵌入一致性引导的重建框架；
- 设计一套可复现的训练与推理流程（含超参数、微调策略与采样配置），用于评估重建的识别一致性与视觉质量；
- 通过大规模对比实验揭示不同引导策略、噪声调度与微调规模对重建成功率与资源消耗之间的权衡。

本章工作的技术路线基于两条核心观察：一是现代扩散生成器在隐空间（latent）上进行条件化可在保持采样效率的同时取得高质量输出；二是识别模型的嵌入空间提供了直接、可微的相似度信号，该信号既可用于微调阶段的嵌入一致性损失，也可在采样阶段作为分数/分类器引导注入，从而将目标模板的约束显式融入生成过程。基于此，我们在后续小节中逐步给出问题的形式化、方法细节、训练与推理流程以及工程化复现提示（包括示例命令与超参数表），以便实现可复现且可比较的实验评估。

\section{攻击任务与假设}

令原始图像空间为 $\mathcal{X}$（例如 $H\times W\times C$ 的像素域），识别器为映射 $F:\mathcal{X}\to\mathbb{R}^d$，其中 $d$ 为嵌入维度。记目标模板为 $t\in\mathbb{R}^d$，它可为单一浮点向量，也可附带元信息（量化位宽、归一化方式或置信度分数）。攻击者的目标是构造一个攻击算法 $\mathcal{A}$，根据可用信息生成一组候选图像或单个重构图像 $\hat{x}=\mathcal{A}(\mathcal{I})$，使得重建图像在识别器空间与目标模板相吻合：
\begin{equation}\label{eq:attack_goal}
  	ext{maximize}\quad \mathrm{sim}(F(\hat{x}), t),
\end{equation}
其中 $\mathrm{sim}(\cdot,\cdot)$ 可取余弦相似度或负欧氏距离。我们称攻击成功当
\begin{equation}\label{eq:success}
  \mathrm{sim}(F(\hat{x}), t) \ge \tau,
\end{equation}
其中阈值 $\tau$ 可由目标系统的验证策略（例如在给定假接受率 FAR 下的 TAR）确定。

此外，可定义识别级别的成功（identification success）：在给定候选库（gallery）$\mathcal{G}$ 中，若 $\hat{x}$ 与同一身份的真实样本在检索/比对中排名靠前（例如 top-1 命中），则视为识别成功。相应指标可写为
\begin{equation}
  \mathrm{ID\_succ}(\hat{x}, t;\mathcal{G}) = \mathbb{I}\left[\operatorname{rank}_{g\in\mathcal{G}}\big(\mathrm{sim}(F(\hat{x}), F(g))\big) = 1\right].
\end{equation}

\subsection*{输入/输出与前置假设}
- 输入：目标模板 $t\in\mathbb{R}^d$。可选的伴随信息 $\mathcal{I}$ 包括：预处理流水线描述 $\mathcal{P}$（对齐/裁剪/归一化）、量化信息、置信度或打分 $s$，以及（若存在）小量真实图像样本 $\{x_i\}$ 用于微调/校准。图像尺寸与像素范围应在实验协议中明确（例如 $H{=}224,W{=}224$，像素归一化到 $[-1,1]$）。
- 输出：若干候选重构图像集合 $\{\hat{x}_k\}_{k=1}^K$ 或单一最佳重构 $\hat{x}$，并报告对应的识别器相似度分数与感知质量度量（LPIPS/FID 等）。

前置假设（威胁模型的维度）：
- 白盒（Full white-box）：攻击者能访问识别器 $F$ 的结构与权重，能计算或回传梯度 $\nabla_x\mathrm{sim}(F(x),t)$；在此情形下，可直接利用梯度信息进行采样引导或优化式反演。\
- 黑盒-可查询嵌入（Embedding-query black-box）：攻击者不能访问 $F$ 的内部，但可以发送任意输入并获得嵌入向量 $F(x)$；该模型允许通过迭代查询估计梯度或构建代理模型。\
- 黑盒-仅打分/相似度（Score-only black-box）：攻击者只能获取相似度分数或阈内/阈外的二元判定（例如认证通过/失败），查询预算有限。\
- 无访问-仅预训练生成器（No-access generative prior）：攻击者无法查询识别器或模板，但可以使用在相似域上训练好的生成先验（预训练的 EDM/LDM）；此类攻击依赖于将 generative prior 与目标模板信息（若可用）结合的策略，例如通过微调 LoRA 或优化生成器潜变量。\

此外，攻击者可能受限于查询预算 $Q$（允许的最大查询次数），存储/计算资源 $R$（GPU 数量与显存），以及可用的外部数据集 $\mathcal{D}_{aux}$（用于微调或训练代理模型）。这些约束应在实验中明确并作为可比性条件。

\subsection*{评估协议与指标}
为公平比较不同攻击策略与防御方法，本研究采用如下统一评估协议：

- 相似度度量：报告重建样本与目标模板的平均余弦相似度 $\mathbb{E}_t[\mathrm{cos}(F(\hat{x}),t)]$ 及其分位数分布；同时展示成功率曲线在不同阈值 $\tau$ 下的变化（等价于 ROC/TAR 曲线的局部视图）。
- 验证成功率：在指定 FAR（例如 1e-3, 1e-4）下报告 TAR；若攻击者目标为冒名顶替，应报告在给定阈值下的接受率。\
- 识别/检索指标：在给定 gallery 下计算 top-k 命中率（特别是 top-1）。\
- 感知质量：使用 FID、LPIPS、SSIM 等衡量重建图像的视觉质量与多样性，避免仅凭相似度指标误导结论。\
- 计算/查询成本：报告每次生成的平均采样步数、单次生成的平均 GPU 时间，以及攻击所需的查询预算 $Q$ 与微调参数量（例如 LoRA 的参数数目）。

在实验报告中，应同时给出成功/失败样本的可视化，以及对失败模式（例如姿态、遮挡或数据偏差）进行定性分析以增强结论的可解释性。

% 原占位（若存在）保留为注释以便回溯

\section{攻击目标}

基于模板(Template)匹配的识别模型, 主要应用于人脸识别、指纹识别等生物特征识别系统。此类模型用户的原始数据如人脸图像 $x$ , 经过特征提取网络 $F(\cdot)$ 得到特征模板 $t = F(x)$, 并存储于数据库, 这里的 $t$ 称为模板信息。在需要进行身份验证时, 用户给出新的输入图像 $x'$ ; 识别系统会比对此次输入的图像与数据库中的特征模板的匹配程度, 从而判断用户身份。以常见的余弦相似度为例, 模板匹配的判定准则为:
\[
  d(F(x'), t) = \frac{F(x') \cdot t}{\| F(x') \|_2 \| t \|_2}
\]
若 $d(F(x'), t) > \tau$, 则判定 $x'$ 与模板 $t$ 属于同一身份, 其中 $\tau$ 为系统设定的阈值。

虽然这种方法在实际应用中具有较高的准确率和效率, 但也存在隐私泄露的风险。具体来说, 由于模板存储在特征数据库中, 假设攻击者获得了特征数据库的访问权限, 窃取到特征模板信息, 则攻击者可以通过模板信息反向生成出接近用户的图像信息, 从而误导识别模型的识别结果。针对这类模型的攻击方法称为模板逆向攻击(Template Inversion Attack, TIA)。模板逆向攻击的核心在于利用特征模板 $t$ 来重建与之匹配的原始输入图像 $x'$ 。攻击者可以通过优化算法或生成模型来实现这一目标。此类攻击寻找一个输入 $x^*$, 使得其特征 $F(x^*)$ 与模板 $t$ 的相似度最大化, 可通过如下优化目标来描述:
$$x^* = \arg\min_{x'}Sim(F(x'), t)$$
其中$Sim(\cdot)$表示衡量特征与模板之间相似程度的函数。
\section{结合生成式模型的重建方法}
\section{损失函数设计}


针对基于模板匹配模型的隐私泄露问题, 设计了如图\ref{fig:edm_tia_train}所示的利用EDM扩散模型进行模板逆向攻击的训练流程。其中扩散模型的核心部分采用了EDM扩散模型, 利用其生成能力和噪声调度机制, 实现高效的模板逆向攻击算法。通过对扩散模型的训练和优化, 模型可以重建与目标模板匹配的原始输入图像, 从而实现对用户隐私信息的还原。本课题在损失函数设计上, 结合了特征提取网络与扩散生成模型, 使得攻击流程能够同时优化生成图像的像素质量以及其与目标模板的特征相似度。

本节详细介绍将隐空间扩散模型（LDM/EDM）用于模板逆向重建的具体架构与训练/微调流程。本方法遵循“先有强生成先验，再做目标化微调”的范式，以兼顾视觉质量与识别一致性。
本研究采用隐空间扩散（LDM）框架作为基线，并在其 U-Net 去噪器上实现条件化。总体架构包括：

\begin{itemize}
  \item 能量式引导/分数注入：不在网络结构中直接条件化，而是在采样时用识别器的相似度梯度修正去噪器输出（参见第2章理论推导），适用于白盒或嵌入可查询的设置。
\end{itemize}
\subsection{训练与两阶段流程}
为兼顾通用生成能力与目标适配能力，我们采用两阶段训练流程：

\paragraph{基础生成器训练 / 采用预训练权重}
使用大规模人脸数据集（或通用人像数据集）在隐空间上训练 EDM/LDM，目标为还原像素或隐空间重建误差（EDM 损失）。若可利用高质量开源预训练权重（例如公开的 LDM/EDM 模型），建议直接加载并冻结大部分参数，仅用于作为生成先验。

\paragraph{目标化微调（微适配）}
在每个目标模板或目标集合上进行参数高效微调：仅微调 Cross-Attention 投影层或使用 LoRA 在 U-Net 的关键线性/注意力矩阵上注入低秩增量。微调目标函数包含生成器的像素/隐空间重建损失与识别器嵌入一致性损失的组合：
\begin{equation}\label{eq:finetune_loss}
\mathcal{L}_{\text{finetune}} = \mathcal{L}_{\text{EDM}} + \lambda_{id}(t)\,\mathcal{L}_{id} + \lambda_{perc}\,\mathcal{L}_{perc} + \lambda_{adv}\,\mathcal{L}_{adv} + \lambda_{reg}\,\mathcal{L}_{reg}.
\end{equation}
微调阶段的实现细节：
\begin{itemize}
  \item 冻结大部分网络，仅训练 LoRA 模块或 attention 投影（减少显存与计算）；
  \item 使用较小学习率与较短训练步数（例如数百到上千步），并以识别器在验证集上的相似度作为早停准则；
  \item 可在微调时采用数据增强（轻微姿态/光照扰动）以提升鲁棒性，但应避免破坏身份特征。
\end{itemize}

\section{损失函数设计与采样引导策略}

本节在第2章理论推导的基础上，系统化描述训练阶段与采样阶段使用的损失项、权重调度与引导策略，以便实现既有高视觉质量又能在识别器空间中匹配目标模板的重建。

\subsection{总目标与损失项分解}
训练时的总损失通常采用多项式组合：像素/隐空间重建（EDM 基线）、识别器嵌入一致性、感知损失与可选的对抗/正则化项：
\begin{equation}\label{eq:total_loss}
  \mathcal{L}_{\text{total}} = \mathcal{L}_{\text{EDM}} + \lambda_{id}(t)\,\mathcal{L}_{id} + \lambda_{perc}\,\mathcal{L}_{perc} + \lambda_{adv}\,\mathcal{L}_{adv} + \lambda_{reg}\,\mathcal{L}_{reg}.
\end{equation}

说明各项：
- EDM 基线（去噪/重建）损失：采用明晰扩散（EDM）定义的加权均方误差：
\begin{equation}\label{eq:edm_loss}
  \mathcal{L}_{\text{EDM}} = \mathbb{E}_{x_0,\sigma,\epsilon}\left[ w(\sigma) \left\| f_\theta(x_0 + \sigma\epsilon,\sigma) - x_0 \right\|_2^2 \right].
\end{equation}
其中 $w(\sigma)$ 为噪声权重函数（遵循 EDM/文献建议以平衡不同噪声尺度的训练信号）\cite{karras2022elucidating}。

- 嵌入一致性损失（识别器约束）：用于保证生成图像在识别器嵌入空间与目标模板 $t$ 接近。可选择均方误差或余弦相似度损失：
\begin{align}
  &\mathcal{L}_{id}^{\mathrm{MSE}} = \| F(D(z_0)) - t \|_2^2, \\
  &\mathcal{L}_{id}^{\mathrm{cos}} = 1 - \frac{F(D(z_0))\cdot t}{\|F(D(z_0))\|_2\,\|t\|_2}.
\end{align}
在实践中我们常用 $\mathcal{L}_{id}^{\mathrm{MSE}}$ 作简单可微目标，或混合使用余弦目标以直接最大化相似度。

- 感知损失 $\mathcal{L}_{perc}$：使用 VGG 感知特征的 L2 距离（或 LPIPS）以改善视觉细节与纹理一致性。\
- 对抗损失 $\mathcal{L}_{adv}$（可选）：若需提升真实感，可在微调阶段加入小规模 Patch-GAN 判别器，注意该项易影响识别一致性且可能带来不稳定性。\
- 正则化项 $\mathcal{L}_{reg}$：包括 TV 损失、参数范数惩罚或 LoRA 参数的范数约束，防止过拟合与生成伪影。

超参数调度：特别说明 $\lambda_{id}(t)$ 可采用时间/阶段依赖调度（见下）。常用做法是训练初期以较小 $\lambda_{id}$ 保障视觉学习，随后逐步增大以提升识别一致性。

\subsection{识别一致性权重调度（示例）}
为避免在微调初期破坏生成器的视觉质量，推荐采用分段或余弦退火式的 $\lambda_{id}$ 调度：
\begin{equation}
  \lambda_{id}(e) = \lambda_{id}^{\max} \cdot S(e; e_{warm}, e_{ramp}),
\end{equation}
其中 $e$ 为当前微调 epoch/step，$S(\cdot)$ 为平滑上升函数（线性或余弦），$e_{warm}$ 为预热期长度，$e_{ramp}$ 为达到最大值的步数。经验值：$\lambda_{id}^{\max}=0.5\sim2.0$，$e_{warm}$ 为前 50--200 步。

\subsection{采样阶段的引导（Guidance）}
训练后在采样阶段可采用若干引导策略以增强重构与模板的契合度：

1) Classifier-free guidance（CFG）：训练时部分样本屏蔽条件以学得无条件与有条件去噪器。采样时常用公式：
\[
  \epsilon_{\text{guid}} = \epsilon_{\text{uncond}} + s\cdot(\epsilon_{\text{cond}} - \epsilon_{\text{uncond}}),
\]
其中 $s$ 为 guidance scale，通常取值在 $1.0\sim10.0$。对嵌入条件的 CFG 能有效提升条件遵从性且实现简单。

2) Classifier / energy guidance：若能计算 $\nabla_x \log p(t|x)$（白盒或可查询情形），则可在采样步加入该梯度：
\[
  \nabla_x \log p(x|t) \approx \nabla_x \log p(x) + \gamma\,\nabla_x \log p(t|x),
\]
其中 $\nabla_x \log p(t|x)$ 可由识别器相似度 / 负损失 $-\nabla_x \mathcal{L}_{id}$ 估计（注意符号）。在离散采样更新中对 $x$ 加入该项等价于对噪声预测 $\epsilon_\theta$ 做修正（参见第2章公式推导）。常用做法是将该梯度正则化并按步长缩放以保证数值稳定性。

3) Gradient-projection / iterative refinement：在每一步去噪后，可对当前样本 $x_t$ 做 $k$ 次小步长梯度下降以减小识别一致性损失：
\[
  x \leftarrow x - \eta \frac{\nabla_x \mathcal{L}_{id}(x)}{\|\nabla_x \mathcal{L}_{id}(x)\| + \epsilon},
\]
其中 $\eta$ 为小步长（如 $1\times10^{-2}$），归一化能避免过大扰动。通常 $k=1\sim3$，以平衡计算开销。

综合策略：对多数场景，采用 CFG 作为主导（低成本且稳定），并在白盒或可查询情形下结合轻量的能量/投影步以进一步提高识别一致性。

\section{算法概览与完整伪代码}
为便于实现与复现，本小节给出端到端的算法概览（训练 + 微调 + 推理），并以伪代码方式列出关键步骤。原文中关于各个损失项、调度与采样的理论推导保留，下面的伪代码用于桥接理论与工程实现。

\subsection*{整体流程（概览）}
步骤概述：
\begin{enumerate}
  \item 准备：准备人脸数据集、预训练 EDM/LDM 检查点、目标模板并统一预处理流水线（对齐/裁剪/归一化）。
  \item 基础训练（可选）：在大规模人像数据上训练或微调 EDM 生成器以获得高质量生成先验（可使用开源权重跳过）。
  \item 目标化微调（LoRA / attention head / small head）：针对目标模板集合进行参数高效微调，优化式参照式~\eqref{eq:finetune_loss}。保存 LoRA 权重与训练元信息。
  \item 推理/采样：使用 CFG 为主的采样器进行隐空间或像素域采样；在白盒或可查询情形可辅以投影步或能量引导以进一步提升识别一致性。
  \item 评估与记录：计算 TAR@FAR、top-k、FID、LPIPS，并记录采样步数、平均时延、查询预算消耗与 LoRA 参数量。
\end{enumerate}

\subsection*{伪代码：训练 + 微调 + 推理}
\begin{verbatim}
# ====== 基础训练（可跳过，加载预训练模型） ======
train_edm(base_cfg):
    model = EDM(cfg=base_cfg)
    for epoch in range(E):
        for batch in dataloader:
            loss = edm_loss(batch)
            loss.backward(); optim.step()
    save_checkpoint(model)

# ====== LoRA 微调（目标化） ======
finetune_lora(ckpt, templates):
    model = load_edm(ckpt); freeze(model.parameters())
    lora = attach_lora_modules(model, r=R, alpha=A)
    for step in range(N_steps):
        x_batch, t_batch = sample_mini_batch(templates)
        # 构造带噪样本并计算 EDM 损失
        loss_edm = edm_loss_on_batch(model, x_batch)
        # 解码并计算识别器嵌入损失
        x_hat = decode_latent(model, z_sample)
        loss_id = id_loss(F(x_hat), t_batch)
        loss = loss_edm + lambda_id(step) * loss_id + other_terms
        loss.backward(); optim.step()
    save_lora_weights(lora, meta_info)

# ====== 推理（采样 + 可选投影） ======
infer(template, ckpt_or_lora):
    model = load_model(ckpt_or_lora)
    z_T = sample_noise()
    for i in schedule:
        eps_uncond = denoiser(z_i, cond=None)
        eps_cond   = denoiser(z_i, cond=template)
        eps = eps_uncond + s*(eps_cond - eps_uncond)
        z_{i-1} = sampler_step(z_i, eps)
        if proj_enabled:
            x = decode(z_{i-1})
            g = grad_x id_loss(F(x), template)
            x = x - eta * normalize(g)
            z_{i-1} = encode(x)
    return decode(z_0)
\end{verbatim}

% 注意：上面伪代码为高层次说明，具体实现参见项目脚本与配置文件。


\section{本章小结}
本章给出了面向人脸模板逆向重建的完整方法框架：从问题形式化、损失设计到 LoRA 微调与采样引导策略，再到工程化配方与复现实验建议均有覆盖。核心原则是“先构建高质量生成先验，再做目标化微调/引导”，以在可控资源下取得识别一致性与视觉质量的平衡。后续第4章与第5章将基于本章给出的协议完成具体实验、对比分析与报告。
