% !Mode:: "TeX:UTF-8"

% TODO (写作提示):
% - 本章较长，建议加入一个“符号说明”小节，列出常用符号 (例如 $x_t, \alpha_t, \epsilon_\theta, \sigma$) 与含义，便于读者快速查阅。
% - 在章节末尾注明实现细节：使用的框架（PyTorch/TensorFlow）、关键库版本、参考实现链接（若有）。
% - 若有较长证明，考虑把完整证明移到附录并在正文给出结论要点。

\chapter[理论基础]{理论基础}[Theoretical Foundation]
\section[引言]{引言}
本章旨在为后续方法设计与实验评估奠定理论基础。首先对本文所涉及的问题与符号进行形式化说明，然后回顾支持本研究的若干核心技术：人脸识别中的特征表示与验证指标、生成模型家族（包括显式似然模型、生成对抗网络与扩散模型及其隐空间变体）、以及参数高效微调方法（如 LoRA）与判别/分数引导的理论依据。通过对这些基础理论的系统梳理，读者将能理解第3章与第4章所提出方法的建模取向、损失设计与采样引导策略的理论来源。

在形式化层面，我们采用以下基本约定：原始图像记为 $x\in\mathcal{X}$，其经目标识别模型$f(\cdot)$ 提取得到的特征（模板或嵌入）记为 $y=f(x)\in\mathbb{R}^d$；生成器或扩散模型以参数化映射 $g_\theta(z)$ 或去噪器 $\epsilon_\theta(\cdot,t)$ 表示，其中 $z$ 为隐空间随机变量，$t$ 表示扩散/噪声等级。后续章节中若出现常用符号（例如 $x_t,\alpha_t,\epsilon_\theta,\sigma$ 等），将统一在本章“符号说明”小节列出以便查阅。

此外，本章亦简要讨论基于得分函数的条件化生成原理（score-based guidance）与分类器/分数引导对扩散采样路径的影响机理，这些理论结果直接支撑第3章提出的嵌入一致性损失与采样修正项的推导（参见文献 \\cite{hoDenoisingDiffusionProbabilistic2020,songScoreBasedGenerativeModeling2021,rombachHighResolutionImageSynthesis2022}）。最后，我们将对工程实现细节（推荐的深度学习框架、关键库与版本）在本章末尾做说明，并提示将技术证明或较长推导置于附录以保持正文的流畅性。

% === 被替换/新增内容的记录（原文若存在则保留为注释） ===
% 此处原先为空白“引言”章节，现添加引导性说明、符号约定与章节导读，便于后续理论与方法的连贯表述。

\section[人脸识别模型理论基础]{人脸识别模型理论基础}
% 原占位："人脸识别模型理论基础"
本节系统回顾用于人脸识别与验证的模型设计要点、典型的损失函数与嵌入规范化技术，以及用于衡量识别性能与模板相似性的常用指标。目的是为第3章和第4章中针对特征模板的逆向重建与模型反演方法提供必要的理论背景。

1) 模型架构与特征表示。现代人脸识别系统通常以卷积神经网络（CNN）或其变体（例如 ResNet 系列）作为骨干网络，用于将输入图像映射到紧凑的特征向量空间；代表性工作包括 FaceNet\cite{schroff2015facenet}、SphereFace\cite{liu2017sphereface}、CosFace\cite{wang2018cosface} 与 ArcFace\cite{deng2019arcface}。这些方法在网络架构之外的关键贡献集中在损失函数与采样策略上，以提升嵌入的可区分性与跨域、跨姿态的鲁棒性。

2) 判别性损失与边际约束。基于度量学习的损失（如三元组损失）和基于分类器的角度/余弦边际损失（SphereFace 的角度间隔、CosFace 的加性余弦边际、ArcFace 的加性角度边际）通过在训练阶段人为扩大类间距或收缩类内散度来提高识别器的判别性。这类损失直接影响嵌入空间的几何结构，从而决定了模板间相似度在验证任务中的可用性\cite{schroff2015facenet,liu2017sphereface,wang2018cosface,deng2019arcface}。

3) 嵌入规范化与距离度量。为便于比对，实践中常对嵌入向量进行 L2 归一化，并使用余弦相似度或欧氏距离作为比对度量。归一化后的嵌入使得阈值在不同模型/数据下更具可迁移性，并简化了基于阈值的验证协议（例如在给定假接受率 FAR 下报告真实接受率 TAR）\cite{schroff2015facenet}。

4) 模板格式与信息内容。所谓“模板”可指模型最后一层的浮点向量、量化后的离散表示或带噪声/扰动的变换表示。模板的维度、量化水平与是否存储置信度/打分信息都会显著影响逆向重建难度和隐私风险；例如，公开或被泄露的原始浮点嵌入比量化或签名化模板更容易被重建\cite{fredrikson2015model}。

5) 评估指标与协议。针对验证/识别任务，常用的评估指标包括 TAR@FAR（在给定假接受率下的真正接受率）、ROC 曲线、CMC 排名指标；而在模板逆向/重建研究中，则通常同时报告嵌入相似度（余弦/欧氏）、识别/验证成功率与感知质量指标（例如 FID、LPIPS）以衡量重建图像既保持视觉真实性又能在识别层面通过匹配\cite{9393327}。

6) 训练数据与泛化问题。人脸识别模型的鲁棒性在很大程度上依赖于训练数据的多样性（种族、年龄、光照、姿态等）。低样本或数据偏倚会导致嵌入在某些群体上表现较差，也会影响基于嵌入的逆向攻击的成功率与泛化性。本研究在实验设计时将显式考虑数据集的多样性与潜在偏倚问题，并在结果分析中讨论其对攻击/防御结论的影响。

7) 隐私与安全考量。识别系统的模板作为长期存储的中间表示，其可比对性使得一旦泄露便可能被用于重建原始脸部图像或进行身份滥用。已有工作表明，仅凭模型输出来反推训练样本或输入（模型反演、成员推断）存在现实风险\cite{fredrikson2015model}。因此在后续章节中，我们将把模板格式、输出信息（是否包含相似度分数或置信度）作为不同攻击假设的维度，系统评估重建方法在白盒/黑盒/嵌入可见等场景下的表现。

本节对主流人脸识别模型的关键组成、损失设计与评估协议作了概述，为第3章和第4章的算法设计与实验协议选择提供依据。

% === 原占位（保留为注释以便回溯） ===
% 人脸识别模型理论基础
\section[扩散生成模型技术基础]{扩散生成模型技术基础}
% 扩展说明：在此小节先给出扩散模型家族的系统性技术要点与工程考虑，然后保留下文的形式化推导与公式，便于读者由理论到实践的理解。
扩散生成模型已成为近年生成建模的主流范式之一，其核心在于将生成问题转化为一个由无噪声样本向高斯噪声分布的正向扩散过程及其对应的反向去噪过程的建模任务。针对本课题（基于嵌入/模板的逆向重建），以下技术要点尤为重要：

- 像素空间与隐空间（latent）扩散：像素空间扩散直接在图像像素上建模，通常能获得更直接的视觉质量但计算代价大；隐空间扩散（LDM）先通过编码器将图像映射到低维隐表征，在隐空间上执行扩散与去噪，再解码回像素域，显著降低计算与存储开销且便于条件化控制\\cite{rombachHighResolutionImageSynthesis2022}。

- 得分函数与条件化原理（score-based view）：扩散模型可以等价地看作对不同噪声等级下数据分布得分函数的估计。通过贝叶斯分解，条件分布的得分可由无条件得分与条件项之和表示，这为将外部信息（如识别器输出或嵌入相似度）作为引导项直接加入采样过程提供了理论基础\\cite{songScoreBasedGenerativeModeling2021,hoDenoisingDiffusionProbabilistic2020}。

- 引导策略：常用引导包括（1）分类器引导（classifier guidance）：通过训练额外的噪声条件分类器估计 \nabla_x \log p(y|x) 并在采样时叠加该梯度；（2）classifier-free guidance：在同一扩散模型中通过随机屏蔽条件实现无监督的条件强化，具有实现简单且效果稳定的优点；（3）基于能量或判别器的引导：将识别器的相似度或代价函数作为能量项融入采样。针对模板逆向任务，识别模型的嵌入相似度可直接构造成条件梯度或损失用于引导采样/微调\\cite{hoDenoisingDiffusionProbabilistic2020}。

- 采样效率与加速器：传统 DDPM/score-based 采样需要大量步数（数百至上千步），不利于工程化部署。DDIM、EDM 与分数匹配下的二阶采样器等提出了步数减少与采样稳定性的改进，适合在需要较低延迟或多次查询的逆向攻击场景采用\\cite{songGenerativeModelingEstimating2019,rombachHighResolutionImageSynthesis2022}。

- 噪声调度与权衡：噪声调度（noise schedule）与权重函数 $w(\sigma)$ 对生成质量与可控性有显著影响。EDM 等工作对连续噪声谱与去噪器权重进行了系统化设计，能在相同或更少采样步数下获得更高的视觉保真度与稳定性\\cite{karras2022elucidating}。

- 参数高效微调与适配：在目标特定的逆向任务中，直接对大型生成器全量微调代价高且不可行，因而采用 LoRA、低秩调整或仅微调解码器/条件模块等参数高效策略可在较少可训练参数下实现良好适配，从而在资源受限环境中加速攻击器的训练与部署\\cite{hu2021loralowrankadaptationlarge}。

- 与识别器的耦合方式：将识别器嵌入作为条件有多种实现路径：直接以嵌入相似度构造损失（微调阶段）；在采样阶段通过对未来样本预测的嵌入误差进行动态修正；或训练噪声条件的嵌入到图像映射器以实现一键条件化。每种方式对计算开销、稳定性与鲁棒性有不同取舍，需在实验中对比验证。

基于以上要点，本研究在设计模板逆向重建方法时将优先采用隐空间扩散以兼顾质量与成本，使用 classifier-free 与嵌入导向的混合引导策略来平衡视觉质量与识别一致性，并通过 LoRA 等微调方法实现对目标模板的高效适配。下面保留原有的形式化推导与公式，详细说明条件化采样的数学基础与实现细节。

本研究提出一个高效率的模型反演方法，从公共数据集上训练的一般无条件生成网络，结合图像特征信息的分数作为引导，从而实现高效率的图像特征反向攻击。
\par
首先对图像特征反向攻击问题作出基本假设。记图像特征信息为y，对应的原始未知图像为$x \sim p(x)$，则图像特征信息的分布可以表示为 $p(y|x)$。本课题所研究的目标是对分布$p(x|y)$进行建模。以往的方法采用GAN模型作为生成器，其生成时是一步生成，难以使用分类引导生成。本研究基于扩散模型进行，其前向扩散步骤与反向生成步骤可以表示为公式\eqref{eqn-1}和公式\eqref{eqn-2},
\begin{align}
      q(x_t|x_{0})=\mathcal{N}(x_t;\sqrt{\overline{\alpha}_t}x_{0},(1-\overline{\alpha}_t)I)\label{eqn-1} \\
      x_{t-1}= \frac{1}{\sqrt{\alpha_t}}
      (x_t -
      \frac{1-\alpha_T}{\sqrt{1-\overline{\alpha}_t}}
      (\epsilon_\theta(x_t,t))) + \sigma_t z \label{eqn-2}
\end{align}
\par
其中$z \sim \mathcal{N}(0,I)$，$x_T \sim \mathcal{N}(0,I)$，$\epsilon_\theta$ 是通过训练得到的关于$x_t$和$t$的噪音，$\sigma_t$,$\alpha_t$ 为与扩散时间步t相关的参数，$\alpha_t$和$\overline{\alpha}_t$为前向过程中参数，这些参数会在\ref{sec:finishwork}一节中详细说明。生成过程即通过从随机噪声 $x_T$ 的采样，迭代公式\eqref{eqn-2}，一步一步恢复图像直至 $x_0$ ，完成生成过程。
\par
以上过程为无条件图像重建的过程，接下来增加图像特征信息$y$对生成过程的引导和约束。对于条件概率贝叶斯公式的导数形式，可以有如下表示：
\begin{equation}\label{eqn-3}
      \nabla \log p(x|y) = \nabla \log p(x) + \nabla \log p(y|x)
\end{equation}
\par
其中的 $y$ 表示分类标签，$\nabla \log p(x|y)$ 表示标签条件下的分数估计，而 $\nabla \log p(x)$表示无条件的分数，$\nabla \log p(y|x)$ 这个认为是在此图像$x$的条件下标签的分数估计。使用特威迪公式对扩散模型的采样过程做估计可以得到如下表示：
\begin{equation}\label{eqn-4}
      \sqrt{\overline{\alpha}_t}x_0 = x_t + (1 - \overline{\alpha}_t) \cdot \nabla_x \log p(x_t) = x_t - \sqrt{1-\overline{\alpha}_t}\cdot\epsilon_\theta(x_t,t)
\end{equation}
\par
于是可以推得扩散模型中采样过程的网络输出与模型分数的关联：
\begin{equation}\label{eqn-5}
      \nabla_{x_t} \log p(x_t) = - \frac{1}{\sqrt{1-\overline{\alpha}_t}} \cdot\epsilon_\theta(x_t,t)
\end{equation}
\par
代入公式\eqref{eqn-3}，得到以下结果：
\begin{equation}\label{eqn-6}
      \nabla \log p(x|y) = - \frac{1}{\sqrt{1-\overline{\alpha}_t}} \cdot\epsilon_\theta(x_t,t)
      + \nabla \log p(y|x)
\end{equation}
\par
若将$p(x|y)$视为生成过程，那么其与模型分数的关联可以表示为：
\begin{equation}\label{eqn-7}
      \nabla \log p(x|y) = - \frac{1}{\sqrt{1-\overline{\alpha}_t}} \cdot\hat{\epsilon}_\theta(x_t,t)
\end{equation}
\par
联合公式\eqref{eqn-6}，则得到以下表达：
\begin{equation}\label{eqn-8}
      \hat{\epsilon}_\theta(x_t,t) = \epsilon_\theta(x_t,t) -\sqrt{1-\overline{\alpha}_t} \cdot \nabla \log p(y|x)
\end{equation}
\par
其中，公式\eqref{eqn-8}等号右边第一项为扩散模型原本的模型噪声输出，右边第二项可以认为是在当前图像上的模型图像分类器分数，而等号左边则为分类器分数调整后的模型噪声修正。
\subsection{无条件引导扩散模型}\label{sec:DDPM}
无条件扩散模型模型包含两个过程，前向扩散过程和反向生成过程，下面进行详细分析。
前向扩散过程是指的对数据逐渐增加高斯噪音直至数据变成随机噪音的过程。
\begin{equation}\label{eqn-11}
      q(x_t|x_{t-1})=\mathcal{N}(x_t;\sqrt{1-\beta_t}x_{t-1},\beta_tI)
\end{equation}
\par
其中$\{\beta_t\}^{T}_{t=1}$为每一步所采用的方差，介于$0 \sim 1$之间。通常情况下，越后面的时间步会采用更大的方差。如果扩散步数T足够大，那么最终得到的$x_T$就完全丢失了原始数据而变成了一个随机噪音。扩散过程的每一步都生成一个带噪音的数据，整个扩散过程也就是一个马尔卡夫链：
\begin{equation}\label{eqn-12}
      q(x_{1:T}|x_0) = \Pi^T_{t=1}{q(x_t|x_{t-1})}
\end{equation}
\par
扩散过程的一个重要特性是可以直接基于原始数据来对任意t步的$x_t$进行采样：$x_t \sim q(x_t|x_0)$。
定义$\alpha_t = 1 - \beta_t$和$\overline{\alpha}_t=\Pi^t_{i=1}{\alpha_i}$，通过反复使用重参数技巧，每次重参数都随机从标准高斯分布中采样，再将采样值作为噪声在数据中扩散，那么有：
\begin{align}
x_t &= \sqrt{\alpha_t}x_{t-1} + \sqrt{1-\alpha_t}\epsilon_{t-1} \nonumber\\
    &= \sqrt{\alpha_t}(\sqrt{\alpha_{t-1}}x_{t-2} + \sqrt{1-\alpha_{t-1}}\epsilon_{t-2}) + \sqrt{1-\alpha_t}\epsilon_{t-1} \nonumber\\
    &= \sqrt{\alpha_t\alpha_{t-1}}x_{t-2} + \sqrt{\sqrt{\alpha_t-\alpha_t\alpha_{t-1}^2}+ \sqrt{1-\alpha_t}^2}\overline{\epsilon}_{t-2}; \nonumber\\
    &= \sqrt{\alpha_t\alpha_{t-1}}x_{t-2} + \sqrt{1-\alpha_t\alpha_{t-1}}\overline{\epsilon}_{t-2} \nonumber\\
    &= \cdots \nonumber\\
    &= \sqrt{\overline{\alpha}_t}x_{0} + \sqrt{1-\overline{\alpha}_t}\epsilon \label{eqn-13}
\end{align}
\par
于是可以得到以下表示:
\begin{equation}\label{eqn-14}
      q(x_t|x_{0})=\mathcal{N}(x_t;\sqrt{\overline{\alpha}_t}x_{0},(1-\overline{\alpha}_t)I)
\end{equation}
\par
扩散过程是将数据噪音化，那么反向过程就是一个去噪的过程，如果反向过程的每一步的真实分布$q(x_{t-1}|x_t)$已知，那么从一个随机噪音$x_T \sim \mathcal{N}(0,I)$开始，逐渐去噪就能生成一个真实的样本，所以反向过程也就是生成数据的过程。
估计分布$q(x_{t-1}|x_t)$需要用到整个训练样本，可以用神经网络来估计这些分布。这里将反向过程也定义为一个马尔卡夫链，只不过它是由一系列用神经网络参数化的高斯分布来组成：
\begin{align}
      p_{\theta}(x_{0:T}) &= p(X_T)\Pi^T_{t=1}{p_{\theta}(x_{t-1}|x_t)} \label{eqn-15}\\
      p(x_T) &= \mathcal{N}(x_T;0,I)\label{eqn-16}\\
      p_{\theta}(x_{t-1}|x_t) &= \mathcal{N}(x_{t-1};\mu_{\theta}(x_t,t),\Sigma_{\theta}(x_t,t))\label{eqn-17}
\end{align}
\par
分布是$q(x_{t-1}|x_t)$不可直接处理的，但是加上条件$x_0$的后验分布$q(x_{t-1}|x_t,x_0)$却是可处理的。
利用贝叶斯公式，得到以下结果：
\begin{equation}\label{eqn-18}
      q(x_{t-1}|x_t,x_0) = q(x_{t}|x_{t-1},x_0)\frac{q(x_{t-1}|x_0)}{q(x_{t}|x_0)}
\end{equation}
\par
这里利用马尔可夫链性质，可知第一项与$x_0$无关，分式两项可以从前向过程得到。因此可以计算。再利用公式\eqref{eqn-14}及公式\eqref{eqn-18}，可以证明$q(x_{t-1}|x_t,x_0)$是一个高斯分布，这里表示为:
\begin{equation}\label{eqn-19}
      q(x_{t-1}|x_t,x_0) = \mathcal{N}(x_{t-1};\widetilde{\mu}(x_t,x_0),\widetilde{\beta_t}I)
\end{equation}
\par
最终可以得到:
\begin{align}
      \widetilde{\beta_t} &= \frac{1 - \overline{\alpha}_{t-1}}{1 - \overline{\alpha}_{t}}\beta_t \label{eqn-20}\\
      \widetilde{\mu}(x_t,x_0) &= \frac{\sqrt{\alpha_t}(1- \overline{\alpha}_{t-1})}{1- \overline{\alpha}_{t}}x_t + \frac{\sqrt{\overline{\alpha}_{t-1}}\beta_t}{1- \overline{\alpha}_{t}}x_0 \label{eqn-21}
\end{align}
\par
可以看到由于扩散过程参数固定，方差是一个定量，而均值是一个依赖$x_0$和$x_t$的函数。
\par
上面介绍了扩散模型的扩散过程和反向过程，现在从另外一个角度来看扩散模型：如果把中间产生的变量看成隐变量的话，那么扩散模型其实是包含$T$个隐变量的隐变量模型，它可以看成是一个特殊的层次化的VAE，相比VAE来说，扩散模型的隐变量是和原始数据同维度的，而且扩散过程是固定的。既然扩散模型是隐变量模型，那么就可以基于变分推断常用的证据下界ELBO作为最大化优化目标，这里有：
\begin{align}
      \log{p_{\theta}(x_0)} &= \log{\int{p_{\theta}(x_{0:T})dx_{1:T}}};\nonumber\\
      &=\log{\int{\frac{p_{\theta}(x_{0:T})q(x_{1:T}|x_0)}{q(x_{1:T}|x_0)}dx_{1:T}}} \nonumber\\
      &\ge \mathbb{E}_{q(x_{1:T}|x_0)}[\log{\frac{p_{\theta}(x_{0:T})}{q(x_{1:T}|x_0)}}]\nonumber
\end{align}
\par
则训练目标为：
\begin{equation}\label{eqn-22}
L = - L_{VLB} = \mathbb{E}_{q(x_{1:T}|x_0)}[-\log{\frac{p_{\theta}(x_{0:T})}{q(x_{1:T}|x_0)}}] = \mathbb{E}_{q(x_{1:T}|x_0)}[\log{\frac{q(x_{1:T}|x_0)}{p_{\theta}(x_{0:T})}}]
\end{equation}
\par
最终得到：
\begin{align}
      L &= \underbrace{D_{KL}(q(x_T|x_0) || p_\theta(x_T))}_{L_T} \nonumber\\
      &+ \sum^T_{t=2}{\underbrace{\mathbb{E}_{q(x_t|x_0)}[D_{KL}(q(x_{t-1}|x_t,x_0) || p_\theta(x_{t-1}|x_t))]}_{L_{t-1}}} \nonumber\\
      &- \underbrace{\mathbb{E}_{q(x_1|x_0)}\log{p_\theta(x_0|x_1)}}_{L_0} \label{eqn-23}
\end{align}
\par
在这里对模型做进一步简化，采用固定的方差$\Sigma_\theta=\sigma^2_tI$，利用高斯分布计算KL散度的公式，经推导优化目标$L_{t-1}$可以变换为：
\begin{equation}\label{eqn-24}
L_{t-1}=\mathbb{E}_{q(x_t|x_0)}[\frac{1}{2\sigma^2_t}\lVert \widetilde{\mu}_t(x_t,x_0)-\mu(x_t,t) \rVert^2_2]
\end{equation}
\par
从上述公式来看，扩散模型希望网络学习到的均值和后验分布的均值一致。从另外一个角度利用重新参数化技巧。在对$q ( x_t | x_0 )$形式的推导以及公式\eqref{eqn-13}中，重新整理结果，将$x_0$视为变量，来得到以下结果：
\begin{equation}\label{eqn-25}
      x_0 = \frac{x_t - \sqrt{1-\overline{\alpha}_t}\epsilon_0}{\sqrt{\overline{\alpha}_t}}
\end{equation}
\par
将其代入我们之前推导的去噪转移均值公式\eqref{eqn-21}，利用新得到的表达式代入公式\eqref{eqn-23}可以重新推导优化目标$L_{t-1}$为：
\begin{equation}\label{eqn-26}
      L_{t-1}=\mathbb{E}_{x_0,\epsilon \sim \mathcal{N}(0,I)}[\lVert \epsilon - \epsilon_\theta (\sqrt{\overline{\alpha}_t}x_0 + \sqrt{1 - \overline{\alpha}_t}\epsilon,t)\rVert^2_2]
\end{equation}
\par
以上结果表明通过预测原始图像$x_0$的学习目标来训练扩散模型等价于通过学习预测噪声来进行训练。
\subsection{基于得分函数的扩散模型解释与条件引导生成}
对于一个高斯变量$z\sim \mathcal{N} ( z ; \mu_z , \Sigma_z)$，特威迪公式为：
\begin{equation}\label{eqn-27}
\mathbb{E}[\mu_z | z] = z + \Sigma_z\nabla_z\log{p(z)}
\end{equation}
\par
由之前的结果，可以得到：
\begin{equation}\label{eqn-28}
      q(x_t|x_0) = \mathcal{N}(x_t;\sqrt{\overline{\alpha}_t}x_0,(1-\overline{\alpha}_t)I)
\end{equation}
\par
然后，应用特威迪公式来预测给定样本的$x_t$的真实后验均值：
\begin{equation}\label{eqn-29}
  \mathbb{E}[\mu_{x_t} | x_t] = x_t + (1-\overline{\alpha}_t)\nabla_{x_t}\log{p(x_t)}
\end{equation}
\par
根据特威迪公式，真实均值最佳估计定义为：
\begin{align}
  \sqrt{\overline{\alpha}_t}x_0 = x_t + (1-\overline{\alpha}_t)\nabla_{x_t}\log{p(x_t)} \label{eqn-30} \\
  x_0 =\frac{ x_t + (1-\overline{\alpha}_t)\nabla_{x_t}\log{p(x_t)}}{\sqrt{\overline{\alpha}_t}} \label{eqn-31}
\end{align}
\par
然后，我们可以将上述方程再次代入\ref{sec:DDPM}节的$\widetilde{\mu}(x_t,x_0)$并推导出新优化目标的形式：
\begin{equation}\label{eqn-32}
      L_{t-1}=\mathbb{E}_{x_0,\epsilon \sim \mathcal{N}(0,I)}[\lVert s_\theta(x_t,t) - \nabla \log p(x_t)\rVert^2_2]
\end{equation}
\par
这里可以认为训练扩散模型可以通过学习预测得分函数$\nabla_{x_t}\log{p(x_t)}$来优化。得分函数是对于任意的噪声水平$t$，$x_t$在数据空间的梯度。
\par
以上过程中只对无条件数据分布$p ( x )$进行了建模。然而，如果希望通过条件信息y显式地控制生成的数据，需要学习条件分布$p ( x | y )$。从扩散模型的基于得分的表述开始，我们的目标可以视为是在任意噪声水平t下学习条件模型的得分$\nabla \log p ( x_t | y )$。根据贝叶斯法则，可以推导出如下等价形式。其中，$\log p ( y )$关于$x_t$的梯度为零。
\begin{align}
  \nabla \log p (x_t|y)
  &= \nabla \log \frac{
    p(x_t)p(y|x_t)
  }{
    p(y)
  } \nonumber\\
  &= \nabla \log p(x_t) + \nabla \log p(y|x_t) + \nabla \log p(y) \nonumber\\
  &= \nabla \log p(x_t) + \nabla \log p(y|x_t) \label{eqn-33}
\end{align}
\par
我们的最终推导结果可以理解为学习一个无条件的得分函数，结合分类器的对抗梯度。因此，在分类器指导中，无条件扩散模型的得分与前面推导的一样被学习，同时一个分类器接受任意噪声$x_t$并试图预测条件信息$y$。然后，在采样过程中，用于朗之万动力学的整体条件得分函数被计算为无条件得分函数和噪声分类器的对抗梯度之和。

\subsection[明晰扩散模型]{明晰扩散模型}

EDM是扩散概率模型领域的重要进展, 由Karras等人在2022年提出。EDM对扩散过程的噪声调度、采样策略和损失函数进行了系统性分析和优化, 极大提升了扩散模型的采样效率和生成质量。

具体来说, 扩散模型通过逐步向数据添加噪声, 将数据分布映射为高斯分布, 并训练神经网络学习逆过程以去噪重建数据。EDM提出了一种统一的噪声调度框架, 定义了噪声幅度 $\sigma$ 的连续变化, 并用参数化的去噪器 $f_\theta(x, \sigma)$ 预测无噪声数据。EDM的核心训练目标为:
\[
  \mathcal{L}(\theta) = \mathbb{E}_{x_0, \sigma, \epsilon} \left[ w(\sigma) \left\| f_\theta(x_0 + \sigma \epsilon, \sigma) - x_0 \right\|^2 \right]
\]
其中, $x_0$ 为真实样本, $\epsilon \sim \mathcal{N}(0, I)$ 为高斯噪声, $\sigma$ 为噪声幅度, $w(\sigma)$ 为权重函数。


EDM的采样过程可用如下随机微分方程描述:
\[
  dx = -\frac{1}{2} \sigma^2 \nabla_x \log p_\theta(x, \sigma) \, d\sigma + \sigma \, dW
\]

其中 $dW$ 为维纳过程, $\nabla_x \log p_\theta(x, \sigma)$ 由神经网络近似。基于以上随机微分方, EDM提出使用二阶采样器来大幅减少采样步数, 提升生成速度。EDM框架统一了多种扩散模型的训练与采样方式, 便于理论分析和工程实现。本课题使用EDM扩散模型作为基础, 设计任务对应的生成模型来达到攻击目的。通过对EDM的训练和优化, 利用不同任务信息来重建匹配的原始输入图像, 从而实现对用户隐私信息的还原。
\subsection[换脸模型]{换脸模型}

换脸（face swapping / face replacement）技术旨在将源人物的面部属性（身份特征、表情或口型）无缝地迁移到目标人物图像或视频上。尽管换脸最初多用于娱乐与影视制作，近年来该技术在深度学习推动下取得显著进展，同时也引发了严重的隐私与滥用风险问题。本小节综述主流的方法学路线、实现要点、常用评估指标以及与模板逆向重建/模型反演研究的关系。

1) 方法学路线。当前换脸方法大致可分为三类：
- 基于自编码器/生成器的端到端映射：这类方法通常采用编码器—解码器结构（或 U-Net 变体）学习从源图像到目标图像的像素级映射，训练时通过重构与身份保持的复合损失确保源身份在目标图像中得以保留；当用于视频时需加上时序一致性约束以避免抖动或闪烁。
- 基于几何/模型的融合（如 3DMM / 仿真渲染）：通过人脸关键点、3D 面部模型估计姿态与光照，先将源面部几何与纹理投影到目标基础几何上，再进行色彩与边界融合；该类方法在保持几何一致性与物理可解释性方面具有优势，便于处理大角度或光照差异。
- 基于条件生成与迁移学习的少样本/单样本方法：为提升泛化性，出现了少样本或单样本换脸方法（使用多任务训练、特征分离或风格融合），以及通过对抗训练提高合成的真实感。这些方法通常将身份表示与表情/姿态表示解耦，并在解码阶段重组以获得目标图像。

2) 身份与表情分解。换脸任务的核心挑战在于如何把“身份”与“可变因素”（表情、姿态、光照）有效分离。常用技术包括特征域投影与互信息最小化、利用专门的身份判别器保证身份一致性、以及在训练损失中引入嵌入相似度约束（如与预训练人脸识别网络的嵌入对齐）来显式维护身份特征。这一点与本研究中的“嵌入一致性”目标高度相关：将识别器嵌入作为度量或训练目标可以在换脸系统中提高身份保真度，但同时也提示了当模板或嵌入被泄露时的滥用风险。

3) 时序与视频一致性。视频换脸需关注帧间一致性与口型/表情同步问题，常用策略包括时序卷积、运动场估计、基于光流的混合以及在损失函数中加入感知级和光流一致性项；对于实时或近实时应用，还需优化推理延迟与内存占用。

4) 无缝融合与后处理。为了获得视觉上无缝的复合效果，换脸系统通常采用面部边界的软掩模、颜色一致化（color transfer）、多尺度融合与 Poisson blending 等技术来减少边界伪影和色彩不一致；这些工程化步骤对最终识别一致性也有影响，因过度平滑可能损失身份细节，而粗糙拼接又可能导致被识别器拒绝匹配。

5) 评估指标与伦理考量。换脸质量评估既包含感知真实度（FID、SSIM、LPIPS 等），也要求衡量身份保真（通过人脸识别模型的验证成功率或嵌入相似度）。重要的是，换脸研究与应用必须考虑伦理与法律约束，包括数据使用许可、明确标注合成内容、以及防止滥用的技术与政策手段（例如水印化、可检测性或合成内容签名）。

6) 与模板逆向重建的相关性。换脸技术与模板逆向重建在方法论上存在交集：二者都依赖高质量的生成模型、身份-表情分解与嵌入级约束。换脸系统展示了在人脸领域重构高保真外观的能力，这既为逆向重建提供了可借鉴的生成与融合技巧，也提醒我们应在设计防御与评估时考虑换脸方法可能带来的更强攻击主体（例如利用换脸生成的高保真图像进行识别系统的旁路攻击）。

7) 工程化建议。本研究在使用换脸或人脸合成作为基线/对照时，将采用统一的对齐与预处理流程、明确记录是否使用时序信息、并在报告中同时给出感知质量与识别一致性指标。此外，对于需要个性化适配的场景（例如少量样本下的跨域换脸），推荐采用参数高效的微调策略（如 LoRA）以在不完全重训练生成器的前提下获得较好的身份迁移效果。

上述内容为换脸技术的要点梳理，为第3章中利用生成模型进行模板重建、以及第5章中的实验对照提供参考。
\section[低秩适配微调技术]{低秩适配微调技术}
% === 被替换/新增内容的记录（保留原占位以便回溯） ===
% 原占位："低秩适配微调技术"

低秩适配（Low-Rank Adaptation，简称 LoRA）及其它参数高效微调方法，已经成为在大型生成模型或识别模型上进行任务特定适配时的常用选择。其基本出发点是：当基础模型参数规模非常大时，直接全量微调代价高、容易过拟合且不利于存储与部署；通过在若干关键权重矩阵上引入低秩可训练增量，可以在冻结原有权重的前提下以极少量额外参数实现对新任务的适配\cite{hu2021loralowrankadaptationlarge}。

下面先给出一个简洁的数学表述，再讨论工程实践要点、超参数建议与局限性。

\subsection*{数学表述}
设某层的权重矩阵为 $W\in\mathbb{R}^{d_{out}\times d_{in}}$，传统微调会直接优化 $W$。LoRA 的做法是在不改变 $W$ 的前提下引入一个可训练的低秩增量 $\Delta W$：
\begin{equation}\label{eq:lora}
      W' = W + \Delta W, \quad\Delta W = B A,
\end{equation}
其中 $A\in\mathbb{R}^{r\times d_{in}}$、$B\in\mathbb{R}^{d_{out}\times r}$，$r\ll\min(d_{in},d_{out})$ 为秩超参数。常见实现会在前向计算时以尺度因子 $\alpha$ 做缩放，即 $W' = W + \frac{\alpha}{r} B A$，以便对不同秩值间的更新幅度做归一化。

可训练参数量的附加成本为 $r(d_{in}+d_{out})$（近似），远小于全量微调的 $d_{in}d_{out}$。这一形式既可看作对权重矩阵的低秩近似，也等价于对网络权重空间做一组低维方向的线性组合。

\subsection*{应用位置与工程实现}
在视觉生成与识别模型中，LoRA 常用于以下位置：
- 注意力模块中的投影矩阵（query/key/value 投影或输出投影）；
- 前馈网络（MLP）中的线性层；
- U-Net 或 Transformer 的某些瓶颈层；
- 对卷积层，可通过在 $1\times1$ 卷积或点卷积处应用低秩分解实现类似效果。

实现要点：
- 冻结原始网络参数，仅优化 $A,B$（以及可能的偏置项），这能显著降低显存占用并避免破坏原有能力；
- 初始值选取：常用将 $A$ 置为小的高斯随机或零初始化、将 $B$ 置为零或小随机值，以保证训练初期网络行为接近原模型；\\
- 缩放策略：采用 $\frac{\alpha}{r}$ 缩放项，能让不同秩设置下的学习率与幅度更可比；\\
- 推理优化：训练完成后可将 $\Delta W$ 与 $W$ 合并以得到纯粹的密集权重用于高效推理，或在运行时将低秩模块以高效内核实现以节省内存。

\subsection*{训练细节与超参数建议}
针对本研究中对生成器（例如 EDM / LDM 的 U-Net）或识别器做微调的场景，建议的经验性超参数范围如下（可根据数据量、目标复杂度与计算资源调整）：
- 秩 $r$：常用 $4\sim64$，对微量个性化适配（例如单身份）可取较小值($r=4$或$8$)，对更复杂风格/身份迁移可增大；
- 缩放因子 $\alpha$：常用 $1\sim32$；实际生效缩放为 $\alpha/r$，因此可通过 $\alpha$ 调整更新强度；
- 学习率：使用 AdamW，微调 $A,B$ 时一般在 $1\times10^{-5}\sim5\times10^{-4}$ 之间；若只微调条件模块或低秩矩阵，可适当取靠上界；
- 权重衰减与正则化：微小的 weight decay（如 $\le 1\times10^{-2}$）有助于稳定；可选地对 $B$ 做范数约束以防止过大投影；
- 批大小与步数：微调通常需要较小的训练轮次（从数十到数百步起步，或少量 epoch（如 1\~10 epoch）），批大小依据显存条件设定（8\~64 常见）；
- 早停与校验：建议使用识别器嵌入一致性（验证集的嵌入相似度或 TAR）作为早停/模型选择指标，避免生成视觉质量退化但识别一致性并不提升的情况。

在实验过程中，应额外监控：生成图像的感知质量（FID/LPIPS）、以及识别层面的匹配率（TAR@FAR），以避免单一指标优化带来的过拟合。

\subsection*{优势、局限与替代方法}
优势：低秩适配在参数效率、存储开销与部署便捷性上具有明显优势。对于需要对大量目标（例如多个身份）做个性化适配的场景，可以仅保存每个目标的小量 LoRA 权重而不是完整模型副本，从而极大降低存储成本。

局限：若目标变化过大或需要学习与基础模型截然不同的表征结构，低秩增量的容量可能不足，导致适配效果受限。此外，过度依赖缩放或不当初始化可能引入训练不稳定或伪影。

替代/补充方法：除 LoRA 外，常见的参数高效方法还包括 Adapter（在层间插入小型瓶颈模块）、Prefix-tuning（对 Transformer 的注意力键值加入可学习前缀）、BitFit（仅微调偏置）等。实践中可根据任务选择或组合这些方法（例如 LoRA + Adapter），以兼顾效率与表达能力。

\subsection*{针对模板逆向重建任务的建议}
在本研究的模板逆向重建情形，应考虑如下工程建议：
- 首先在公共数据集或通用无条件生成器上完成基础训练（或采用开源预训练权重），再对每个目标模板做 LoRA 微调（微适配），以避免对大模型全量训练；
- 微调目标应以嵌入一致性损失为核心（见第3章），同时辅以感知/像素损失以维持视觉质量；LoRA 的低秩参数仅需在微调阶段更新；
- 为提高样本效率，可在微调时采用学习率预热、梯度累积与小批次多次采样策略；
- 存储与复现：仅保存 $A,B$ 参数与对应的元信息（所用层、秩 $r$、$\alpha$、训练步数与验证指标），便于复现实验并降低存储成本。

% === 结束新增内容 ===
\section[本章小结]{本章小结}
本章对支持后续第3章与第4章方法设计和实验评估的若干理论与工程要点做了系统性的梳理，主要结论与实践建议如下：

1) 符号与问题约定——为保证论文的可读性与实验的可复现性，建议在附录或本章开头的“符号说明”中明确全部常用符号（例如 $x,x_t,x_0,y,f(\cdot),g_\theta,\epsilon_\theta,\alpha_t,\sigma$ 等）与数据/模板的格式（浮点/量化、维度 $d$、是否包含置信度），以便读者快速查阅并在复现在实现中保持一致性。

2) 人脸识别模型的几何性质与评估协议——基于度量学习的判别性损失（如 ArcFace 等）塑造了嵌入空间的几何结构，这直接影响模板逆向攻击的可行性与评估方法。实验应同时报告嵌入相似度（余弦/欧氏）、验证指标（TAR@FAR）、以及感知质量指标（FID、LPIPS），以便从识别一致性与视觉真实感两个维度综合评价重建结果。

3) 扩散模型的条件化与引导机制——从得分函数的角度，条件化生成可看作是将识别器关于输入的对数似然梯度或相似度能量项加入无条件得分的过程（见公式\eqref{eqn-3}~\eqref{eqn-8}）。这为两类工程实现提供理论支持：一是采样时通过 classifier/classifier-free/能量引导施加嵌入约束；二是在微调阶段将嵌入一致性作为显式损失以调整生成器参数或低秩增量。

4) 采样效率的工程折中——为应对需要多次查询或实时性要求，推荐基线采用隐空间扩散（LDM）并结合 EDM/二阶采样器或 DDIM 等加速方法以在少量步数下保持较好视觉质量；在评估攻击代价时记得报告平均采样步数与每次查询的运行时延迟。

5) 参数高效微调（以 LoRA 为代表）的实践建议——LoRA 在本课题中可作为对单个模板或少量目标做个性化适配的首选方案：它在参数/存储开销、训练稳定性与部署便捷性上有明显优势。本章给出的秩 $r$、缩放 $\alpha$ 与学习率范围可作为微调实验的起点；此外应保存每次微调的元信息以便复现（所更新层、秩、缩放、训练步数与验证指标）。

6) 评估与伦理约束——在进行模板逆向或换脸相关实验时，务必遵守数据许可与伦理规范：使用公开许可的数据集、对合成内容做标注、并在论文中说明潜在风险与防御建议（例如模板保护、差分隐私或签名化模板）。在结果展示中应同时给出成功攻击的统计概率与失败案例分析，以免仅展示“最好”样本造成误导。

7) 工程实现提示与复现清单——为保证工作可复现，建议在附录或项目说明中列出关键实现细节：深度学习框架与版本（例如 PyTorch 的具体版本）、关键第三方库（如 timm、accelerate、diffusers/edm 实现）、训练/推理的硬件配置、超参数表、随机种子与数据预处理脚本。对 LoRA 等微调方法，应提供如何将低秩增量合并回原模型的说明与伪代码。

本章的理论与工程要点将直接支撑第3章中提出的基于扩散模型的模板逆向重建方法（包括嵌入一致性损失、LoRA 微适配策略与采样引导实现），后续章节将基于本章约定给出详细的算法、实验设置与可复现的实现细节。

% Local Variables:
% TeX-master: "../main"
% TeX-engine: xetex
% End:
