% !Mode:: "TeX:UTF-8"
\subsection[数学原理补充]{数学原理补充}
本小节补充并明确本章涉及的若干数学原理与推导要点，便于将来在论文正文中引用定理/公式并用于算法实现的严格说明。

\subsubsection*{1. 从 score-matching 到去噪目标的等价性（要点）}
考虑噪声预测目标
\begin{equation}
      L_{\epsilon} = \mathbb{E}_{x_0,\epsilon\sim\mathcal{N}(0,I),t}\left[ w(t) \|\epsilon - \epsilon_\theta(x_t,t)\|^2\right],
\end{equation}
其中 $x_t=\sqrt{\overline{\alpha}_t}x_0+\sqrt{1-\overline{\alpha}_t}\,\epsilon$。按链式运算可得关于 $x_t$ 的得分函数近似
\begin{equation}
      \nabla_{x_t}\log p(x_t) = -\frac{1}{\sqrt{1-\overline{\alpha}_t}}\,\epsilon_\theta(x_t,t) + C(t),
\end{equation}
其中常数项 $C(t)$ 与 $x_t$ 无关，可被吸收到权重或偏移项中。进而，最小化 $L_{\epsilon}$ 等价于对不同噪声尺度下的加权得分匹配（score-matching）问题，从而保证训练得到的 $\epsilon_\theta$ 能用于近似 $\nabla_{x_t}\log p(x_t)$（参见式~\eqref{eqn-5}）。

证明要点（略）: 将 $x_0$ 用 $x_t,\epsilon$ 表示并展开展开平方项，可把 $L_{\epsilon}$ 重写为关于 $\epsilon_\theta$ 与真实得分的二次项，进而等价于加权的得分匹配下界（见 Song 等人的推导）。在工程实践中通过选择合适的权重 $w(t)$ 可稳定训练并平衡不同噪声尺度的贡献。

\subsubsection*{2. Score-based SDE 与反向 SDE}
令前向 SDE 写作
\begin{equation}
      d x = f(x,t)\,dt + g(t)\,dW_t,
\end{equation}
则其对应的反向（time-reversed）SDE 在已知 $\nabla_x\log p_t(x)$ 时可写为
\begin{equation}
      d x = \left[f(x,t) - g(t)^2\,\nabla_x\log p_t(x)\right] dt + g(t)\,d\bar W_t,
\end{equation}
其中 $\bar W_t$ 为反向 Wiener 过程。该表达说明：若能估计出 $\nabla_x\log p_t(x)$（由去噪网络提供），即可解出反向生成过程；分类器/能量项可通过在得分上叠加 $\nabla_x\log p(y|x)$ 实现条件化（见下小节）。

\subsubsection*{3. 分类器引导与 classifier-free guidance 的关系}
若存在一个条件分类器 $p_\phi(y|x_t)$，则
\begin{equation}
      \nabla_{x_t}\log p(y|x_t) \approx \nabla_{x_t} \log p_\phi(y|x_t).
\end{equation}
将其与无条件得分相加给出条件得分（贝叶斯分解）:
\begin{equation}
      \nabla_{x_t}\log p(x_t|y) = \nabla_{x_t}\log p(x_t) + \nabla_{x_t}\log p(y|x_t).
\end{equation}
在实际采样中，常用带权重的混合形式来放大条件信息：
\begin{equation}
      s_{\text{guid}} = s_{\text{uncond}} + w\,(s_{\text{cond}} - s_{\text{uncond}}) = (1-w) s_{\text{uncond}} + w s_{\text{cond}},
\end{equation}
其中 $s=\nabla_{x_t}\log p(\cdot)$。等价地，对噪声預測器而言有
\begin{equation}
      \epsilon_{\text{guid}} = \epsilon_{\text{uncond}} + \gamma\,(\epsilon_{\text{cond}} - \epsilon_{\text{uncond}}),
\end{equation}
其中 $\gamma$ 与 $w$ 存在简单线性映射（与噪声尺度因子有关）。

Classifier-free guidance 的实现不需要额外训练分类器，而是在训练阶段隨機屏蔽条件（例如将条件 embedding 替换为全零或 sentinel），使模型学会在有/无条件下均可预测噪声。推导上 classifier-free guidance 与上式等价，只是 $\epsilon_{\text{cond}}$ 与 $\epsilon_{\text{uncond}}$ 来自同一网络在不同输入下的输出。

\subsubsection*{4. 条件化采样时的能量项近似}
在本研究我们把识别器的嵌入相似度视为能量 $E(x;y) = -\lambda\cdot \text{sim}(f(x),y)$，其对 $x$ 的梯度用于在采样过程中修正得分：
\begin{equation}
      \nabla_x \log p(x|y) \approx \nabla_x \log p(x) - \nabla_x E(x;y).
\end{equation}
在实现中直接对 $f(\cdot)$ 取微分并反向传播得到 $\nabla_x \text{sim}(f(x),y)$ 的近似梯度，该项与去噪器的输出在 score-space 中进行线性组合（见伪代码示例），可视为对目标嵌入相似度的显式引导。

\subsubsection*{5. LoRA 的代数表示与参数量分析}
设原权重矩阵为 $W\in\mathbb{R}^{d_{out}\times d_{in}}$，LoRA 引入低秩增量 $\Delta W = B A$，其中 $A\in\mathbb{R}^{r\times d_{in}}$、$B\in\mathbb{R}^{d_{out}\times r}$。若在前向传播中采用缩放因子 $\alpha$，则实际替换为
\begin{equation}
      W' = W + \frac{\alpha}{r} B A.
\end{equation}
参数额外开销约为 $r(d_{in}+d_{out})$，远小于 $d_{out}d_{in}$。训练时仅更新 $A,B$（和可能的缩放），可显著降低显存与存储成本。训练结束后可合并：
\begin{equation}
      W'_{\text{merged}} = W + \frac{\alpha}{r} B A
\end{equation}
以便高效推理。

梯度维度说明：若损失为 $\mathcal{L}$，则对 $A,B$ 的梯度分别为
\begin{equation}
      \nabla_A \mathcal{L} = B^{\top} \nabla_{W'} \mathcal{L},\qquad \nabla_B \mathcal{L} = \nabla_{W'} \mathcal{L}\, A^{\top},
\end{equation}
从而训练仅在低维子空间中进行权重更新。

\subsubsection*{6. 黑盒优化时的无梯度近似（简要）}
在黑盒场景下，若只能得到标量分数 $S(x)$，可采用有限差分或随机扰动估计梯度：
\begin{equation}
      \hat g = \frac{1}{m}\sum_{i=1}^m \frac{S(x+\delta_i)-S(x-\delta_i)}{2\epsilon} \, \delta_i,
\end{equation}
其中 $\delta_i$ 为服从零均值分布的随机方向（例如高斯或 Rademacher），$\epsilon$ 为扰动幅度。NES / SPSA 等方法即基于该类估计，通过并行化或控制方差技巧提高查询效率。本研究在实现黑盒潜在优化基线时采用了上述思路并在实验中测量查询成本与成功率的 trade-off。

% End of math supplement
      q(x_t|x_{0})=\mathcal{N}(x_t;\sqrt{\overline{\alpha}_t}x_{0},(1-\overline{\alpha}_t)I)\label{eqn-1} \\
      x_{t-1}= \frac{1}{\sqrt{\alpha_t}}
      (x_t -
      \frac{1-\alpha_T}{\sqrt{1-\overline{\alpha}_t}}
      (\epsilon_\theta(x_t,t))) + \sigma_t z \label{eqn-2}
\end{align}
\par
其中$z \sim \mathcal{N}(0,I)$，$x_T \sim \mathcal{N}(0,I)$，$\epsilon_\theta$ 是通过训练得到的关于$x_t$和$t$的噪音，$\sigma_t$,$\alpha_t$ 为与扩散时间步t相关的参数，$\alpha_t$和$\overline{\alpha}_t$为前向过程中参数，这些参数会在\ref{sec:finishwork}一节中详细说明。生成过程即通过从随机噪声 $x_T$ 的采样，迭代公式\eqref{eqn-2}，一步一步恢复图像直至 $x_0$ ，完成生成过程。
\par
以上过程为无条件图像重建的过程，接下来增加图像特征信息$y$对生成过程的引导和约束。对于条件概率贝叶斯公式的导数形式，可以有如下表示：
\begin{equation}\label{eqn-3}
      \nabla \log p(x|y) = \nabla \log p(x) + \nabla \log p(y|x)
\end{equation}
\par
其中的 $y$ 表示分类标签，$\nabla \log p(x|y)$ 表示标签条件下的分数估计，而 $\nabla \log p(x)$表示无条件的分数，$\nabla \log p(y|x)$ 这个认为是在此图像$x$的条件下标签的分数估计。使用特威迪公式对扩散模型的采样过程做估计可以得到如下表示：
\begin{equation}\label{eqn-4}
      \sqrt{\overline{\alpha}_t}x_0 = x_t + (1 - \overline{\alpha}_t) \cdot \nabla_x \log p(x_t) = x_t - \sqrt{1-\overline{\alpha}_t}\cdot\epsilon_\theta(x_t,t)
\end{equation}
\par
于是可以推得扩散模型中采样过程的网络输出与模型分数的关联：
\begin{equation}\label{eqn-5}
      \nabla_{x_t} \log p(x_t) = - \frac{1}{\sqrt{1-\overline{\alpha}_t}} \cdot\epsilon_\theta(x_t,t)
\end{equation}
\par
代入公式\eqref{eqn-3}，得到以下结果：
\begin{equation}\label{eqn-6}
      \nabla \log p(x|y) = - \frac{1}{\sqrt{1-\overline{\alpha}_t}} \cdot\epsilon_\theta(x_t,t)
      + \nabla \log p(y|x)
\end{equation}
\par
若将$p(x|y)$视为生成过程，那么其与模型分数的关联可以表示为：
\begin{equation}\label{eqn-7}
      \nabla \log p(x|y) = - \frac{1}{\sqrt{1-\overline{\alpha}_t}} \cdot\hat{\epsilon}_\theta(x_t,t)
\end{equation}
\par
联合公式\eqref{eqn-6}，则得到以下表达：
\begin{equation}\label{eqn-8}
      \hat{\epsilon}_\theta(x_t,t) = \epsilon_\theta(x_t,t) -\sqrt{1-\overline{\alpha}_t} \cdot \nabla \log p(y|x)
\end{equation}
\par
其中，公式\eqref{eqn-8}等号右边第一项为扩散模型原本的模型噪声输出，右边第二项可以认为是在当前图像上的模型图像分类器分数，而等号左边则为分类器分数调整后的模型噪声修正。
\subsection{无条件引导扩散模型}\label{sec:DDPM}
无条件扩散模型模型包含两个过程，前向扩散过程和反向生成过程，下面进行详细分析。
前向扩散过程是指的对数据逐渐增加高斯噪音直至数据变成随机噪音的过程。
\begin{equation}\label{eqn-11}
      q(x_t|x_{t-1})=\mathcal{N}(x_t;\sqrt{1-\beta_t}x_{t-1},\beta_tI)
\end{equation}
\par
其中$\{\beta_t\}^{T}_{t=1}$为每一步所采用的方差，介于$0 \sim 1$之间。通常情况下，越后面的时间步会采用更大的方差。如果扩散步数T足够大，那么最终得到的$x_T$就完全丢失了原始数据而变成了一个随机噪音。扩散过程的每一步都生成一个带噪音的数据，整个扩散过程也就是一个马尔卡夫链：
\begin{equation}\label{eqn-12}
      q(x_{1:T}|x_0) = \Pi^T_{t=1}{q(x_t|x_{t-1})}
\end{equation}
\par
扩散过程的一个重要特性是可以直接基于原始数据来对任意t步的$x_t$进行采样：$x_t \sim q(x_t|x_0)$。
定义$\alpha_t = 1 - \beta_t$和$\overline{\alpha}_t=\Pi^t_{i=1}{\alpha_i}$，通过反复使用重参数技巧，每次重参数都随机从标准高斯分布中采样，再将采样值作为噪声在数据中扩散，那么有：
\begin{subequations}\label{eqn:xt_expand}
\begin{align}
x_t &= \sqrt{\alpha_t}x_{t-1} + \sqrt{1-\alpha_t}\,\epsilon_{t-1} \\
      &= \sqrt{\alpha_t}\left(\sqrt{\alpha_{t-1}}x_{t-2} + \sqrt{1-\alpha_{t-1}}\,\epsilon_{t-2}\right) + \sqrt{1-\alpha_t}\,\epsilon_{t-1} \\
      &= \sqrt{\alpha_t\alpha_{t-1}}\,x_{t-2} + \sqrt{1-\alpha_t\alpha_{t-1}}\,\overline{\epsilon}_{t-2} \\
      &\vdots \nonumber \\
      &= \sqrt{\overline{\alpha}_t}\,x_{0} + \sqrt{1-\overline{\alpha}_t}\,\epsilon \label{eqn-13}
\end{align}
\end{subequations}
\par
于是可以得到以下表示:
\begin{equation}\label{eqn-14}
      q(x_t|x_{0})=\mathcal{N}(x_t;\sqrt{\overline{\alpha}_t}x_{0},(1-\overline{\alpha}_t)I)
\end{equation}
\par
扩散过程是将数据噪音化，那么反向过程就是一个去噪的过程，如果反向过程的每一步的真实分布$q(x_{t-1}|x_t)$已知，那么从一个随机噪音$x_T \sim \mathcal{N}(0,I)$开始，逐渐去噪就能生成一个真实的样本，所以反向过程也就是生成数据的过程。
估计分布$q(x_{t-1}|x_t)$需要用到整个训练样本，可以用神经网络来估计这些分布。这里将反向过程也定义为一个马尔卡夫链，只不过它是由一系列用神经网络参数化的高斯分布来组成：
\begin{align}
      p_{\theta}(x_{0:T}) &= p(X_T)\Pi^T_{t=1}{p_{\theta}(x_{t-1}|x_t)} \label{eqn-15}\\
      p(x_T) &= \mathcal{N}(x_T;0,I)\label{eqn-16}\\
      p_{\theta}(x_{t-1}|x_t) &= \mathcal{N}(x_{t-1};\mu_{\theta}(x_t,t),\Sigma_{\theta}(x_t,t))\label{eqn-17}
\end{align}
\par
分布是$q(x_{t-1}|x_t)$不可直接处理的，但是加上条件$x_0$的后验分布$q(x_{t-1}|x_t,x_0)$却是可处理的。
利用贝叶斯公式，得到以下结果：
\begin{equation}\label{eqn-18}
      q(x_{t-1}|x_t,x_0) = q(x_{t}|x_{t-1},x_0)\frac{q(x_{t-1}|x_0)}{q(x_{t}|x_0)}
\end{equation}
\par
这里利用马尔可夫链性质，可知第一项与$x_0$无关，分式两项可以从前向过程得到。因此可以计算。再利用公式\eqref{eqn-14}及公式\eqref{eqn-18}，可以证明$q(x_{t-1}|x_t,x_0)$是一个高斯分布，这里表示为:
\begin{equation}\label{eqn-19}
      q(x_{t-1}|x_t,x_0) = \mathcal{N}(x_{t-1};\widetilde{\mu}(x_t,x_0),\widetilde{\beta_t}I)
\end{equation}
\par
最终可以得到:
\begin{align}
      \widetilde{\beta_t} &= \frac{1 - \overline{\alpha}_{t-1}}{1 - \overline{\alpha}_{t}}\beta_t \label{eqn-20}\\
      \widetilde{\mu}(x_t,x_0) &= \frac{\sqrt{\alpha_t}(1- \overline{\alpha}_{t-1})}{1- \overline{\alpha}_{t}}x_t + \frac{\sqrt{\overline{\alpha}_{t-1}}\beta_t}{1- \overline{\alpha}_{t}}x_0 \label{eqn-21}
\end{align}
\par
可以看到由于扩散过程参数固定，方差是一个定量，而均值是一个依赖$x_0$和$x_t$的函数。
\par
上面介绍了扩散模型的扩散过程和反向过程，现在从另外一个角度来看扩散模型：如果把中间产生的变量看成隐变量的话，那么扩散模型其实是包含$T$个隐变量的隐变量模型，它可以看成是一个特殊的层次化的VAE，相比VAE来说，扩散模型的隐变量是和原始数据同维度的，而且扩散过程是固定的。既然扩散模型是隐变量模型，那么就可以基于变分推断常用的证据下界ELBO作为最大化优化目标，这里有：
\begin{align}
      \log{p_{\theta}(x_0)} &= \log{\int{p_{\theta}(x_{0:T})dx_{1:T}}};\nonumber\\
      &=\log{\int{\frac{p_{\theta}(x_{0:T})q(x_{1:T}|x_0)}{q(x_{1:T}|x_0)}dx_{1:T}}} \nonumber\\
      &\ge \mathbb{E}_{q(x_{1:T}|x_0)}[\log{\frac{p_{\theta}(x_{0:T})}{q(x_{1:T}|x_0)}}]\nonumber
\end{align}
\par
则训练目标为：
\begin{equation}\label{eqn-22}
L = - L_{VLB} = \mathbb{E}_{q(x_{1:T}|x_0)}[-\log{\frac{p_{\theta}(x_{0:T})}{q(x_{1:T}|x_0)}}] = \mathbb{E}_{q(x_{1:T}|x_0)}[\log{\frac{q(x_{1:T}|x_0)}{p_{\theta}(x_{0:T})}}]
\end{equation}
\par
最终得到：
\begin{align}
      L &= \underbrace{D_{KL}(q(x_T|x_0) || p_\theta(x_T))}_{L_T} \nonumber\\
      &+ \sum^T_{t=2}{\underbrace{\mathbb{E}_{q(x_t|x_0)}[D_{KL}(q(x_{t-1}|x_t,x_0) || p_\theta(x_{t-1}|x_t))]}_{L_{t-1}}} \nonumber\\
      &- \underbrace{\mathbb{E}_{q(x_1|x_0)}\log{p_\theta(x_0|x_1)}}_{L_0} \label{eqn-23}
\end{align}
\par
在这里对模型做进一步简化，采用固定的方差$\Sigma_\theta=\sigma^2_tI$，利用高斯分布计算KL散度的公式，经推导优化目标$L_{t-1}$可以变换为：
\begin{equation}\label{eqn-24}
L_{t-1}=\mathbb{E}_{q(x_t|x_0)}[\frac{1}{2\sigma^2_t}\lVert \widetilde{\mu}_t(x_t,x_0)-\mu(x_t,t) \rVert^2_2]
\end{equation}
\par
从上述公式来看，扩散模型希望网络学习到的均值和后验分布的均值一致。从另外一个角度利用重新参数化技巧。在对$q ( x_t | x_0 )$形式的推导以及公式\eqref{eqn-13}中，重新整理结果，将$x_0$视为变量，来得到以下结果：
\begin{equation}\label{eqn-25}
      x_0 = \frac{x_t - \sqrt{1-\overline{\alpha}_t}\epsilon_0}{\sqrt{\overline{\alpha}_t}}
\end{equation}
\par
将其代入我们之前推导的去噪转移均值公式\eqref{eqn-21}，利用新得到的表达式代入公式\eqref{eqn-23}可以重新推导优化目标$L_{t-1}$为：
\begin{equation}\label{eqn-26}
      L_{t-1}=\mathbb{E}_{x_0,\epsilon \sim \mathcal{N}(0,I)}[\lVert \epsilon - \epsilon_\theta (\sqrt{\overline{\alpha}_t}x_0 + \sqrt{1 - \overline{\alpha}_t}\epsilon,t)\rVert^2_2]
\end{equation}
\par
以上结果表明通过预测原始图像$x_0$的学习目标来训练扩散模型等价于通过学习预测噪声来进行训练。
\subsection{基于得分函数的扩散模型解释与条件引导生成}
对于一个高斯变量$z\sim \mathcal{N} ( z ; \mu_z , \Sigma_z)$，特威迪公式为：
\begin{equation}\label{eqn-27}
\mathbb{E}[\mu_z | z] = z + \Sigma_z\nabla_z\log{p(z)}
\end{equation}
\par
由之前的结果，可以得到：
\begin{equation}\label{eqn-28}
      q(x_t|x_0) = \mathcal{N}(x_t;\sqrt{\overline{\alpha}_t}x_0,(1-\overline{\alpha}_t)I)
\end{equation}
\par
然后，应用特威迪公式来预测给定样本的$x_t$的真实后验均值：
\begin{equation}\label{eqn-29}
  \mathbb{E}[\mu_{x_t} | x_t] = x_t + (1-\overline{\alpha}_t)\nabla_{x_t}\log{p(x_t)}
\end{equation}
\par
根据特威迪公式，真实均值最佳估计定义为：
\begin{align}
  \sqrt{\overline{\alpha}_t}x_0 = x_t + (1-\overline{\alpha}_t)\nabla_{x_t}\log{p(x_t)} \label{eqn-30} \\
  x_0 =\frac{ x_t + (1-\overline{\alpha}_t)\nabla_{x_t}\log{p(x_t)}}{\sqrt{\overline{\alpha}_t}} \label{eqn-31}
\end{align}
\par
然后，我们可以将上述方程再次代入\ref{sec:DDPM}节的$\widetilde{\mu}(x_t,x_0)$并推导出新优化目标的形式：
\begin{equation}\label{eqn-32}
      L_{t-1}=\mathbb{E}_{x_0,\epsilon \sim \mathcal{N}(0,I)}[\lVert s_\theta(x_t,t) - \nabla \log p(x_t)\rVert^2_2]
\end{equation}
\par
这里可以认为训练扩散模型可以通过学习预测得分函数$\nabla_{x_t}\log{p(x_t)}$来优化。得分函数是对于任意的噪声水平$t$，$x_t$在数据空间的梯度。
\par
以上过程中只对无条件数据分布$p ( x )$进行了建模。然而，如果希望通过条件信息y显式地控制生成的数据，需要学习条件分布$p ( x | y )$。从扩散模型的基于得分的表述开始，我们的目标可以视为是在任意噪声水平t下学习条件模型的得分$\nabla \log p ( x_t | y )$。根据贝叶斯法则，可以推导出如下等价形式。其中，$\log p ( y )$关于$x_t$的梯度为零。
\begin{align}
  \nabla \log p (x_t|y)
  &= \nabla \log \frac{
    p(x_t)p(y|x_t)
  }{
    p(y)
  } \nonumber\\
  &= \nabla \log p(x_t) + \nabla \log p(y|x_t) + \nabla \log p(y) \nonumber\\
  &= \nabla \log p(x_t) + \nabla \log p(y|x_t) \label{eqn-33}
\end{align}
\par
我们的最终推导结果可以理解为学习一个无条件的得分函数，结合分类器的对抗梯度。因此，在分类器指导中，无条件扩散模型的得分与前面推导的一样被学习，同时一个分类器接受任意噪声$x_t$并试图预测条件信息$y$。然后，在采样过程中，用于朗之万动力学的整体条件得分函数被计算为无条件得分函数和噪声分类器的对抗梯度之和。

\subsection[明晰扩散模型]{明晰扩散模型}

EDM是扩散概率模型领域的重要进展, 由Karras等人在2022年提出。EDM对扩散过程的噪声调度、采样策略和损失函数进行了系统性分析和优化, 极大提升了扩散模型的采样效率和生成质量。

具体来说, 扩散模型通过逐步向数据添加噪声, 将数据分布映射为高斯分布, 并训练神经网络学习逆过程以去噪重建数据。EDM提出了一种统一的噪声调度框架, 定义了噪声幅度 $\sigma$ 的连续变化, 并用参数化的去噪器 $f_\theta(x, \sigma)$ 预测无噪声数据。EDM的核心训练目标为:
\begin{equation}
      \mathcal{L}(\theta) = \mathbb{E}_{x_0, \sigma, \epsilon} \left[ w(\sigma) \left\| f_\theta(x_0 + \sigma \epsilon, \sigma) - x_0 \right\|^2 \right]
\end{equation}
其中, $x_0$ 为真实样本, $\epsilon \sim \mathcal{N}(0, I)$ 为高斯噪声, $\sigma$ 为噪声幅度, $w(\sigma)$ 为权重函数。


EDM的采样过程可用如下随机微分方程描述:
\begin{equation}
      dx = -\frac{1}{2} \sigma^2 \nabla_x \log p_\theta(x, \sigma) \, d\sigma + \sigma \, dW
\end{equation}

其中 $dW$ 为维纳过程, $\nabla_x \log p_\theta(x, \sigma)$ 由神经网络近似。基于以上随机微分方, EDM提出使用二阶采样器来大幅减少采样步数, 提升生成速度。EDM框架统一了多种扩散模型的训练与采样方式, 便于理论分析和工程实现。本课题使用EDM扩散模型作为基础, 设计任务对应的生成模型来达到攻击目的。通过对EDM的训练和优化, 利用不同任务信息来重建匹配的原始输入图像, 从而实现对用户隐私信息的还原。
\subsubsection*{实用采样与调参配方（工程化建议）}
为便于将理论转为可复现的实验，本小节给出一组工程化的“配方”与伪代码，适用于以 EDM/LDM 为基础进行嵌入引导的模板重建任务。

要点摘要：
\begin{itemize}
      \item 采样步数与采样器：在工程评估中常以 20~100 步作为效率—质量折中。对于 EDM/二阶采样器，20~50 步通常能得到较好视觉质量；若质量为首要指标，可上升至 100 步。优先选用 Heun / 2nd-order 采样器以在低步数下获得稳定性。
      \item 指导强度（guidance scale）：对 classifier-free guidance 推荐在 3.0~8.0 之间搜索；嵌入/能量型引导（embedding guidance）可使用随噪声水平衰减的权重 $w(t)$，例如 $w(t)=w_0\\cdot e^{-\\kappa\\sigma(t)}$，取 $w_0\\in[1.0,10.0],\\kappa\\in[0.1,1.0]$ 进行调优。
      \item 噪声谱与权重函数：在 EDM 框架下，使用连续噪声谱并配合 $w(\\sigma)$（如 $w(\\sigma)=1/\\sigma^2$ 或作者建议的平衡形式）可提升低步数表现；在实现时请参考开源 EDM/denoiser 实现的默认设置并在小规模网格搜索中验证。
      \item LoRA 微调配方（单目标个性化）：秩 $r\\in\\{4,8,16\\}$；缩放 $\\alpha$ 取 8 或 16；学习率 $\\in[1\\times10^{-5},5\\times10^{-4}]$；训练步数依据样本量在 50~2000 步之间；以识别器余弦相似度作为早停与模型选择指标。
\end{itemize}

简要伪代码（采样 + 嵌入引导示例）：
\begin{verbatim}
# x_T ~ N(0,I)
x = x_T
for t in sampler_schedule:
            # predict noise / denoised x
            eps_uncond = denoiser(x, sigma(t), cond=None)
            eps_cond   = denoiser(x, sigma(t), cond=embedding)
            # classifier-free guidance
            eps_guided = eps_uncond + guidance_scale * (eps_cond - eps_uncond)

            # embedding-guidance: approximate gradient of similarity in pixel/latent space
            g = embedding_weight(t) * compute_embedding_grad(x, target_embedding)

            # combine in score domain (示例形式)
            eps_combined = eps_guided - sqrt(1 - alpha_bar(t)) * g

            # sampler step (Heun / 2nd order)
            x = sampler_step(x, eps_combined, t)
end
return x0_estimate(x)
\end{verbatim}

调参注意事项与实验设计建议：
\begin{itemize}
      \item 在小规模验证集上先做两维网格搜索（guidance_scale × embedding_weight），记录识别一致性（TAR@FAR）与感知指标（LPIPS/FID）；优先按识别一致性排序，再用视觉指标做二次筛选。\\
      \item 将 LoRA 微调与采样引导结合：建议先用少量步数与 LoRA 快速微调验证可行性，再在微调后的模型上执行高质量采样以获得最终结果。\\
      \item 严格记录复现实验清单：随机种子、采样器类型、步数、噪声谱/σ 范围、LoRA 参数、识别器版本与预处理细节。\\
\end{itemize}

\subsection[换脸模型]{换脸模型}

换脸（face swapping / face replacement）技术旨在将源人物的面部属性（身份特征、表情或口型）无缝地迁移到目标人物图像或视频上。尽管换脸最初多用于娱乐与影视制作，近年来该技术在深度学习推动下取得显著进展，同时也引发了严重的隐私与滥用风险问题。本小节综述主流的方法学路线、实现要点、常用评估指标以及与模板逆向重建/模型反演研究的关系。

1) 方法学路线。当前换脸方法大致可分为三类：
- 基于自编码器/生成器的端到端映射：这类方法通常采用编码器—解码器结构（或 U-Net 变体）学习从源图像到目标图像的像素级映射，训练时通过重构与身份保持的复合损失确保源身份在目标图像中得以保留；当用于视频时需加上时序一致性约束以避免抖动或闪烁。
- 基于几何/模型的融合（如 3DMM / 仿真渲染）：通过人脸关键点、3D 面部模型估计姿态与光照，先将源面部几何与纹理投影到目标基础几何上，再进行色彩与边界融合；该类方法在保持几何一致性与物理可解释性方面具有优势，便于处理大角度或光照差异。
- 基于条件生成与迁移学习的少样本/单样本方法：为提升泛化性，出现了少样本或单样本换脸方法（使用多任务训练、特征分离或风格融合），以及通过对抗训练提高合成的真实感。这些方法通常将身份表示与表情/姿态表示解耦，并在解码阶段重组以获得目标图像。

2) 身份与表情分解。换脸任务的核心挑战在于如何把“身份”与“可变因素”（表情、姿态、光照）有效分离。常用技术包括特征域投影与互信息最小化、利用专门的身份判别器保证身份一致性、以及在训练损失中引入嵌入相似度约束（如与预训练人脸识别网络的嵌入对齐）来显式维护身份特征。这一点与本研究中的“嵌入一致性”目标高度相关：将识别器嵌入作为度量或训练目标可以在换脸系统中提高身份保真度，但同时也提示了当模板或嵌入被泄露时的滥用风险。

3) 时序与视频一致性。视频换脸需关注帧间一致性与口型/表情同步问题，常用策略包括时序卷积、运动场估计、基于光流的混合以及在损失函数中加入感知级和光流一致性项；对于实时或近实时应用，还需优化推理延迟与内存占用。

4) 无缝融合与后处理。为了获得视觉上无缝的复合效果，换脸系统通常采用面部边界的软掩模、颜色一致化（color transfer）、多尺度融合与 Poisson blending 等技术来减少边界伪影和色彩不一致；这些工程化步骤对最终识别一致性也有影响，因过度平滑可能损失身份细节，而粗糙拼接又可能导致被识别器拒绝匹配。

5) 评估指标与伦理考量。换脸质量评估既包含感知真实度（FID、SSIM、LPIPS 等），也要求衡量身份保真（通过人脸识别模型的验证成功率或嵌入相似度）。重要的是，换脸研究与应用必须考虑伦理与法律约束，包括数据使用许可、明确标注合成内容、以及防止滥用的技术与政策手段（例如水印化、可检测性或合成内容签名）。

6) 与模板逆向重建的相关性。换脸技术与模板逆向重建在方法论上存在交集：二者都依赖高质量的生成模型、身份-表情分解与嵌入级约束。换脸系统展示了在人脸领域重构高保真外观的能力，这既为逆向重建提供了可借鉴的生成与融合技巧，也提醒我们应在设计防御与评估时考虑换脸方法可能带来的更强攻击主体（例如利用换脸生成的高保真图像进行识别系统的旁路攻击）。

7) 工程化建议。本研究在使用换脸或人脸合成作为基线/对照时，将采用统一的对齐与预处理流程、明确记录是否使用时序信息、并在报告中同时给出感知质量与识别一致性指标。此外，对于需要个性化适配的场景（例如少量样本下的跨域换脸），推荐采用参数高效的微调策略（如 LoRA）以在不完全重训练生成器的前提下获得较好的身份迁移效果。

上述内容为换脸技术的要点梳理，为第3章中利用生成模型进行模板重建、以及第5章中的实验对照提供参考。
\section[低秩适配微调技术]{低秩适配微调技术}
% === 被替换/新增内容的记录（保留原占位以便回溯） ===
% 原占位："低秩适配微调技术"

低秩适配（Low-Rank Adaptation，简称 LoRA）及其它参数高效微调方法，已经成为在大型生成模型或识别模型上进行任务特定适配时的常用选择。其基本出发点是：当基础模型参数规模非常大时，直接全量微调代价高、容易过拟合且不利于存储与部署；通过在若干关键权重矩阵上引入低秩可训练增量，可以在冻结原有权重的前提下以极少量额外参数实现对新任务的适配\cite{hu2021loralowrankadaptationlarge}。

下面先给出一个简洁的数学表述，再讨论工程实践要点、超参数建议与局限性。

\subsection*{数学表述}
设某层的权重矩阵为 $W\in\mathbb{R}^{d_{out}\times d_{in}}$，传统微调会直接优化 $W$。LoRA 的做法是在不改变 $W$ 的前提下引入一个可训练的低秩增量 $\Delta W$：
\begin{equation}\label{eq:lora}
      W' = W + \Delta W, \quad\Delta W = B A,
\end{equation}
其中 $A\in\mathbb{R}^{r\times d_{in}}$、$B\in\mathbb{R}^{d_{out}\times r}$，$r\ll\min(d_{in},d_{out})$ 为秩超参数。常见实现会在前向计算时以尺度因子 $\alpha$ 做缩放，即 $W' = W + \frac{\alpha}{r} B A$，以便对不同秩值间的更新幅度做归一化。

可训练参数量的附加成本为 $r(d_{in}+d_{out})$（近似），远小于全量微调的 $d_{in}d_{out}$。这一形式既可看作对权重矩阵的低秩近似，也等价于对网络权重空间做一组低维方向的线性组合。

\subsection*{应用位置与工程实现}
在视觉生成与识别模型中，LoRA 常用于以下位置：
- 注意力模块中的投影矩阵（query/key/value 投影或输出投影）；
- 前馈网络（MLP）中的线性层；
- U-Net 或 Transformer 的某些瓶颈层；
- 对卷积层，可通过在 $1\times1$ 卷积或点卷积处应用低秩分解实现类似效果。

实现要点：
% 原句备份：
% - 冻结原始网络参数，仅优化 $A,B$（以及可能的偏置项），这能显著降低显存占用并避免破坏原有能力；
% - 初始值选取：常用将 $A$ 置为小的高斯随机或零初始化、将 $B$ 置为零或小随机值，以保证训练初期网络行为接近原模型；\\
% - 缩放策略：采用 $\frac{\alpha}{r}$ 缩放项，能让不同秩设置下的学习率与幅度更可比；\\
% - 推理优化：训练完成后可将 $\Delta W$ 与 $W$ 合并以得到纯粹的密集权重用于高效推理，或在运行时将低秩模块以高效内核实现以节省内存。

- 冻结与分层解冻策略（实践建议）：通常建议在微调初期冻结基础模型 $W$，仅训练 LoRA 增量 $A,B$。这样能显著降低显存与计算开销，同时保留预训练模型的通用能力，从而减少过拟合风险与训练不稳定性。当验证性能不足时，可采用分层解冻（逐步解冻靠近输出或条件模块的少量参数）以增加适配能力，但应配合更小的学习率与更短的训练轮次以避免破坏原有能力。

- 初始化与数值稳定性：将 $A$ 以小方差高斯或零初始化、$B$ 以零或极小值初始化是常见做法；同时建议使用学习率预热（warmup）、梯度裁剪与较低的基线学习率（对 LoRA 参数）以避免早期发散。

- 缩放与超参数对齐：采用 $\frac{\alpha}{r}$ 作为缩放因子能让不同秩设置下的更新幅度更可比；在实验设计中应把 $r$ 与 $\alpha$ 作为一组超参数并联合调优，而不是孤立调整某一项。

- 正则化与监控：对 $B$ 使用轻度 L2 正则化或范数约束可抑制过大投影；训练过程中优先以识别器嵌入一致性（验证集余弦相似度 / TAR@FAR）作为早停与模型选择指标，辅以感知质量指标（LPIPS/FID）防止视觉质量退化。

- 推理与部署：训练结束后可将 $\Delta W=BA$ 与原权重合并（$W'=W+\frac{\alpha}{r}BA$）以获得最高推理速度；若需支持多套 LoRA 配置，建议将底层模型保存为只读并动态加载 LoRA 增量以节省存储与便于切换。

\subsection*{训练细节与超参数建议}
针对本研究中对生成器（例如 EDM / LDM 的 U-Net）或识别器做微调的场景，建议的经验性超参数范围如下（可根据数据量、目标复杂度与计算资源调整）：
- 秩 $r$：常用 $4\sim64$，对微量个性化适配（例如单身份）可取较小值($r=4$或$8$)，对更复杂风格/身份迁移可增大；
- 缩放因子 $\alpha$：常用 $1\sim32$；实际生效缩放为 $\alpha/r$，因此可通过 $\alpha$ 调整更新强度；
- 学习率：使用 AdamW，微调 $A,B$ 时一般在 $1\times10^{-5}\sim5\times10^{-4}$ 之间；若只微调条件模块或低秩矩阵，可适当取靠上界；
- 权重衰减与正则化：微小的 weight decay（如 $\le 1\times10^{-2}$）有助于稳定；可选地对 $B$ 做范数约束以防止过大投影；
- 批大小与步数：微调通常需要较小的训练轮次（从数十到数百步起步，或少量 epoch（如 1\~10 epoch）），批大小依据显存条件设定（8\~64 常见）；
- 早停与校验：建议使用识别器嵌入一致性（验证集的嵌入相似度或 TAR）作为早停/模型选择指标，避免生成视觉质量退化但识别一致性并不提升的情况。

在实验过程中，应额外监控：生成图像的感知质量（FID/LPIPS）、以及识别层面的匹配率（TAR@FAR），以避免单一指标优化带来的过拟合。

\subsection*{优势、局限与替代方法}
优势：低秩适配在参数效率、存储开销与部署便捷性上具有明显优势。对于需要对大量目标（例如多个身份）做个性化适配的场景，可以仅保存每个目标的小量 LoRA 权重而不是完整模型副本，从而极大降低存储成本。

局限：若目标变化过大或需要学习与基础模型截然不同的表征结构，低秩增量的容量可能不足，导致适配效果受限。此外，过度依赖缩放或不当初始化可能引入训练不稳定或伪影。

替代/补充方法：除 LoRA 外，常见的参数高效方法还包括 Adapter（在层间插入小型瓶颈模块）、Prefix-tuning（对 Transformer 的注意力键值加入可学习前缀）、BitFit（仅微调偏置）等。实践中可根据任务选择或组合这些方法（例如 LoRA + Adapter），以兼顾效率与表达能力。

\subsection*{针对模板逆向重建任务的建议}
在本研究的模板逆向重建情形，应考虑如下工程建议：
- 首先在公共数据集或通用无条件生成器上完成基础训练（或采用开源预训练权重），再对每个目标模板做 LoRA 微调（微适配），以避免对大模型全量训练；
- 微调目标应以嵌入一致性损失为核心（见第3章），同时辅以感知/像素损失以维持视觉质量；LoRA 的低秩参数仅需在微调阶段更新；
- 为提高样本效率，可在微调时采用学习率预热、梯度累积与小批次多次采样策略；
- 存储与复现：仅保存 $A,B$ 参数与对应的元信息（所用层、秩 $r$、$\alpha$、训练步数与验证指标），便于复现实验并降低存储成本。

% === 结束新增内容 ===
\section[本章小结]{本章小结}
本章对支持后续第3章与第4章方法设计和实验评估的若干理论与工程要点做了系统性的梳理，主要结论与实践建议如下：

1) 符号与问题约定——为保证论文的可读性与实验的可复现性，建议在附录或本章开头的“符号说明”中明确全部常用符号（例如 $x,x_t,x_0,y,f(\cdot),g_\theta,\epsilon_\theta,\alpha_t,\sigma$ 等）与数据/模板的格式（浮点/量化、维度 $d$、是否包含置信度），以便读者快速查阅并在复现在实现中保持一致性。

2) 人脸识别模型的几何性质与评估协议——基于度量学习的判别性损失（如 ArcFace 等）塑造了嵌入空间的几何结构，这直接影响模板逆向攻击的可行性与评估方法。实验应同时报告嵌入相似度（余弦/欧氏）、验证指标（TAR@FAR）、以及感知质量指标（FID、LPIPS），以便从识别一致性与视觉真实感两个维度综合评价重建结果。

3) 扩散模型的条件化与引导机制——从得分函数的角度，条件化生成可看作是将识别器关于输入的对数似然梯度或相似度能量项加入无条件得分的过程（见公式\eqref{eqn-3}~\eqref{eqn-8}）。这为两类工程实现提供理论支持：一是采样时通过 classifier/classifier-free/能量引导施加嵌入约束；二是在微调阶段将嵌入一致性作为显式损失以调整生成器参数或低秩增量。

4) 采样效率的工程折中——为应对需要多次查询或实时性要求，推荐基线采用隐空间扩散（LDM）并结合 EDM/二阶采样器或 DDIM 等加速方法以在少量步数下保持较好视觉质量；在评估攻击代价时记得报告平均采样步数与每次查询的运行时延迟。

5) 参数高效微调（以 LoRA 为代表）的实践建议——LoRA 在本课题中可作为对单个模板或少量目标做个性化适配的首选方案：它在参数/存储开销、训练稳定性与部署便捷性上有明显优势。本章给出的秩 $r$、缩放 $\alpha$ 与学习率范围可作为微调实验的起点；此外应保存每次微调的元信息以便复现（所更新层、秩、缩放、训练步数与验证指标）。

6) 评估与伦理约束——在进行模板逆向或换脸相关实验时，务必遵守数据许可与伦理规范：使用公开许可的数据集、对合成内容做标注、并在论文中说明潜在风险与防御建议（例如模板保护、差分隐私或签名化模板）。在结果展示中应同时给出成功攻击的统计概率与失败案例分析，以免仅展示“最好”样本造成误导。

7) 工程实现提示与复现清单——为保证工作可复现，建议在附录或项目说明中列出关键实现细节：深度学习框架与版本（例如 PyTorch 的具体版本）、关键第三方库（如 timm、accelerate、diffusers/edm 实现）、训练/推理的硬件配置、超参数表、随机种子与数据预处理脚本。对 LoRA 等微调方法，应提供如何将低秩增量合并回原模型的说明与伪代码。

本章的理论与工程要点将直接支撑第3章中提出的基于扩散模型的模板逆向重建方法（包括嵌入一致性损失、LoRA 微适配策略与采样引导实现），后续章节将基于本章约定给出详细的算法、实验设置与可复现的实现细节。

\subsection[数学原理补充]{数学原理补充}
本小节补充并明确本章涉及的若干数学原理与推导要点，便于将来在论文正文中引用定理/公式并用于算法实现的严格说明。

\subsubsection*{1. 从 score-matching 到去噪目标的等价性（要点）}
考虑噪声预测目标
\begin{equation}
      L_{\epsilon} = \mathbb{E}_{x_0,\epsilon\sim\mathcal{N}(0,I),t}\left[ w(t) \|\epsilon - \epsilon_\theta(x_t,t)\|^2\right],
\end{equation}
其中 $x_t=\sqrt{\overline{\alpha}_t}x_0+\sqrt{1-\overline{\alpha}_t}\,\epsilon$。按链式运算可得关于 $x_t$ 的得分函数近似
\begin{equation}
      \nabla_{x_t}\log p(x_t) = -\frac{1}{\sqrt{1-\overline{\alpha}_t}}\,\epsilon_\theta(x_t,t) + C(t),
\end{equation}
其中常数项 $C(t)$ 与 $x_t$ 无关，可被吸收到权重或偏移项中。进而，最小化 $L_{\epsilon}$ 等价于对不同噪声尺度下的加权得分匹配（score-matching）问题，从而保证训练得到的 $\epsilon_\theta$ 能用于近似 $\nabla_{x_t}\log p(x_t)$（参见式~\eqref{eqn-5}）。

证明要点（略）: 将 $x_0$ 用 $x_t,\epsilon$ 表示并展开展开平方项，可把 $L_{\epsilon}$ 重写为关于 $\epsilon_\theta$ 与真实得分的二次项，进而等价于加权的得分匹配下界（见 Song 等人的推导）。在工程实践中通过选择合适的权重 $w(t)$ 可稳定训练并平衡不同噪声尺度的贡献。

\subsubsection*{2. Score-based SDE 与反向 SDE}
令前向 SDE 写作
\begin{equation}
      d x = f(x,t)\,dt + g(t)\,dW_t,
\end{equation}
则其对应的反向（time-reversed）SDE 在已知 $\nabla_x\log p_t(x)$ 时可写为
\begin{equation}
      d x = \left[f(x,t) - g(t)^2\,\nabla_x\log p_t(x)\right] dt + g(t)\,d\bar W_t,
\end{equation}
其中 $\bar W_t$ 为反向 Wiener 过程。该表达说明：若能估计出 $\nabla_x\log p_t(x)$（由去噪网络提供），即可解出反向生成过程；分类器/能量项可通过在得分上叠加 $\nabla_x\log p(y|x)$ 实现条件化（见下小节）。

\subsubsection*{3. 分类器引导与 classifier-free guidance 的关系}
若存在一个条件分类器 $p_\phi(y|x_t)$，则
\begin{equation}
      \nabla_{x_t}\log p(y|x_t) \approx \nabla_{x_t} \log p_\phi(y|x_t).
\end{equation}
将其与无条件得分相加给出条件得分（贝叶斯分解）:
\begin{equation}
      \nabla_{x_t}\log p(x_t|y) = \nabla_{x_t}\log p(x_t) + \nabla_{x_t}\log p(y|x_t).
\end{equation}
在实际采样中，常用带权重的混合形式来放大条件信息：
\begin{equation}
      s_{\text{guid}} = s_{\text{uncond}} + w\,(s_{\text{cond}} - s_{\text{uncond}}) = (1-w) s_{\text{uncond}} + w s_{\text{cond}},
\end{equation}
其中 $s=\nabla_{x_t}\log p(\cdot)$。等价地，对噪声預測器而言有
\begin{equation}
      \epsilon_{\text{guid}} = \epsilon_{\text{uncond}} + \gamma\,(\epsilon_{\text{cond}} - \epsilon_{\text{uncond}}),
\end{equation}
其中 $\gamma$ 与 $w$ 存在简单线性映射（与噪声尺度因子有关）。

Classifier-free guidance 的实现不需要额外训练分类器，而是在训练阶段隨機屏蔽条件（例如将条件 embedding 替换为全零或 sentinel），使模型学会在有/无条件下均可预测噪声。推导上 classifier-free guidance 与上式等价，只是 $\epsilon_{\text{cond}}$ 与 $\epsilon_{\text{uncond}}$ 来自同一网络在不同输入下的输出。

\subsubsection*{4. 条件化采样时的能量项近似}
在本研究我们把识别器的嵌入相似度视为能量 $E(x;y) = -\lambda\cdot \text{sim}(f(x),y)$，其对 $x$ 的梯度用于在采样过程中修正得分：
\begin{equation}
      \nabla_x \log p(x|y) \approx \nabla_x \log p(x) - \nabla_x E(x;y).
\end{equation}
在实现中直接对 $f(\cdot)$ 取微分并反向传播得到 $\nabla_x \text{sim}(f(x),y)$ 的近似梯度，该项与去噪器的输出在 score-space 中进行线性组合（见伪代码示例），可视为对目标嵌入相似度的显式引导。

\subsubsection*{5. LoRA 的代数表示与参数量分析}
设原权重矩阵为 $W\in\mathbb{R}^{d_{out}\times d_{in}}$，LoRA 引入低秩增量 $\Delta W = B A$，其中 $A\in\mathbb{R}^{r\times d_{in}}$、$B\in\mathbb{R}^{d_{out}\times r}$。若在前向传播中采用缩放因子 $\alpha$，则实际替换为
\begin{equation}
      W' = W + \frac{\alpha}{r} B A.
\end{equation}
参数额外开销约为 $r(d_{in}+d_{out})$，远小于 $d_{out}d_{in}$。训练时仅更新 $A,B$（和可能的缩放），可显著降低显存与存储成本。训练结束后可合并：
\begin{equation}
      W'_{\text{merged}} = W + \frac{\alpha}{r} B A
\end{equation}
以便高效推理。

梯度维度说明：若损失为 $\mathcal{L}$，则对 $A,B$ 的梯度分别为
\begin{equation}
      \nabla_A \mathcal{L} = B^{\top} \nabla_{W'} \mathcal{L},\qquad \nabla_B \mathcal{L} = \nabla_{W'} \mathcal{L}\, A^{\top},
\end{equation}
从而训练仅在低维子空间中进行权重更新。

\subsubsection*{6. 黑盒优化时的无梯度近似（简要）}
在黑盒场景下，若只能得到标量分数 $S(x)$，可采用有限差分或随机扰动估计梯度：
\begin{equation}
      \hat g = \frac{1}{m}\sum_{i=1}^m \frac{S(x+\delta_i)-S(x-\delta_i)}{2\epsilon} \\, \delta_i,
\end{equation}
其中 $\delta_i$ 为服从零均值分布的随机方向（例如高斯或 Rademacher），$\epsilon$ 为扰动幅度。NES / SPSA 等方法即基于该类估计，通过并行化或控制方差技巧提高查询效率。本研究在实现黑盒潜在优化基线时采用了上述思路并在实验中测量查询成本与成功率的 trade-off。

% End of math supplement

% Local Variables:
% TeX-master: "../main"
% TeX-engine: xetex
% End:
