% !Mode:: "TeX:UTF-8"
\begin{conclusions}

% 原始结论已保留于版本历史；为便于回溯，下面将原文整体以注释形式保存在仓库历史中。

% ====== 改写并扩充后的结论（正文） ======

本文围绕人脸识别系统中的两类重要隐私威胁——模板逆向攻击（Template Inversion Attack, TIA）与模型反演攻击（Model Inversion Attack, MIA）——进行了系统性的理论刻画、方法设计与实证验证。基于本文的研究与实验，得出以下结论：

1) 问题与威胁建模的区分有助于方法设计。我们将 TIA（以目标模板为条件、追求特征空间一致性）与 MIA（以类别标签为条件、最大化分类器响应）区分开来，并据此设计不同的攻击范式与评价指标，这对后续算法选择与实验对比至关重要。

2) 在有特征或可查询输出的条件下，结合高质量生成先验与特征约束的攻击方法既可保持视觉质量又能显著提升攻击成功率。对于 TIA，基于 EDM 的条件扩散模型并辅以两阶段的特征一致性微调，能够在不显著牺牲图像感知质量的前提下提高与目标模板的嵌入相似度；对于 MIA，将换脸（Deepfake）类生成先验与标签驱动的局部微调相结合，能在仅有类别信息时生成更具代表性的“类别样本”。

3) LoRA 等轻量级增量参数化方法在资源受限场景下非常有效。实验证明，在微调预算有限（少参数、少步数）时，LoRA 能以远低于全模型微调的成本实现明显的识别一致性提升，这对于实际工程化攻击与防御评估具有重要意义。

4) 方法效能存在明显的访问与先验依赖性。若目标系统仅返回极其有限的输出（如仅返回 top-1 类别或高度量化的概率），基于生成的重建效果与攻击成功率都会显著下降；同样，生成先验的质量（预训练生成器或换脸模型）对最终效果有显著影响。这提示在指标解释与系统威胁评估时应明确访问假设。

5) 实验评估应采用多维指标并报告不确定性。本研究建议并实践了以 TAR@FAR、嵌入余弦相似度、FID/LPIPS 等为核心的多指标评估体系，且对所有关键配置进行多次重复以报告均值与置信区间，从而更可靠地刻画方法间差异。

6) 防御方向具有工程可行性但需权衡效用与成本。针对本研究暴露的风险，实用的防御措施包括模板不可逆化/加密、API 层的噪声注入或差分隐私、查询速率限制与异常检测、以及训练阶段的对抗正则化。上述措施在降低反演可行性的同时，会对系统性能或用户体验带来不同程度的影响，需结合具体应用场景做权衡。

7) 研究局限与未来工作。本文工作主要基于公开数据集与可获得的生成先验进行验证，未来需在更贴近生产环境的数据与更严格的黑盒访问模型上进行扩展。后续工作建议包括：
\begin{itemize}
	\item 发展黑盒与低信息场景下的高效查询/代理方法；\
	\item 构建标准化的防御-对抗基准，量化差分隐私、输出截断、模板保护等多种防御的效力/成本曲线；\
	\item 将方法与评估推广到其他生物特征与跨模态隐私威胁场景；\
	\item 增强解释性分析，揭示生成样本为何携带特定嵌入信息以指导更有针对性的防御。
\end{itemize}

8) 可复现性与工程产物。为支持后续研究与审阅复现，本文随附完整训练/微调、推理与评估脚本、关键配置样例与随机种子记录（见 `experiments/` 目录），并在论文中明确了所有关键超参数与数据划分策略。

总结：本文通过问题形式化、两类攻击范式的设计与系统实验，揭示了在不同访问假设下针对人脸识别系统的逆向重建攻击的能力范围与实现路径；研究结果既为理解潜在隐私风险提供了实证依据，也为部署端设计防御策略提供了可行方向。

\end{conclusions}
